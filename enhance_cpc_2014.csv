A blurred barcode image is processed by providing an image representation thereof comprising grayscale values. The image representation is deconvoluted using a candidate motion kernel to get a deconvoluted representation. A barcode similarity measure is calculated for the deconvoluted representation to indicate how close the distribution of the grayscale values of the deconvoluted representation is to an optimal distribution for a barcode image. The kernel provision deconvolution and measure calculation are repeated for different candidate kernels and the candidate kernel resulting in a deconvoluted representation that is closest to a barcode image as determined based on the barcode similarity measures is selected. The selected kernel is used for deconvoluting the blurred barcode image to get a deblurred barcode image that can be read and decoded.
A method performs an image processing application by expressing the image processing application as a non-negative quadratic program NNQP with a quadratic objective and nonnegativity constraints. A Karush-Kuhn-Tucker condition of the NNQP is expressed as a fixpoint ratio. Then the fixpoint ratio is determined iteratively until a solution to the image processing application is reached with a desired precision.
Various implementations relate to improving depth maps. This may be done for example by identifying bad depth values and modifying those values. The values may represent for example holes and/or noise. According to a general aspect a segmentation is determined based on an intensity image. The intensity image is associated with a corresponding depth image that includes depth values for corresponding locations in the intensity image. The segmentation is applied to the depth image to segment the depth image into multiple regions. A depth value is modified in the depth image based on the segmentation. A two-stage iterative procedure may be used to improve the segmentation and then modify bad depth values in the improved segmentation and iterating until a desired level of smoothness is achieved. Both stages may be based for example on average depth values in a segment.
A method of enhancing an image includes: dividing the input image into multiple tiles; and constructing a respective histogram for each respective multiple tile. The method further includes: dividing each respective histogram into multiple portions in which each portion represents a count of pixels spanning across pixel intensity value bands. The method also includes: constructing a respective cumulative distribution function CDF for each of the multiple portions; and transforming each of the multiple portions using the respective CDF. Each histogram may be divided as an example into two portions.
A method of enhancing an image. This includes the steps of: dividing the image into multiple tiles and constructing a histogram for each tile wherein the histogram represents a distribution of pixel intensity values in each tile. In addition the method applies a bias value to the histogram and a plateau value to the histogram. A cumulative histogram is constructed after applying the bias value and the plateau value to the histogram. The method transforms each pixel in the image by weighing four cumulative histograms respectively in four adjacent and closest tiles to the pixel under consideration. The pixel under consideration is modified based on a weighted cumulative histogram.
When reconstructing low-collimation nuclear scan data 18 e.g. SPECT into a nuclear image volume 19 a spatial frequency-dependent SFD filter function is applied in Fourier space to the reconstructed image 19 to improve image resolution given a predefined number of reconstruction iterations and/or to reduce the number of reconstruction iterations required to achieve a predetermined level of image resolution. Size of an object to be imaged is determined and the SFD filter function is determined or generated based on signal power spectrum and/or modulated transfer function data object size and desired image quality or number of reconstruction iterations . The SFD filter function amplifies higher-energy components e.g. corresponding to a lesion or tumor or the like of the spatial frequency spectrum to improve viability in a low collimated nuclear image 19 using fewer reconstruction iterations.
In a first exemplary embodiment of the present invention an automated computerized method is provided for processing an image. According to a feature of the present invention the method comprises the steps of providing an image file depicting an image in a computer memory determining intrinsic component information as a function of spatio-spectral information for the image and calculating analytical information as a function of the intrinsic component information.
Signals are provided which allow colors in a wider color range than predetermined standards which can be handled by apparatus according to such predetermined standards. A primary color converter converts first color signals having primary color points in a wider color range than the primary color points according to BT.709 into second color signals based on the primary colors according to BT.709. A photoelectric transducer converts the second color signals into third color signals according to photoelectric transducer characteristics defined in a numerical range wider than a range from 0 to 1.0 of color signals corresponding to a luminance signal and color difference signals according to BT.709. A color signal converter converts the third color signals into a luminance signal and color difference signals. A corrector incorporated in the color signal converter corrects the color difference signals into color difference signals.
An image processing method and device and a medical instrument are provided to perform equalization processing on a residual image obtained by decomposing an input image and perform composition processing on the equalized residual image and a detail image obtained by decomposing the input image to obtain a result image.
A vehicle is equipped with a camera which may be a stereoscopic camera and a computer for processing the image data acquired by the camera. The image acquired by the camera is processed by the computer and features are extracted therefrom. The features are further processed by various techniques such as object detection/segmentation and object tracking/classification. The acquired images are sometimes contaminated by optical occlusions such as raindrops stone-chippings and dirt on the windshield. In such a case the occluded parts of the image are reconstructed by optical flow estimation or stereo disparity estimation. The fully reconstructed image is then used for intended applications.
An image processing method includes the steps of obtaining an image generated by an image pickup system and performing correction processing for the image by utilizing an image restoration filter generated or selected based on an optical transfer function of the image pickup system. The image restoration filter is a filter configured to reduce a phase degradation component of the image.
A method including the steps of obtaining an original image generating a converted image by converting a gradation of a pixel of the original image into a prescribed gradations for an image forming apparatus to express outputting a dot pattern image through a nozzle based on a predetermined dot pattern signal generating nozzle characteristic information of the nozzle based on the dot pattern image generating simulation information based on the converted image and the nozzle characteristic information generating converted simulation information by converting the simulation information to the same gradation as that of the pixel of the original image comparing the converted simulation information with the original image and calculating an error between the original image and the converted simulation information.
A system and method for generating a fused image is provided. The system comprises processing circuitry configured to receive a plurality of images filter each received image using an edge preserving filter compute a weight for each received image based on the corresponding filtered image and the received image and generate a fused image based on the weights of each received image. The system further comprises a memory device configured to store the fused image.
An image processing device includes an edge-enhancing image enlarger that converts an input image to a high-resolution image with edge enhancement. A difference calculator determines differences between the high-resolution image and the input image. A high-resolution image corrector corrects the high-resolution image by diffusing the differences to pixels of the high-resolution image thereby generating a corrected image in which edges are enhanced without image degradation in textured areas.
A blemish detection method includes the following steps: capturing a first image using an image sensor; adjusting the brightness of the first image to obtain a second image; calculating a brightness ratio of each pixel in the second image; marking the pixels of which the brightness ratios are greater than or equal to a predetermined reference value as &#x201c;1&#x201d; and marking the other pixels as &#x201c;0&#x201d;; calculating the quantity of pixels in a continuous area in which all pixels are marked as &#x201c;1&#x201d;; and determining that the continuous area is a blemish if the quantity of pixels in the continuous area is greater than or equal to a predetermined pixel quantity.
A method of filling occluded areas of a depth or disparity map estimated from at least two images and consisting of a matrix of pixels forming a set of lines and columns each pixel of the map being associated with a depth or disparity value pixel value and any pixel of an occluded area invalid pixel being associated with a pixel value identifiable as being invalid. This method comprises a step of processing each line of the map pixel by pixel in a predefined direction and assigning each invalid pixel Pi encountered on a current line a value determined as a function of the values associated with the pixels in a predefined vicinity around the first valid pixel P1 if any that follows the invalid pixel Pi on the current line and the value V P1 of which corresponds to a greater depth or a lesser disparity relative to the value V P0 of the last valid pixel P0 if any that precedes the invalid pixel Pi on the current line.
A method is provided for scaling an image taken at a given exposure time to a selected exposure time. The method generally comprises: determining a dark pixel intensity of an imaging device; acquiring a first image at a given exposure time; and adjusting a pixel intensity of one or more pixels in the first image based at least in part on the dark pixel intensity for a second exposure time that is different from the given exposure time.
The method for improving the visual perception of a digital image may comprise dividing the digital image into repetitive areas and modifying the tone curve and/or the histogram of each area to improve the visual perception of the corresponding area. Lastly the joins between adjacent areas may be smoothed.
A method is provided that includes generating coefficients of a scene adaptive filter SAF based on differences between values of neighboring pixels in a representative two dimensional 2D image and applying the SAF to a plurality of corresponding 2D images.
The picture quality of captured images can be improved with the degradation of clearness of image-captured object boundaries suppressed. An image processing apparatus 100 comprises: an image/distance acquiring unit 200 that acquires corresponding pixel pairs between left-eye and right-eye images its depth information and its matching scores; a weight information calculating unit 300 that determines for each of the pixel pairs a weight of each of the pixels in a certain area including as pixels of interest the pixel pair on the basis of the depth information and the matching scores; and a pixel value superimposing unit 400 that applies for each of the pixel pairs the weight to the pixel values in the aforementioned certain area thereby performing a smoothing process in at least one of the two images and that superimposes the two images using the values obtained by the smoothing process.
The present invention relates to an image interpolation method based on matrix and an image processing system. The image processing system first determines a gradient direction of an image region formed by a pixel dot array containing an interpolation point and then based on the gradient direction and a position of the interpolation point determines a triangle for interpolation in the image region formed with the pixel dot array and finally based on pixel values of pixel dots corresponding to three vertexes of the determined triangle and a distance from the interpolation point to a vertex of the triangle calculates a pixel value of the interpolation point. Thus the problem of edge jag or sawteeth of details in an oblique direction of a zoomed image is effectively solved and a high-quality image is obtained. Furthermore for the method the calculation is simple and the computation load is light.
Systems and methods for texture processing are presented. In one embodiment a texture method includes creating a sparse texture residency translation map; performing a probe process utilizing the sparse texture residency translation map information to return a finest LOD that contains the texels for a texture lookup operation; and performing the texture lookup operation utilizing the finest LOD. In one exemplary implementation the finest LOD is utilized as a minimum LOD clamp during the texture lookup operation. A finest LOD number indicates a minimum resident LOD and a sparse texture residency translation map includes one finest LOD number per tile of a sparse texture. The sparse texture residency translation can indicate a minimum resident LOD.
A night vision device and method for filtering a series of image frames that depict a moving subject which thereby improves the signal-to-noise ratio of each image frame is provided. A composite image is formed for each image frame by combining pixel values in a current image frame with pixel values in composite images corresponding to image frames acquired before the current image frame. Additionally pixels values in image frames acquired subsequent to the acquisition of the current image frame are included when forming the composite image. A bi-directional recursive filter is used to weight the contributions from the previous composite images and subsequent image frames with a decay constant. Motion of the imaging system is optionally compensated for by establishing a moving reference frame and shifting the image frames to account for this motion; thus registering the image frames before filtering the current image frame.
A method for digital image eye artifact detection and correction include identifying one or more candidate red-eye defect regions in an acquired image. For one or more candidate red-eye regions a seed pixels and/or a region of pixels having a high intensity value in the vicinity of the candidate red-eye region is identified. The shape roundness or other eye-related characteristic of a combined hybrid region including the candidate red-eye region and the region of high intensity pixels is analyzed. Based on the analysis of the eye-related characteristic of the combined hybrid region it is determined whether to apply flash artifact correction including red eye correction of the candidate red-eye region and/or correction of the region of high intensity pixels.
A method for noise suppression in a 3-D volume image executed at least in part on a logic processor obtains the 3-D volume image applies diffusion to the volume image according to a parameter that relates to image scale and is specified in an operator instruction and displays the volume image modified according to the applied diffusion.
An image processing apparatus includes a first extraction unit a second extraction unit a third extraction unit a determination unit a correction unit and a color quantization unit. The first extraction unit extracts from an image a region and color of an information image. The second extraction unit extracts a color of a peripheral image surrounding the extracted region. The third extraction unit extracts information necessary for color quantization processing. The determination unit determines whether a color difference between the extracted color of the information image and the extracted color of the peripheral image falls within a predetermined range when color quantization processing is based on the extracted information. The correction unit corrects a representative color if it is determined that the color difference does not fall within the predetermined range. The color quantization unit performs color quantization processing on the image on the basis of the corrected representative color.
The embodiments described below include systems methods and computer storage mediums for blending image assets based on changes in a zoom level. An exemplary method includes determining an image asset from a collection of image assets wherein the image asset is determined as a function of the zoom level. When the zoom level meets a threshold zoom level a color corrected image asset is determined from the collection of image assets. The color corrected image asset is determined as a function of the zoom level and a color correction profile. The image asset and the color corrected image asset are blended where the blending includes applying a first coefficient value to the image asset and a second coefficient to the color corrected image asset. Each of the first and second coefficient values may be determined as a function of the difference between the zoom level and the threshold zoom level.
A method of processing a digital image said image comprising a plurality of pixels the method comprising a computation step S1 wherein a histogram of the distribution of the number of pixels of the image as a function of their luminance is computed a step S2 for lightening the image based on said histogram comprising a subdivision S20 of the pixels of the image into a first set of pixels having luminance values between a low threshold and a high threshold and into a second set of pixels having luminance values greater than said high threshold a first luminance processing operation S21 on the pixels of the first set of pixels and a second luminance processing operation S22 on the pixels of the second set of pixels the two luminance processing operations S21 S22 being different the first processing operation S21 comprising an increase in the luminance of the pixels of the image.
Disclosed is a decoding device 300a that outputs an output signal by receiving as an input an encoded signal including a signal in which an original signal is encoded the original signal being indicative of contents of at least one of image and audio and the output signal being indicative of the contents which decoding device includes a decoding process section 310 that generates a decoded signal be decoding the encoded signal and a nonlinear process section 102 that generates a nonlinear process signal i in which positive and negative signs of a low-frequency-free signal are retained which low-frequency-free signal is obtained by removing from the input signal at least a direct current of frequency components included in the decoded signal and ii which broadly monotonically increases nonlinearly with respect to the low-frequency-free signal when values of the low-frequency-free signal are at least in the vicinity of 0; the nonlinear process signal is added to the decoded signal to generate the output signal.
Systems and methods for image data fusion include providing first and second sets of image data corresponding to an imaged first and second scene respectively. The scenes at least partially overlap in an overlap region defining a first collection of overlap image data as part of the first set of image data and a second collection of overlap image data as part of the second set of image data. The second collection of overlap image data is represented as a plurality of image data subsets such that each of the subsets is based on at least one characteristic of the second collection and each subset spans the overlap region. A fused set of image data is produced by an image processor by modifying the first collection of overlap image data based on at least a selected one of but less than all of the image data subsets.
The present invention relates to minimally invasive X-ray guided interventions in particular to an image processing and rendering system and a method for improving visibility and supporting automatic detection and tracking of interventional tools that are used in electrophysiological procedures. According to the invention this is accomplished by calculating differences between 2D projected image data of a preoperatively acquired 3D voxel volume showing a specific anatomical region of interest or a pathological abnormality e.g. an intracranial arterial stenosis an aneurysm of a cerebral pulmonary or coronary artery branch a gastric carcinoma or sarcoma etc. in a tissue of a patient s body and intraoperatively recorded 2D fluoroscopic images showing the aforementioned objects in the interior of said patient s body wherein said 3D voxel volume has been generated in the scope of a computed tomography magnet resonance imaging or 3D rotational angiography based image acquisition procedure and said 2D fluoroscopic images have been co-registered with the 2D projected image data. After registration of the projected 3D data with each of said X-ray images comparison of the 2D projected image data with the 2D fluoroscopic images&#x2014;based on the resulting difference images&#x2014;allows removing common patterns and thus enhancing the visibility of interventional instruments which are inserted into a pathological tissue region a blood vessel segment or any other region of interest in the interior of the patient s body. Automatic image processing methods to detect and track those instruments are also made easier and more robust by this invention. Once the 2D-3D registration is completed for a given view all the changes in the system geometry of an X-ray system used for generating said fluoroscopic images can be applied to a registration matrix. Hence use of said method as claimed is not limited to the same X-ray view during the whole procedure.
One or more systems and methods for edge-adaptive and recursive non-linear filtering of ringing effect on image or video data are disclosed in accordance with various embodiments of the invention. In one embodiment of the invention a method for edge-adaptive and recursive non-linear filtering of ringing effect first involves detecting all edges within a process area of an image including a direction of an edge slope and a value of an edge signal level. Then if the process area is determined to be a &#x201c;non-busy&#x201d; area based on a &#x201c;busyness&#x201d; measure relative to empirically-defined threshold values then an edge influence function subsequently determines whether to apply a de-ringing filter to a current pixel within the process area or not. Preferably the de-ringing filter is edge-adaptive non-linear and recursive. The de-ringing filter can adjust the current pixel multiple times based on filter angles adjacent pixels and pixel transition levels.
Systems including apparatus and methods for obtaining and/or correcting images particularly from atmospheric and/or other distortions. These corrections may involve among others collecting two or more sets of image data corresponding to images of the same scene in different wavelength regimes and using correlations between wavelength and expected distortion to distinguish apparent image motion due to distortion from apparent image motion due to object or scene motion. These systems may be useful in any suitable imaging context including navigation targeting search and rescue law enforcement commercial video cameras and/or surveillance among others.
An image processing device for performing edge-preserving smoothing includes a reducing unit for reducing an input image; a reduced image smoothing unit for performing a smoothing processing on a reduced image generated by the reducing unit with edges preserved; and an edge-preserving enlarging unit for enlarging an image generated by the reduced image smoothing unit with the edges preserved. The edge-preserving enlarging unit performs a filtering processing by determining a pixel value of a target pixel for the filtering processing based on weighted addition of pixel values of respective reference pixels. Weighting coefficients for the pixel values of the respective reference pixels is set based on differences between a pixel value of the input image corresponding to the target pixel and pixel values of the respective reference pixels and based on distances between the target pixel and the respective reference pixels.
A system for displaying hybrid image data produced by embedding additional media objects within street-level panoramic images includes a user interface through which a user may view search for and/or navigate through additional media objects in the context of browsing a virtual environment of a location at street level. In response to user input indicating a request to view a geographic location and/or an additional media object street-level panoramic image data associated with the geographic location in which one or more additional media objects also associated with the geographic location have been embedded may be provided for display through the user interface. The user interface may be provided by a client device including one or more processors that receive hybrid image data produced by one or more processors of a server and display the image data to the user.
This disclosure pertains to apparatuses methods and computer readable media for red-eye removal techniques using multiple recognition channels. In the following examples red golden and white recognition channels are used. A recognition channel is the monochrome extraction from a color photograph in a manner designed to make one kind of red-eye artifact glow with maximum contrast. Once the red-eye artifact has been characterized by e.g. size and location the techniques disclosed herein may then discern whether the red-eye artifact is for example a red- golden- or white-eye case by examining the configuration and characteristics of prominence bitmasks created for the various recognition channels. Once the type of red-eye case has been discerned the techniques disclosed herein may then replace the artifact with a photographically reasonable result based on the type of red-eye case being repaired. Specular reflection may also be re-added to the photograph.
Inter-color image prediction is based on color grading modeling. Prediction is applied to the efficient coding of images and video signals of high dynamic range. Prediction models may include a color transformation matrix that models hue and saturation color changes and a non-linear function modeling color correction changes. Under the assumption that the color grading process uses a slope offset and power SOP operations an example non linear prediction model is presented.
A median filtering method makes a plurality of pixel data into a block of fixed unit area which includes a central pixel and a plurality of ambient pixels adjacent to the central pixel. Pixel data within the unit area is divided into sub unit areas which are smaller than the unit area. The data value of the divided pixel data is arranged in a fixed order for each of the sub unit areas. An intermediate value is determined from the arranged pixel data in each of the sub unit areas. An average value of the intermediate values which are extracted from each of the sub unit areas and the central pixel data is determined corresponding to the central pixel of the unit area with the average value.
An image processing method for boundary resolution enhancement is disclosed. Firstly an image is transferred into an image layer. Noise of the image layer is removed by a bilateral filter and crisp edges are retained at the same time. Moreover the image layer is interpolated by an interpolation filter for resolution enhancement. The image processing method of the present invention can lower the image blur degree substantially enhance the image resolution and be widely implemented in all sorts of image/video processing hardware devices.
An apparatus for correcting image distortion of a rear imaging device including analyzing by a processor a characteristic of a imaging device installed in a rear of a vehicle; setting by the processor a plurality of tilting angles for a plurality of photographed areas of a virtual imaging device corresponding to the rear imaging device from a characteristic value of the imaging device; generating by the processor a correction model by applying the plurality of tilting angles for the plurality of photographed areas of the virtual imaging device; tilting by the processor the virtual imaging device based on the correction model; performing by the processor a view conversion on an image photographed through the rear imaging device according to the plurality of set tilting angles for the plurality of photographed areas of the virtual imaging device to generate a corrected image; and outputting by the processor the corrected image.
Systems and methods are disclosed for image reconstruction and enhancement using a computer system. One method includes acquiring a plurality of images associated with a target anatomy; determining using a processor one or more associations between subdivisions of localized anatomy of the target anatomy identified from the plurality of images and local image regions identified from the plurality of images; performing an initial image reconstruction based on image acquisition information of the target anatomy; and updating the initial image reconstruction or generating a new image reconstruction based on the image acquisition information and the one or more determined associations.
A first color component of a pixel or scene entity is modified using a color correction curve defined at least partly by a second color component of this pixel or entity. Each pixel or entity has its own separate color correction curve independent of the color correction curves of other pixels or entities. The saturation value of a pixel or scene entity may be modified based on its luminance value. The luminance value determines a saturation gamma function curve mapping the original saturation value of a pixel or entity to a new saturation value. The unilluminated color of a pixel or of an illuminated entity in a scene being rendered may also be taken into account. This output color may be stored in the appropriate pixel of an image or combined with colors from other portions of the scene being rendered.
An image processing apparatus for applying a color balance correction to input image data comprises a first highlight color calculation unit which estimates a light source at the time of shooting from pixel values of the image data converts color values of the image data based on a condition of the estimated light source at the time of shooting and calculates a first highlight color; a second highlight color calculation unit which calculates a second highlight color from the image data; a third highlight color calculation unit which calculates a third highlight color based on a positional relationship between the first highlight color and the second highlight color on a color space; and a correction unit which attains the color balance correction by converting the pixel values of the image data using the third highlight color.
An image processing device includes: a first band limiting unit that reduces noise included in an input image; and a restoring unit wherein the restoring unit has a difference calculating unit that calculates a difference between the input image and a noise-reduced image a predicted noise obtaining unit that obtains a predicted noise amount to be included in the input image a correction signal generating unit that generates a correction signal for correcting the noise-reduced image and controlling an absolute value of the difference between the input image and the noise-reduced image within a range of the predicted noise amount and an image synthesizing unit that corrects the noise-reduced image based on the correction signal.
A system method and computer program product are provided for reducing noise in an image using depth-based on sweeping over image samples. In use each noisy pixel of an image having noise is identified. Additionally for each noisy pixel at least one sample included in each of a plurality of neighboring pixels to the noisy pixel is identified. Furthermore the samples are swept over at least partially in a depth-based order to identify a value for the noisy pixel that reduces the noise.
A method for performing motion compensation in a series of magnetic resonance MR images includes acquiring a set of MR image frames spanning different points along an MR recovery curve. A motion-free synthetic image is generated for each of the acquired MR image frames using prior knowledge pertaining to an MR recovery curve. Each of the acquired MR images is registered to its corresponding generated synthetic images. Motion within each of the acquired MR image is corrected based on its corresponding generated synthetic image that has been registered thereto.
The present invention relates to a method and a system for rectifying images. An original stereo image pair is obtained and the epipolar lines corresponding to the original stereo image pair are parallelized to obtain a first transformed stereo image pair. Epipolar lines corresponding to the first transformed stereo image pair are collinearized to obtain a second transformed stereo image pair. The present invention parallelizes and collinearizes the epipolar lines corresponding to the stereo image pair after the images are rectified.
In a first exemplary embodiment of the present invention an automated computerized method is provided for processing an image. According to a feature of the present invention the method comprises the steps of providing an image file depicting an image defined by image locations in a computer memory generating a bi-illuminant chromaticity plane in a log color space for representing the image locations of the image in a log-chromaticity representation for the image providing a set of estimates for the orientation of the bi-illuminant chromaticity plane and calculating an orientation for each one of the image locations as a function of the set of estimates for the orientation.
An image combining apparatus obtains information of an object area upon photographing of images executes a preparation operation preceding to the photographing on the basis of the obtained information measures an elapsed time from the preparation operation to a photographing instruction divides each of the photographed images into a plurality of areas detects a motion vector of each divided area weights the detected motion vector by using the elapsed time and the information of the object area and calculates a position adjustment vector by using the weighted motion vector.
Provided is an image processing apparatus including: a frequency value calculation section that allocates each pixel of an input image to any of respective partial regions obtained by dividing the entirety of a possible range of a luminance value into units in a luminance direction on the basis of the luminance value thereof and allocates one pixel of the input image to partial regions when calculating frequency values representing the number of pixels allocated to the partial regions with respect to the respective partial regions to update the frequency values of the partial regions; a characteristic value calculation section that calculates a characteristic value representing a characteristic of the partial region; and a weighted product-sum section that performs edge-preserving smoothing on the input image by weighting and averaging the characteristic values in accordance with a distance in the luminance direction using the calculated frequency value and the calculated characteristic value.
A method for sharpening an original digital image includes generating a smoothed image from the original image. A residual image is generated from the smoothed image and the original image. A sharpened smoothed image is generated. The residual image and the sharpened smoothed image are combined to produce a sharpened version of the original image.
A computer-implemented method for viewing images on an interactive computing device comprises displaying an image from a stack comprising a display image and at least one compressed sub-image of nominally the same scene each of the sub-images of the stack having been acquired at respective focal distances. Responsive to a user selecting a portion of the displayed image the selected portion is mapped to a corresponding mapped portion of a sub-image within the stack according to the difference in focal distances between the displayed image and the sub-image. At least one row of compressed image blocks of the at least one sub-image extending across the mapped portion; and a reference value for a point in the compressed image stream of the sub-image preceding the row of compressed image blocks is determined. Using the reference the row of blocks of the sub-image at least partially decoded and a measure of focus for an area of the mapped portion coinciding with the decoded image blocks is computed to determine if at least that content of the sub-image should be displayed within a display image.
One embodiment of the present invention sets forth a technique for displaying high-resolution images using multiple graphics processing units GPUs . The graphics driver is configured to present one virtual display device simulating a high-resolution mosaic display surface to the operating system and the application programs. The graphics driver is also configured to partition the display surface amongst the GPUs and transmit commands and data to the local memory associated with the first GPU. A video bridge automatically broadcasts this information to the local memories associated with the remaining GPUs. Each GPU renders and displays only the partition of the display surface assigned to that particular GPU and the GPUs are synchronized to ensure the continuity of the displayed images. This technique allows the system to display higher resolution images than the system hardware would otherwise support transparently to the operating system and the application programs.
The present invention relates to an apparatus for and a method of propagating depth-related information from a first depth-map 810 associated with a first image 820 to a second depth-map 860 associated with a second image 830 the first and second image being temporally proximate images in an image sequence. The method comprises generating an intermediate depth-map 840 associated with the second image 830 by propagating depth values from the first depth-map 810 to the intermediate depth-map 840 using pixels of the first image 820 and the second image 830 and generating a motion vector 850 using information comprising depth values in a spatial region around a first location in the first depth-map 810 and depth values in a spatial region around a second location in the intermediate depth-map 840 and generating a depth value for the second location in the second depth-map 860 using information comprising the motion vector 850 and the first depth-map 810 .
Method of removing the spatial response signature of a detector from a computed radiography image by adaptively filtering and spatially warping the characteristic response signature of the detector prior to demodulation.
A method and apparatus for image processing a lens-distorted image e.g. a fisheye image is provided. The method includes partitioning coordinate points in a selected output image into tiles. The output image is an undistorted rendition of a subset of the lens-distorted image. Coordinate points on a border of the tiles in the output image are selected. For each tile coordinate points in the lens-distorted image corresponding to each selected coordinate point in the output image are calculated. In addition for each tile a bounding box on the lens-distorted image is selected. The bounding box includes the calculated coordinates in the lens-distorted image. The bounding boxes are expanded so that they encompass all coordinate points in the lens-distorted image that map to all coordinate points in their respective corresponding tiles. Output pixel values are generated for each tile from pixel values in their corresponding expanded bounding boxes.
The present disclosure includes motion blur modeling methods and systems for image formation. One motion blur modeling method for image formation includes obtaining image data utilized to form a particular image taken by a camera of a subject obtaining velocity vector data for the subject at the time the image was taken defining a convolution kernel for use formation of the particular image and based upon the velocity vector data and applying the convolution kernel to the image data to produce a de-blurred set of image data utilized to form the particular image.
A method can include detecting a pixel direction and a pixel weight for each of a number of pixels in an image generating one-dimensional 1D and two-dimensional 2D histograms based on the pixel directions and weights and generating a global 2D histogram based on the generated 1D and 2D histograms. The method can also include generating a final depth map based on the global 2D histogram. The method can also include generating a block histogram statistic based on the pixel directions and pixel weights and checking the block histogram based on the block histogram statistic.
Methods and apparatus may be applied to reconstruct pixel values in saturated regions of an image. Saturated regions are identified and hues for pixels in the saturated regions are estimated based on hues in boundaries of the saturated regions. Gradients for pixel values in saturated color channels within the saturated region may be estimated based on known gradients for non-saturated color channels. Reconstructed pixel values may be derived from the estimated gradients. The methods and apparatus may be applied in conjunction with dynamic range expansion.
The image processing method includes a filter preparation step of preparing an image restoration filter to be commonly used for plural optical apparatuses having mutually different optical characteristics and a correction information preparation step of preparing correction information varying by the optical characteristic of each of the plural optical apparatuses. The method further includes a processing step of performing an image restoration process on an input image produced by image capturing through a specific optical apparatus of the plural optical apparatuses using the image restoration filter and the correction information for the specific optical apparatus.
An image processing apparatus stores model information representing a subject model belonging to a specific category detects the subject from an input image by referring to the model information determines a region for which an image correction is to be performed within a region occupied by the detected subject in the input image stores for a local region of the image a plurality of correction data sets representing correspondence between a feature vector representing a feature before correction and a feature vector representing a feature after correction selects at least one of the correction data sets to be used to correct a local region included in the region determined to undergo the image correction and corrects the region determined to undergo the image correction using the selected correction data sets.
An image processing apparatus includes: a recognition unit that performs character recognition on an image including at least one character and that obtains a score indicating a recognition accuracy of at least one character region extracted through the character recognition; a local blurring-degree computation unit that computes a first degree of blurring of the at least one character region; and a blurring-degree computation unit that computes a second degree of blurring of the image by using the score and the first degree of blurring of the at least one character region.
A classifier training system trains a classifier for evaluating image deblurring quality using a set of scored deblurred images. In some embodiments the classifier training system trains the classifier based on a number of sub-images extracted from the scored deblurred images. An image deblurring system applies a number of different deblurring transformations to a given blurry reference image and uses the classifier trained by the classifier training system to evaluate deblurring quality thereby finding a highest-quality deblurred image. In some embodiments the classifier training system trains the classifier in the frequency domain and the image deblurring system uses the classifier trained by the classifier training system to evaluate deblurring quality in the frequency domain. In some embodiments the image deblurring system applies the different deblurring transformations iteratively.
Techniques in accordance with the following disclosure enable digital images to be filtered smoothed to reduce noise and at the same time preserve the image s underlying structure. In general image pixels are analyzed to identify those that participate in or belong to structure within the image and those that do not. For those pixels determined to be part of the image s structure the direction of that structure is determined and filtering or smoothing along that direction is provided. Contrast enhancement in a direction perpendicular to the detected edge s direction may also be provided.
A method for enhancing a radiographic image. The method includes obtaining image data for the radiographic image generating conditioned image data by increasing differences between neighboring portions of at least a relatively uniform area of the radiographic image generating an enhanced image by applying contrast limited adaptive histogram equalization to the conditioned image data applying interpolation to the enhanced image and displaying storing or transmitting the enhanced image.
Methods and apparatus for deinterlacing an interlaced image or for upsampling an image. In one embodiment an Edge Aware Deinterlacing system may identify edge areas and non-edge areas of an image in order to apply one interpolation method to pixels within the edge areas and a different interpolation method to pixels within the non-edge areas.
After a plurality of differently exposed images are obtained and tone levels of the plurality of images are adjusted image elements corresponding to changes of objects are detected based on pixel value differences between the plurality of images. Then the numbers of blown-out highlight and shadow-detail loss image elements in the image elements corresponding to the changes of the objects are counted for the plurality of images. Then an image in which the total of the numbers of image elements is smallest is selected. Furthermore image elements corresponding to the changes of the objects in the selected image are used as those corresponding to image elements corresponding to the changes of the objects in an HDR image to be generated.
An image processing apparatus includes a depth control signal generation unit generating a depth control signal controlling emphasis of the feel of each region of an input image based on the depth position of a subject in each region of the input image; a face skin region control signal generation unit generating a face skin region control signal controlling emphasis of the feel of each region in the input image based on the human face skin region in the input image; a person region control signal generation unit generating a person region control signal controlling emphasis of the feel of each region in the input image based on the region of the person in the input image; and a control signal synthesis unit synthesizing the depth control signal the face skin region control signal and the person region control signal to generate a control signal.
The present method relates to digital color image processing in particular restoration and recovery of lost contrast and details in highlights due to overexposure or clipping by reconstructing components based on the signal remaining in at least one non-clipped signal component.
An image enhancement system may generate a net signed fractional modulation value at each location in an image using a modulation strength map MSM in combination with a modulation kernel F &#x3b8; . The system may scale an image value at each location using the net signed fractional modulation value at each location. Application of the algorithm may not result in systematic clipping of peri-edge locations to maximum or minimum brightness values or any other form of systematic homogenization of values at peri-edge locations.
An image processing method is adapted for color enhancement of an original image pixel. The original image pixel is composed of a plurality of pixel components each having a component value. The image processing method includes: determining a hue region to which the original image pixel belongs based directly on the component values of the pixel components thereof; selecting a color enhancement parameter corresponding to the determined hue region; and obtaining a color enhanced pixel according to the selected color enhancement parameter and the component values of the pixel components of the original image pixel.
Systems and methods are provided for providing improved de-noising image content by using directional noise filters to accurately estimate a blur kernel from a noisy blurry image. In one embodiment an image manipulation application applies multiple directional noise filters to an input image to generate multiple filtered images. Each of the directional noise filters has a different orientation with respect to the input image. The image manipulation application determines multiple two-dimensional blur kernels from the respective filtered images. The image manipulation application generates a two-two-dimensional blur kernel for the input image from the two-dimensional blur kernels for the filtered images. The image manipulation application generates a de-blurred version of the input image by executing a de-blurring algorithm based on the two-dimensional blur kernel for the input image.
An apparatus computer program product and method for reducing persistent shadows within an image. The apparatus includes a camera configured to generate frames of the image. The apparatus also includes a computer processor. The computer processor calculates the average normalized brightness for each pixel in the image and adjusts the brightness of each pixel with the average normalized brightness.
The invention relates to the field of digital image processing and can find use in suppression of noise in digital images formed by high-energy radiation including X-ray radiation. Specifically the invention relates to a method for suppression of noise in digital x-ray images. The objective of the invention is to provide a method for noise suppression in digital X-ray images that has extended functionality specifically a method that makes it possible to reduce residual noise level and amount of artifacts in the form of discontinuities directed along local orientation of object borders in textured image areas to reduce residual LF noise level and to eliminate over-smoothing excessive filtering of fine details. The technical innovation achieved is the improvement of digital image processing quality.
According to one embodiment an image processing apparatus includes: a reduction module configured to reduce image data that is input to output reduced data; an extraction module configured to extract a diffuse reflection component from the reduced data; an enlargement module configured to enlarge the diffuse reflection component to a size before reduction of the input image data to output enlarged data; a high-frequency acquisition module configured to acquire a high-frequency component removed by reduction from difference between the input image data and the reduced data; a high-frequency addition module configured to output first data obtained by adding the high-frequency component acquired to the enlarged data; and a gloss component acquisition module configured to acquire a gloss component from difference between the input image data and the first data.
An image processing method of picking up an image of a substrate and converting pixel values of the picked-up substrate image makes the pixel values of the picked-up substrate image into a histogram and creates a tone curve T composed of a periodic function of a predetermined amplitude and a predetermined period based on a distribution of the pixel values in the histogram. The pixel values of the picked-up substrate image are converted using the tone curve T to obtain a substrate image with a high contrast.
A method for obtaining and/or enhancing local contrast differences LD in digital image input data in wherein a local contrast measure SADap approximating a two-dimensional sum of absolute difference SAD measure is obtained by obtaining a first-dimension sum of absolute difference measure energyVk m n representing a sum of absolute difference SAD in a first dimension of at least one image region and obtaining the local contrast measure SADap as a second-dimension convoluted first-dimension sum of absolute difference measure by convoluting the first-dimension sum of absolute difference measure energyVk m n in a second dimension of the at least one image region is proposed wherein the step of obtaining the local contrast measure SADap as the second-dimension convoluted first-dimension sum of absolute differences measure further includes an addition step wherein an energy term &#x394;lpfk j representing a first-order difference on a distance J of a low pass filtered signal used in obtaining the first-dimension sum of absolute differences measure energyVk m n and in obtaining the second-dimension convoluted first-dimension sum of absolute differences measure is introduced while obtaining the local contrast measure SADap .
Multiple-exposure high dynamic range image processing may be performed that filters pixel values that are distorted by blooming from nearby saturated pixels. Pixel values that are near saturated pixels may be identified as pixels that may be affected by blooming. The contributions from those pixels may be minimized when producing a final image. Multiple-exposure images may be linearly combined to produce a final high dynamic range image. Pixel values that may be distorted by blooming may be given less weight in the linear combination.
A computer implemented method for fusing images taken by a plurality of cameras is disclosed comprising the steps of: receiving a plurality of images of the same scene taken by the plurality of cameras; generating Laplacian pyramid images for each source image of the plurality of images; applying contrast normalization to the Laplacian pyramids images; performing pixel-level fusion on the Laplacian pyramid images based on a local salience measure that reduces aliasing artifacts to produce one salience-selected Laplacian pyramid image for each pyramid level; and combining the salience-selected Laplacian pyramid images into a fused image. Applying contrast normalization further comprises for each Laplacian image at a given level: obtaining an energy image from the Laplacian image; determining a gain factor that is based on at least the energy image and a target contrast; and multiplying the Laplacian image by a gain factor to produce a normalized Laplacian image.
A method and an apparatus are provided for eliminating noise in a digital image. An ambient image and at least one flash image are captured in succession of a given location. At least one image alignment technique is applied for the ambient image and the at least one flash image. Joint mean shift filtering is applied to the at least one flash image to obtain filter weights. The filter weights are applied to the ambient image to eliminate noise in the ambient image.
A method for repairing bridging or extrapolating an existing aperture to improve image interpretability in synthetic aperture radar images.
In accordance with an embodiment of the invention an anisotropic denoising method is provided that removes sensor noise from a digital image while retaining edges lines and details in the image. In one embodiment the method removes noise from a pixel of interest based on the detected type of image environment in which the pixel is situated. If the pixel is situated in an edge/line image environment then denoising of the pixel is increased such that relatively stronger denoising of the pixel occurs along the edge or line feature. If the pixel is situated in a detail image environment then denoising of the pixel is decreased such that relatively less denoising of the pixel occurs so as to preserve the details in the image. In one embodiment detection of the type of image environment is accomplished by performing simple arithmetic operations using only pixels in a 9 pixel by 9 pixel matrix of pixels in which the pixel of interest is situated. As a result improved image environment sensitive noise reduction is achieved that requires a relatively low gate count in hardware implementations.
An image processing method is adapted for hue adjustment of an original image pixel. The original image pixel is composed of a plurality of pixel components each having a component value. The image processing method includes: determining a hue zone to which the original image pixel belongs based directly on the component values of the pixel components thereof; obtaining a shifted hue zone according to a predefined hue shift amount the determined hue zone and the component values of the pixel components of the original image pixel; and obtaining a hue shifted pixel according to the obtained shifted hue zone and the component values of the pixel components of the original image pixel.
There is provided an image processing device including a focus area setting section a depth acquisition section and a blur processing section. The focus area setting section sets each of a plurality of areas as a focus area and the each of the plurality of areas is intended to be kept in focus in a captured image of a subject. The depth acquisition section acquires a depth of the subject in relation to each pixel in the image. The blur processing section sets each of the pixels in the image as a target pixel and performs a blur process on the target pixel in accordance with a minimum value of absolute value of each depth difference between depth corresponding to the target pixel and depth corresponding to each of the focus area.
A method for determining noise levels in a subband of an image. The method comprises receiving the subband of the image defining block regions in at least two space domains of the subband for each defined block region identifying first wavelet coefficients associated with coordinate values in the at least two space domains in the defined block region computing a correlation matrix between identified wavelet coefficients to determine the correlation between first wavelet coefficients according to the at least one color domain computing second wavelet coefficients the computation of second wavelet coefficients being based on the correlation matrix and the first wavelet coefficients computing at least one noise level the noise level computation being based on at least one second wavelet coefficient and providing the at least one noise level.
The present invention provides a panchromatic sharpening method of spectral image based on fusion of overall structural information and spatial detail information comprising: performing brightness linear stretching on a panchromatic image so as to set the variance of the panchromatic image to be equal to the variance of said spectral image; respectively interpolating N components of the spectral image so as to generate an interpolation image series having the same resolution as that of the panchromatic image; subtracting the interpolation image series from the panchromatic image after said linear stretching to obtain difference images; performing Gauss filtering on the difference images thereby obtaining difference tendency images; and respectively subtracting the difference tendency image series from the panchromatic image after said linear stretching thus obtaining fused images. The method can maintain both spectral fidelity and texture detail fidelity of the fused images support high computation speed and has wide applicability.
What is disclosed is a system and method for real-time enhancement of an identified time-series signal of interest in a video that has a similar spatial and temporal structure to a given reference signal as determined by a measure of closeness. A closeness measure is computed for pixels of each image frame of each channel of a multi-channel video to identify a time-series signal of interest. The intensity of pixels associated with that time-series signal is modified based on a product of the closeness measure and the reference signal scaled by an amplification factor. The modified pixel intensity values are provided back into the source video to generate a reconstructed video such that upon playback of the reconstructed video viewers thereof can visually examine the amplified time-series signal see how it is distributed and how it propagates. The methods disclosed find their uses in remote sensing applications such as telemedicine.
A method of automatically determining a need to service a digital image acquisition system including a digital camera with a lens assembly includes analyzing pixels within one or more acquired digital images according to probability determinations that such pixels correspond to blemish artifacts. It is automatically determined whether a threshold distribution of blemish artifacts is present within one or more of the digital images. A need for service is indicated when at least the threshold distribution is determined to be present.
A system and method for generating a fused image is provided. The system comprises processing circuitry configured to access a plurality of images group the images into a plurality of sets fuse the images of each set to form a plurality of fused images and fuse the fused images to form a final fused image.
Local contrast enhancement comprises obtaining a first frame as a reference frame and a second frame as a current frame. The reference frame is partitioned into a plurality of reference regions and a first color mapping function is derived for at least one of the reference regions in the reference frame according to the corresponding color distribution. The first color mapping function comprises for at least one of a predetermined set of colors a first source color value and a first contrast-enhanced color value. The current frame is partitioned into a plurality of regions and a second color mapping function is derived for at least one of the regions in the current frame according to the first color mapping functions of at least two of the reference regions in the reference frame. The second color mapping function is applied to generate a contrast-enhanced frame.
Described is a system for stabilizing detecting and recognizing objects in video captured from a mobile platform. The system first receives a video with a plurality of image frames captured from a mobile platform. The video is stabilized by registering the image frames to a global coordinate system to generate stabilized image frames. A bio-inspired attention algorithm is applied to the stabilized image frames to produce a set of locations in the stabilized image frames that are salient points representative of an object of interest. An image chip is generated that surrounds each salient point. High-dimensional feature vectors are extracted from the image chip. The feature vectors are then classified as an object class. Thus through classifying the feature vectors an object of interest can be identified in the video as captured from the mobile platform.
An apparatus and method for filtering depth information received from a capture device. Depth information is filtered by using confidence information provided with the depth information based an adaptively created optimal spatial filter on a per pixel basis. Input data including depth information is received on a scene. The depth information comprises a plurality of pixels each pixel including a depth value and a confidence value. A confidence weight normalized filter for each pixel in the depth information is generated. The weight normalized filter is combined with the input data to provide filtered data to an application.
Embodiments disclose systems and methods that aid in screening diagnosis and/or monitoring of medical conditions. The systems and methods may allow for example for automated identification and localization of lesions and other anatomical structures from medical data obtained from medical imaging devices computation of image-based biomarkers including quantification of dynamics of lesions and/or integration with telemedicine services programs or software.
An image editing application or a blur classification module thereof may automatically estimate a coherent defocus blur map from a single input image. The application may represent the blur spectrum as a differentiable function of radius r and the optimal radius may be estimated by optimizing the likelihood function through a gradient descent algorithm. The application may generate the spectrum function over r through polynomial-based fitting. After fitting the application may generate look-up tables to store values for the spectrum and for its first and second order derivatives respectively. The use of these tables in the likelihood optimization process may significantly reduce the computational costs of a given blur estimation exercise. The application may minimize an energy function that includes a data term a smoothness term and a smoothness parameter that is adaptive to local image content. The output blur map may be used for image object depth estimation.
A method for removing noise from an image includes receiving image data including a plurality of pixels. A graph including a plurality of nodes and a plurality of edges interconnecting the nodes is formulated. Each pixel of the image data is represented as a node of the graph and each edge of the graph is assigned a weight based on a penalty function applied to the nodes connected by the edge where the penalty function is less when a value of a given pixel of the plurality of pixels is between or equal to the values of two neighboring pixels than when the value of the given pixel is either greater than or less than the values of both of the two neighboring pixels. A total penalty of the graph is minimized. A denoised image is provided based on the total penalty-minimized graph.
Aspects of the subject technology relate to methods and systems for removing haze from an input image. The system includes a polarimeter configured to receive an input image the input image comprising haze corresponding to light scatter. The polarimeter is further configured to produce plural Stokes values based on received input image. The system also includes a signal processor coupled to the polarimeter. The signal processor is configured to determine a peak angle and a valley angle for the input image based on the plural Stokes values where the peak angle corresponds to an angle at which the input image has the most amount of light scatter passing therethrough and the valley angle corresponds to an angle at which the input image has the least amount of light scatter passing therethrough. The signal processor is further configured to perform removal of the haze from the input image based on the determined peak and valley angles.
An image denoising method includes the steps of: sequentially selecting a pixel in an image as a current pixel; dynamically determining a current search block and a strength parameter; pre-denoising the comparison block of each pixel in the current search block; comparing the comparison block of the pre-denoised neighborhood pixel and the comparison block of the pre-denoised current pixel to obtain a similarity between each neighborhood pixel and the current pixel in the current search block; determining a weighting of each neighborhood pixel related to the current pixel according to the strength parameter and a distance and the similarity between each neighborhood pixel and the current pixel in the current search block; and weighted averaging each neighborhood pixel and the current pixel in the current search block according to the weighting to obtain a reconstruction value of the current pixel.
A method and apparatus are provided for adaptive sharpness enhancement of image data. In on embodiment a method for sharpness enhancement includes receiving image data for a first frame performing linear sharpening enhancement of the image data performing non-linear sharpening enhancement of the image data and generating blending parameters based on the image data. The blending parameters may be generated based upon image data of the first frame linear sharpened image data for the first frame and non-linear sharpened image data for the first frame. The method may further include blending the image data of the first frame the linear sharpened image data and the non-linear sharpened image data based upon the blending parameters.
The invention relates to a method of determining the distortions in the projection system of a TEM and a method of correcting for these aberrations. The aberrations are determined by collecting a large number of images of a sample the sample slightly displaced between each acquisition of an image. On the images sub-fields 303 304-i showing identical parts of the sample are compared. These sub-fields 303 304-i will show small differences corresponding to differential aberrations. In this way the differential aberrations in a large number of points can determined after which the aberrations for each point can be determined by integration. By now correcting the position of each detected pixel in an image to be displayed the displayed image has much reduced aberrations. An advantage of the method according to the invention is that no highly accurate steps of the sample are needed nor is a sample with known geometry needed.
The invention concerns a method of converting raw multidimensional digital data corresponding to points making up a 2D or 3D image of unknown size and an associated system. The method comprises: the sizing a multidimensional window for traversing of said image the said sizing depending on the size of a buffer; the traversing the said image comprising the movement of the said window in the image along the axes of the image; at each position of the said window in the image:
Some embodiments provide a method of operating a device to capture an image of a high dynamic range HDR scene. Upon the device entering an HDR mode the method captures and stores multiple images at a first image exposure level. Upon receiving a command to capture the HDR scene the method captures a first image at a second image exposure level. The method selects a second image from the captured plurality of images. The method composites the first and second images to produce a composite image that captures the HDR scene. In some embodiments the method captures multiple images at multiple different exposure levels.
Embodiments of the invention relate generally to generating images with an enhanced range of brightness levels and more particularly to facilitating high dynamic range imaging by adjusting pixel data and/or using predicted values of luminance for example at different resolutions. In at least one embodiment a method generates an image with an enhanced range of brightness levels. The method can include accessing a model of backlight that includes data representing values of luminance for a number of first samples. The method also can include inverting the values of luminance as well as upsampling inverted values of luminance to determine upsampled values of luminance. Further the method can include scaling pixel data for a number of second samples by the upsampled values of luminance to control a modulator to generate an image.
There is provided an image processing device including a depth acquisition unit and a smoothing processing unit. The depth acquisition unit acquires a depth to a subject in correlation with a pixel in a captured image of the subject and the smoothing processing unit designates a pixel in a region excluding a predetermined region in the image as a target pixel and performs a smoothing process of the degree according to the depth corresponding to the target pixel for a pixel value of the target pixel in a predetermined direction. This causes a pixel in a region excluding the predetermined region in the image to be blurred thereby generating a panning image.
The image processing device includes a three-dimensional image data input unit which enters three-dimensional image data representing a three-dimensional image a subject extractor which extracts a subject from the three-dimensional image data a spatial vector calculator which calculates a spatial vector of the subject from a plurality of planar image data having different viewpoints contained in the three-dimensional image data and a three-dimensional image data recorder which records the spatial vector and the three-dimensional image data in association with each other.
Provided is an image processing apparatus including an image signal correction section that performs an image correction process. The image signal correction section performs a direction determination process of detecting a direction having a minimum pixel value gradient as a pixel value gradient direction in a pixel area including a target pixel; a defect detection process of calculating a Laplacian based on a pixel value of a reference pixel in a minimum gradient direction detected in the direction determination process with respect to the target pixel and determining presence or absence of a defect of the target pixel; and a defect correction process of performing calculation of a corrected pixel value which is obtained by applying the pixel value of the reference pixel in the direction detected in the direction determination process with respect to a target pixel from which a defect has been detected in the defect detection process.
An image processing method is provided and includes the following steps. A source image arranged in a Bayer pattern is captured. A first-order image process is performed on the source image to produce a first image in YCbCr format. A second-order image process is performed on the source image to produce a second image in YCbCr format. Then a noise-reducing process is performed on the first image in YCbCr format to produce a noise-reduced image. A blending operation is performed on luminance image of the noise-reduced image and luminance image of the second image in YCbCr format and thereafter a chrominance image is combined with the blended image to produce a processed image. A noise reducing degree of the noise-reduced image is higher than that of the second image in YCbCr format.
Systems and methods for block noise detection and filtering are disclosed. One embodiment includes computing difference magnitudes in pixel values for adjacent pixels in the image. The difference magnitudes can include horizontal difference magnitudes for horizontally adjacent pixels and vertical difference magnitudes for vertically adjacent pixels. One embodiment further includes using normalized sums of the difference magnitudes to determine a set of noise characteristics of the block noise and a set of image characteristics of the image and configuring inputs to the block noise filter using the set of noise and image characteristics.
An information processing apparatus is provided that includes a playback unit to play back music data an analysis unit to analyze a feature of a relevant image of the music data an image correction unit to perform image correction with use of any of a plurality of correction types a storage unit to store one or more than one image a selection unit to select a correction type corresponding to the feature of the relevant image analyzed by the analysis unit from the plurality of correction types a correction control unit to cause the image correction unit to perform image correction of an image stored in the storage unit with use of the correction type selected by the selection unit and an output unit to output the image corrected by the image correction unit.
A technique of enhancing a scene containing one or more off-center peripheral regions within an initial distorted image captured with a large field of view includes determining and extracting an off-center region of interest hereinafter &#x201c;ROI&#x201d; within the image. Geometric correction is applied to reconstruct the off-center ROI into a rectangular or otherwise undistorted or less distorted frame of reference as a reconstructed ROI. A quality of reconstructed pixels is determined within the reconstructed ROI. One or more additional initially distorted images is/are acquired and matching additional ROIs are extracted and reconstructed to combine with reduced quality pixels of the first reconstructed ROI using a super-resolution technique to provide one or more enhanced ROIs.
An automated computerized method for processing a video is provided. The method includes providing a video file depicting a video in a computer memory; providing a video file depicting a video in a computer memory; scale separating the video file by applying an edge-preserving blurring filter to generate a detail scale-separated video and a level scale-separated video corresponding to the video; temporally blurring the detail scale-separated video and spatially blurring the level scale-separated video; combining the filtered detailed scale-separated video and the filtered level scale-separated video to provide an output video; and outputting the output video for use in a data compression operation.
A method of processing a computerized tomography image is disclosed. The method comprises preprocessing the image using contrast enhancement weight function thereby providing a preprocessed image having a first dynamic range; and applying a companding procedure to the preprocessed image so as to reduce the first dynamic range.
Method system device and computer program product for determining vanishing point candidates of a text portion in an image document distorted by perspective. The method includes the steps of image binarization connected component analysis estimating a number of text lines in a Cartesian coordinate system transforming the text lines to data points in a homogenous coordinate system assigning a confidence level to the data points grouping a number of data points into a priority sample array clustering the data points in the priority sample array into a number of sample groups and assigning a group confidence value to each sample group. A RANSAC algorithm is applied to determine among the data points a set of inliers initiated with the sample group having the highest group confidence value. A vanishing point candidate is determined from the text lines corresponding to the set of inliers.
Sub-regions within a face image are identified to be enhanced by applying a localized smoothing kernel to luminance data corresponding to the sub-regions of the face image. An enhanced face image is generated including an enhanced version of the face that includes certain original pixels in combination with pixels corresponding to the one or more enhanced sub-regions of the face.
A method for selecting an optimum subset of images from a larger set of images for optimal HDR image creation. For each of the set of images an exposure quality map is computed by assigning to each pixel of the image an exposure quality value based on the pixel brightness value of that pixel. A suitable exposure quality function typically reflecting the properties of the imaging device is used for this purpose. Then for each possible subset of images the exposure quality maps for the images in the subset are combined using a max operation to generate a combined exposure quality map for the subset. An average pixel value of the combined exposure quality map of the subset is then calculated and serves as a quality score. The subset of images processing the highest quality score are used to generate the HDR image.
The correction amount of an aberration caused in each pixel of the region by the optical system is calculated. A predetermined number of peripheral pixels center on a position apart from the pixel by the distance corresponding to the calculated aberration correction amount are multiplied by interpolation coefficients obtained from an interpolation function and added thereby deriving the pixel value at the pixel position after correction. If the predetermined number of peripheral pixels around the position apart by the distance corresponding to the calculated aberration correction amount are not present in the readout region aberration correction is implemented by changing the interpolation function. More specifically the interpolation function is changed so as to make the frequency response behavior of the interpolation function more moderate than that of the interpolation function that gives the interpolation coefficients to multiply the predetermined number of peripheral pixels and used in the correction processing.
An imaging apparatus 100 includes a light emitting part 103 configured to irradiate a subject s with light; an imaging part 101 configured to image the subject s ; the imaging part 101 a distance information acquiring part 102 and a distance calculating part 203 each configured to acquire a distance to the subject s ; a shadow estimating part 204 configured to estimate based on the distance acquired by the imaging part 101 the distance information acquiring part 102 and the distance calculating part 203 a shadow s generated by the light from the light emitting part 103 in an image shot by using the imaging part 101; and a shadow correcting part 205 configured to correct the shadow s estimated by the shadow estimating part 204 such that the shadow s is lightened.
An X-ray imaging apparatus and a method of updating a pixel map correct a bad pixel of an X-ray transmission image. An X-ray transmission image is generated by detecting an X-ray penetrating an object and it is determined whether a difference between a value of each one of the pixels forming the X-ray transmission image and a value of a nearby pixel adjacent to the each one of the pixels is equal to or greater than a reference value. A pixel having a value representing a difference equal to or greater than the reference value is determined as a candidate for a bad pixel. A message is displayed which requests a selection of whether to determine if the candidate is a bad pixel. The pixel map is updated by reflecting the determined bad pixel on the pixel map.
The present disclosure relates to a method for improving the perception of an image. The method may include subjecting an original image to a series of independent processes each producing a pixel calculated using a respective reference kernel. The reference kernels each may comprise pixels from the original image.
In some embodiments a method of processing a video sequence may include receiving an input video sequence having an input video sequence resolution aligning images from the input video sequence reducing noise in the aligned images and producing an output video sequence from the reduced noise images wherein the output video sequence has the same resolution as the input video sequence resolution. Other embodiments are disclosed and claimed.
The invention relates to an electronic device for performing imaging including a camera means for creating image data ID from an imaging target IT the imaging target IT including at least one primary image object I1 and at least one secondary image object I2 an image-processing chain arranged in connection with the camera for processing the image data created from the imaging target and a focussing unit for focussing the camera on at least the primary image object. In addition a blurring unit is arranged in the image-processing chain to blur at least some of the said secondary image objects in the image data and arranged to use the information produced by the focussing unit.
A technique for processing a digital image uses face detection to achieve one or more desired image processing parameters. A group of pixels is identified that corresponds to a face image within the digital image. A skin tone is detected for the face image by determining one or more default color or tonal values or combinations thereof for the group of pixels. Values of one or more parameters are adjusted for the group of pixels that correspond to the face image based on the detected skin tone.
Error-function determining means makes use of a blur function serving as a function representing the degree of blurring of a blurred input image and a geometrical-deformation matrix serving as a matrix for restricting an operation to lay out a 2-dimensional code shown by the input image on cells each serving as a configuration unit of the 2-dimensional code in order to determine an error function serving as a function satisfying a relation that the smaller the error between the input image and an image obtained by adding geometrical deformations and blurs to a recovered image obtained from a recovering process the more the approach to a result determined in advance. Pixel-value restricting means determines pixel-value restriction information prescribing a restriction condition for a restriction imposed on a predetermined pixel value obtained from discretization of pixel values of the 2-dimensional code to be recovered. Objective-function determining means makes use of the error function and the pixel-value restriction information as a basis for determining an objective function serving as a function satisfying a relation that the closer the recovered image to the true image the more the approach to a result determined in advance. Objective-function optimizing means determines a recovered image optimizing the objective function.
An image processing apparatus and method to reduce the deterioration of visibility of an image displayed on an image display device occurring under various lighting conditions when the brightness of ambient light is brighter than that of the image display device and includes a sensor to sense the brightness of an external light a unit to store a luminance-contrast model curve representing an optimal contrast value for a particular luminance for each brightness of the external light a unit to determine a target luminance value according to the sensed brightness of the external light to obtain a contrast value corresponding to the target luminance value with reference to the luminance-contrast model curve corresponding to the sensed brightness and to adjust an input image to have the target luminance value and the obtained contrast value and a unit to adjust the saturation of the adjusted input image according to the target luminance value and the obtained contrast value.
A method of controlling an image analysis apparatus is provided. The method includes receiving a query image; determining at least one main color distributed in the query image and a specific main color from among the at least one main color by using color information contained in the query image; dividing the query image into at least one block having a predetermined number of pixels; and determining whether each of the at least one block includes more than a predetermined percentage of a main color for comparison among the at least main color and creating a binary spatial distribution map by digitizing the at least one block.
A pattern matching processing unit 10 binarizes input image data 1 compares a binarized pattern with a pattern provided for each of groups and outputs either first information indicating a group to which a pattern that matches the binarized pattern belongs or second information indicating no match. A 0-degree direction dedicated filter 21 a 45-degree direction dedicated filter 22 a 90-degree direction dedicated filter 23 and a 135-degree direction dedicated filter 24 which are disposed correspondingly to the groups carry out smoothing processes according to the direction of an edge of the image respectively. When the pattern matching processing unit outputs the first information a selector 30 selects the output of either one of the filters corresponding to the group as output image data 2 whereas when the pattern matching processing unit outputs the second information the selector outputs the input image data 1 as the output image data 2.
A method of generating output image data comprises obtaining derivative data relating to a reference image; obtaining a constraint for output image data; and generating the output image data from the derivative data relating to the reference image in dependence on the constraint. This method can be used to recover a robust output image from the derivative of an input image.
The present disclosure relates to an ultrasonic diagnostic apparatus. The ultrasonic diagnostic apparatus transmits an ultrasound signal to a diagnosis target and receives the reflected ultrasound signal from the diagnosis target to generate an ultrasound image. The ultrasound image to be displayed on a screen is divided into plural division regions and filtering is performed for the respective division regions based on blood-flow information at plural division positions on the diagnosis target corresponding to the respective division regions to provide the filtered result as the ultrasound image.
Systems and methods are disclosed for image reconstruction and enhancement using a computer system. One method includes acquiring a plurality of images associated with a target anatomy; determining using a processor one or more associations between subdivisions of localized anatomy of the target anatomy identified from the plurality of images and local image regions identified from the plurality of images; performing an initial image reconstruction based on image acquisition information of the target anatomy; and updating the initial image reconstruction or generating a new image reconstruction based on the image acquisition information and the one or more determined associations.
An image processing apparatus comprising: an acquiring unit configured to acquire a correction target image and user information indicating characteristics of a user requesting a correction; an image accumulating unit configured to accumulate images therein; an extracting unit configured to extract an image from the image accumulating unit based on the user information acquired by the acquiring unit the image matching the characteristics of the user requesting the correction; a setting unit configured to set a correction target value based on the image extracted by the extracting unit; and a correcting unit configured to correct the correction target image based on the correction target value.
A digital cinema signal is encoded to produce a resulting coded digital cinema bitstream. Decoding the resulting coded digital cinema bitstream allows backwards-compatible delivery of digital cinema content. A digital image or video signal is preprocessed to produce two normalized digital image or video signals of differing quality levels and forward and inverse mapping parameters which relate the normalized digital image or video signals. The preprocessing can be used prior to the encoding of a digital cinema signal to enable backwards-compatible delivery of digital cinema content.
An image processing apparatus includes a point spread function PSF pattern generation unit for generating a PSF pattern in which a plurality of PSFs are located in a plurality of lines of the PSF pattern; a PSF estimation unit for estimating PSFs of an out-of-focus input image from step responses of the plurality of lines of the PSF pattern with respect to an edge of the out-of-focus input image; and an image restoration unit for restoring the out-of-focus input image to a focused restored image using the estimated PSF.
The production of a cutting pattern of a graphic placed upon a cutting mat is disclosed. A source image of the graphic overlaid on a cutting mat is received and includes a plurality of registration marks as well as one or more distortions introduced during acquisition. The registration marks are identified from the source image by matching candidate sets of a plurality of center points of regions of adjacent groupings of pixels within the source image against predetermined positional relationships thereof corresponding to an actual arrangement of the registration marks on the cutting mat. An inverse transformation of the source image with values derived from the registration marks is applied. A corrected image aligned to physical coordinates of the cutting mat and referenced to the cutting machine is generated. A cut path is defined from vectors of the corrected image and transmitted to the cutting machine for execution thereon.
Focus assist systems and methods for imaging devices are provided. The focus assist systems and methods display focus level data to a user. There are a variety of methods of displaying focus level data to a user including but not limited to graphs highlights symbols and varied levels of brightness or color.
An apparatus and a method for generating a motion blur in a mobile terminal are provided. It is determined whether motion halting occurs during video shooting. If the motion halting occurs a motion vector of each block between first and second consecutive images where the motion halting has occurred is estimated. A motion blur is generated on the second image using the motion vector of each block and the motion-blurred image is displayed on a display unit.
A method for contrast enhancement for digital images including filtering an original image having original color values to generate a filtered image receiving parameters for a response curve the response curve being a function of color value that is user-adjustable deriving local multipliers by applying the response curve to the filtered image multiplying the original color values by the local multipliers thereby generating a contrast-enhanced image from the original image. A system and a computer-readable storage medium are also described.
Systems and methods for correcting saturation banding artifacts in magnetic resonance imaging in which artifact and reference calibration scans are used to create one dimensional or two dimensional correction profiles which are subsequently applied to actual diagnostic imaging scans to correct the saturation banding artifacts.
Color-correcting a digital image comprising P pixels P&#x2267;4 is presented. Each of the P pixels has a respective color. Color strengths of the P pixels are determined based at least on respective intensities respective saturations or both respective intensities and respective saturations of the P pixels. A subset of the P pixels less than all of the P pixels is determined. The pixels in the subset have respective color strengths in a range of respective color strength. All other pixels of the P pixels have respective color strengths outside of the range of respective color strengths. Color correction is determined for the P pixels based in part on the colors of the respective pixels in the subset which are the only pixels of the P pixels used for determining the color correction. The colors of the P pixels are corrected based on the color correction.
The present invention concerns a method and associated apparatus for improving the quality of digital imagery by detecting and correcting erroneous pixel values from image sensors such as those produced by stuck or dead pixels in a CCD or CMOS sensor. Anomalous pixel values are detected through comparisons with values of adjacent pixels and corrected selectively per channel through interpolation of adjacent pixel values.
A method and apparatus for processing an image that performs an online brightness change is disclosed the method including dividing a luminance channel in a reference image and a target image based on a size of a chroma channel enhancing an image quality of the target image in which the luminance channel is divided using the reference image in which the luminance channel is divided enhancing the image quality of an image of the luminance channel divided in the target image using the enhanced target image of which and combining the luminance channel of the enhanced target image and the luminance channel of which the image quality is enhanced.
Signals are provided which allow colors in a wider color range than predetermined standards which can be handled by apparatus according to such predetermined standards. A primary color converter converts first color signals having primary color points in a wider color range than the primary color points according to BT.709 into second color signals based on the primary colors according to BT.709. A photoelectric transducer converts the second color signals into third color signals according to photoelectric transducer characteristics defined in a numerical range wider than a range from 0 to 1.0 of color signals corresponding to a luminance signal and color difference signals according to BT.709. A color signal converter converts the third color signals into a luminance signal and color difference signals. A corrector incorporated in the color signal converter corrects the color difference signals into color difference signals.
In an image processing apparatus for carrying out a plurality of correction processes on an input image a multi-dimensional histogram of the input image is calculated and a feature amount of the input image for which a specific correction process has been carried out is analyzed based on the multi-dimensional histogram. Then based on the result of the analysis correction parameters to be used for another correction process are calculated.
A set of images is processed to modify and register the images to a reference image in preparation for blending the images to create a high-dynamic range image. To modify and register a source image to a reference image a processing unit generates correspondence information for the source image based on a global correspondence algorithm generates a warped source image based on the correspondence information estimates one or more color transfer functions for the source image and fills the holes in the warped source image. The holes in the warped source image are filled based on either a rigid transformation of a corresponding region of the source image or a transformation of the reference image based on the color transfer functions.
A visible image based on light output from a region to be observed by illumination of the region to be observed with visible light and a special image based on light output from the region to be observed by illumination of the region to be observed with special light in a wavelength band that is different from the wavelength band of the visible light are obtained. An extraction image is generated by extracting a part of image data representing the visible image. A superimposition image is generated by superimposing the generated extraction image on the special image. The generated superimposition image is displayed.
An image processing apparatus and method for restoring an image which is expected to be when there is no fog from a foggy image the image processing method including: generating a pixel depth image of the foggy image by estimating a plurality of pixel depths of a plurality of pixels respectively included in the foggy image based on a channel difference between at least two of red R green G and blue B channels of the foggy image; processing the pixel depth image; obtaining an optical model parameter with respect to the foggy image; and restoring an image which is expected to be when the foggy image does not include the fog by using the processed pixel depth image and the optical model parameter.
An image processing apparatus for applying a color balance correction to input image data comprises a holding unit which holds information indicating a locus of a change in highlight color when a color temperature for image data is changed on a color space; a highlight color calculation unit which calculates a highlight color from the image data; a distance calculation unit which calculates a distance between the highlight color and the highlight color locus held in the holding unit on the color space; a reliability calculation unit which calculates a reliability for a value of the highlight color calculated by the highlight color calculation unit in accordance with the distance calculated by the distance calculation unit; and a color balance correction unit which applies the color balance correction to the image data using the highlight color and the reliability.
The image processing method acquires an input image and information on an image capturing condition acquires an optical transfer function corresponding to the image capturing condition calculates a specific frequency at which an index value obtained by using the optical transfer function becomes a predetermined value in each azimuth direction and produces a window function to divide a frequency band of the input image into lower and higher frequency side bands than the specific frequency in each azimuth direction. Then the method produces by using the window function and the optical transfer function an image restoration filter to perform the image restoration process on the lower frequency side band of the input image and to restrict the image restoration process on the higher frequency side band thereof and performs the image restoration process using the image restoration filter.
An image processing apparatus is provided. The image processing apparatus includes an image mapping unit for generating a mapping image in which first radiation images of multi-energy bands with respect to a local region of a body are mapped to a second radiation image with respect to a thickness variable phantom an image analyzing unit for analyzing a reference region corresponding to normal tissue in the local region and a peculiar region corresponding to abnormal tissue in the local region based on the mapping image and an enhancement image generating unit for generating a tissue enhancement image that has a shape of the local region in the first radiation images and enhances regions of pixel positions that are mapped to the peculiar region of the first radiation images.
Embodiments and processes of computer tomography perform tasks associated with denoising a reconstructed image using an anistropic diffusion filter and adaptively weighting an iterative instance of the diffused image based upon the product of a weight value and a difference between the iterative instance of the diffused image and the original image. In general the adaptive weighting is a negative feedback in the iterative steps.
A method includes generating enhanced image data based on lower dose image data and a predetermined image quality threshold wherein an image quality of the enhanced image data is substantially similar to an image quality of higher dose image data and a system includes an image quality enhancer 128 that generates enhanced image data based on lower dose image data and a predetermined image quality threshold wherein an image quality of the enhanced image data is substantially similar to an image quality of higher dose image data.
A weighted image enhancement method includes receiving an original image. The original image includes several original pixels. The original image is sharpened to generate a sharpened image. The sharpened image includes several sharpened pixels. Edge detection is performed with respect to the original image to generate a probability of whether each original pixel is on an edge. An enhancement mode setting is received. A corresponding weight table corresponding to the enhancement mode setting is looked up to obtain a corresponding enhancement weight of each original pixel according to the probability of whether each original pixel is on an edge. A weight calculation is performed utilizing each original pixel and its corresponding sharpened pixel according to its corresponding enhancement weight to generate an enhanced image. The enhanced image is displayed by a display unit.
The disclosure generally relates to dual-energy imaging and in particular techniques to produce and process dual-energy images using a dual-energy imaging system. One embodiment provides a method for generating at least one image of a region of interest in a patient the method comprising: obtaining at least two radiological images of the region of interest identified with at least one marker arranged on and/or around the patient wherein a first image is acquired with a first X-ray energy and a second image is acquired with a second X-ray energy; and determining a final radiological image of the region of interest by linearly combining the two radiological images to obtain an image without the markers.
An apparatus and method are disclosed for improving imaging based on a time-series of images. In one embodiment a time-series of images are acquired using a same imaging protocol of the same subject area but the images are spaced in time by one or more time intervals e.g 1 2 3 . . . seconds apart . A sub-region is projected across all of the images to perform a localized analysis corresponding X-Y pixels or X-Y-Z voxels are analyzed across all images that identifies temporal components within each sub-region. In some of the sub-regions the temporal components are removed when the amplitude of the component is below a predetermined amplitude threshold. The images are then combined using the sub-regions with reduced components in order to obtain a single image with reduced noise.
An image processing method includes inputting input image data captured by an imaging unit generating an input histogram of the input image data based on the input image data and correcting the input image data based on noise characteristics data and the input histogram wherein the noise characteristics data includes data indicating probability of a first characteristic value becoming a second characteristic value due to noise.
An apparatus and method creating a ghost-free High Dynamic Range Image HDRI based on filtering are provided. It is possible to effectively prevent a ghost phenomenon from occurring when a single HDRI is created from a plurality of LDRIs by defining a ghost area using a probability based on a global transfer function indicating a relationship for intensities of several frames rather than searching for or identifying a ghost area in a single or each image.
A system and method to capture a plurality of images and store the captured images. The system has multiple camera systems capable of transmitting image data. At least one camera system is equipped with an apparatus for determining location coordinates such as GPS. A computer system monitors location coordinates retrieves image data from the camera systems and stores the image data into a file. A contiguous array of location coordinates is entered and the computer system locates camera systems within the contiguous array of location coordinates; retrieves image data from the located camera systems; and files the image data taken from each of the camera systems to obtain a file of image data. The system provides the ability to serially interleave frames or video captured from multiple sources.
A system and method for automatic contrast enhancement for contouring. The system and method including displaying a volumetric image slice to be analyzed receiving a delineation of a target anatomic structure in the volumetric image slice identifying a region of interest based upon an area being delineated in the volumetric image slice analyzing voxel intensity values in the region of interest and determining an appropriate window-level setting based on the voxel intensity values.
Methods and systems for digitally enhancing an initial image of a material to which a plurality of stains were previously applied that generally comprise: unmixing the image into a plurality of individual reconstructed images each individual image corresponding to one of the stains; estimating a residual image corresponding to the difference between the original image and the reconstructed images; adjusting one or more components of the individual images; mixing the adjusted components using one or more estimated mixing coefficients; and adding the residual image to the mixed adjusted components to generate an enhanced image.
A system uses range and Doppler velocity measurements from a lidar system and images from a video system to estimate a six degree-of-freedom trajectory 6DOF of a target. The 6DOF transformation parameters are used to transform multiple images to the frame time of a selected image thus obtaining multiple images at the same frame time. These multiple images may be used to increase a resolution of the image at each frame time obtaining the collection of the superresolution images.
A device and method for generating RGB arrangement data from an imaging signal by a photograph imaging device having an RGBW arrangement are provided. An edge detection unit analyzes an output signal in the RGBW arrangement from the imaging device and thus obtains edge information corresponding to each pixel and a texture detection unit generates texture information. Furthermore a parameter calculation unit performs an interpolation process of converting an application pixel position according to the edge direction corresponding to a conversion pixel. A blend process unit inputs a parameter which the parameter calculation unit generates edge information and texture information and determines a conversion pixel value by performing a blend process by changing a blend ratio of the parameter which the parameter calculation unit calculates according to the edge information corresponding to the conversion pixel and the texture information.
A magnetic resonance image MRI data array representing an image is filtered in k-space Fourier space domain to produce a low-pass filtered data array a band-pass filtered data array and a high-pass filtered data array. These filtered k-space arrays are two-dimensionally Fourier-Transformed into the image domain where the magnitude of the band-pass filtered data array is thresholded and feathered to produce a fuzzy continuous valued &#x201c;gray-scale&#x201d; edge mask data array and the real part of the high-pass filtered data array may if desired be soft-thresholded to produce a soft thresholded sharpening mask data array. The edge mask data array is multiplied with the sharpening mask data array and the result is added to the magnitude of the low-pass filtered data array in the image domain to produce a Gibbs ringing and noise-filtered image to better represent the underlying anatomy.
The present invention relates to a method of performing dynamic contrast enhanced magnetic resonance imaging of an object 10 with signal separation for water and fat the method comprising acquiring magnetic resonance datasets in the k-space using Dixon acquisition in a chemical shift encoding space and dynamic time resolution in a dynamic time space wherein the dataset acquisition is performed employing undersampling wherein the method further comprises: applying a compressed sensing reconstruction technique in the k-space the chemical shift encoding space and the dynamic time space said compressed sensing reconstruction resulting in reconstructed datasets &#x2014;performing Dixon reconstruction on the reconstructed datasets and dynamic contrast analysis on the Dixon reconstructed datasets.
Methods and apparatus according to various aspects take as input image data in a lower-dynamic-range LDR format and produce as output enhanced image data having a dynamic range greater than that of the input image data i.e. higher-dynamic range HDR image data . In some embodiments the methods are applied to video data and are performed in real-time i.e. processing of video frames to enhance the dynamic range of the video frames is completed at least on average at the frame rate of the video signal .
System and method for image improvement comprising providing a series of frames; summing pixel values to obtain frame intensity; computing average frame intensity; determining frame intensity deviation for each frame by subtracting average frame intensity from frame intensity; determining an array of average pixel values AAPV and subtracting AAPV from the pixel value arrays to determine positive or negative pixel deviation values; grouping frames in first or second groups depending positive or negative frame intensity deviation; selecting all pixel values having a positive or negative deviation value and creating subgroups of positive or negative pixel deviation value frames multiplying the pixel deviation value frames in each subgroup by frame intensity deviation to create first product arrays which are summed together and divided by total number of frames to obtain second product arrays for each subgroup; selecting one or more of second product arrays to generate an image.
A display apparatus with an image-capturing function includes an outputting unit configured to output an image signal to an external apparatus an inputting unit configured to input an image signal from the external apparatus an image-capturing unit a display unit an image-capture-distortion corrector configured to perform image-capture-distortion correction on an image signal captured by the image-capturing unit a display-distortion corrector configured to perform display-distortion correction and a controller configured to control whether or not the image-capture-distortion corrector is to perform the image-capture-distortion correction and whether or not the display-distortion corrector is to perform the display-distortion correction. Therefore distortion caused by the image-capturing system and display system of the display apparatus with an image-capturing function can be appropriately corrected in the overall system including the display apparatus with an image-capturing function and the external apparatus.
An image processing apparatus including a dispersion calculation portion an &#x3b5; deriving portion and a filtering portion and eliminates mosquito noise from a digitally compressed image having a plurality of color components. The dispersion calculation portion is configured to calculate for each of the color components of each pixel contained in the digitally compressed image a dispersion of pixel values of a plurality of pixels contained in a first region in which that pixel serves as a representative pixel. The &#x3b5; deriving portion is configured to derive for each pixel contained in the digitally compressed image a greatest value of the plurality of dispersions that respectively correspond to the plurality of color components of that pixel or a corrected value of the greatest value as an &#x3b5; value of an &#x3b5; filter for that pixel. The filtering portion is configured to apply the &#x3b5; filter to the digitally compressed image.
An image processing apparatus and an image processing method are provided. A storage unit of the image processing apparatus stores an image and a piece of intensity statistical information of the image. The piece of intensity statistical information records that the image has a first number of pixels having a first intensity value a second number of pixels having a second intensity value and a third number of pixels having a third intensity value. A micro-processing unit of the image processing unit calculates a centralization degree of the second intensity value in the image according to the first number the second number and the third number. If the centralization degree is greater than a threshold the micro-processing unit adjusts the intensity value of a pixel having the second intensity value in the image according to the second intensity value and the intensity value of the at least one neighboring pixel of the pixel.
A method of removing coding artifacts in first and second processed edges that are processed edges in an image signal and in different directions includes: determining based on at least pixel values of first adjacent pixels adjacent to the first processed edge a first target pixel from which coding artifacts are to be removed for the first processed edge S11 ; removing coding artifacts from the determined first target pixel S13 ; determining based on at least pixel values of second adjacent pixels adjacent to the second processed edge a second target pixel from which coding artifacts are to be removed for the second processed edge S12 ; and removing coding artifacts from the determined second target pixel S14 wherein at S12 the second target pixel is determined based on pixel values of the second adjacent pixels from which the coding artifacts are not removed at S13.
A method of multi-frame image noise reduction suitable for an image-capturing device includes following steps: obtaining a current frame and multiple reference frames; defining a mask and a target point in the mask; judging whether the target point pixel of the current frame is on an edge according to an edge map of the frame; when the pixel is on the edge using the pixels in the reference frames on the edge to calculate a replacement result; when the target point pixel is not on the edge using the pixels in the reference frames surrounding the target point to calculate a replacement result; after that generating a pixel corresponding to the position of the target point in an output image according to the replacement result; further moving the mask and going back to judge whether the pixel of the target point of the current frame is on the edge.
An image processing apparatus includes a relative coordinate acquiring portion for acquiring a corresponding position over the input image to a predetermined pixel in a rectangular region obtained by dividing the output image a reference region specifying portion for specifying a reference region including a corresponding region over the input image of the rectangular region for a plurality of rectangular regions arranged continuously over the output image respectively a reading region determining portion for merging each reference region related to each of the rectangular regions thereby obtaining a merging region reading control means for reading a pixel value of each pixel included in the merging region in the input image and correction processing means for executing the distortion correction processing by using a pixel value of a pixel which is read through the reading control means thereby acquiring a pixel value of the output image.
An image processing apparatus includes a calculation unit configured to calculate a first gain for adjusting brightness of a first image and a second image based on the first image captured at a first exposure amount and the second image captured at a second exposure amount a division unit configured to divide the first gain into a second gain which changes according to a position in an image and a third gain which does not change according to a position in an image a first gain correction unit configured to perform gain correction on the second image with the second gain and a second gain correction unit configured to perform gain correction on the second image with the third gain.
The present invention discloses a method for establishing evaluation standard parameters and method for evaluating the quality of a display image wherein the method comprises: taking pictures to a group of test images having different color shift severity degrees to obtain a sample picture group; selecting a standard picture by human eye; applying the Fourier transform to tristimulus values of all pictures; respectively applying convolution to the frequency distribution function corresponding to each primary color with a contrast sensitivity function of human eye; respectively normalizing to each of the convolution functions; and selecting the evaluation parameters of the three primary colors of the standard picture as the evaluation standard parameters. The present invention can obtain more objective and systemic evaluation standard parameters.
In some implementations a method provides color correction in images and includes determining multiple input groups of pixels of an image based on one or more pixel attributes of the pixels. Each of the input groups includes different pixels of the image than the other input groups. The method determines an individual neutral color associated with each of the input groups of pixels based on the colors of the pixels in the associated input group. An individual color correction associated with each of a number of output groups of pixels is determined based on one or more neutral colors associated with the input groups. The method applies each individual color correction to its associated output group of pixels including adjusting the color of pixels in each output group to reduce color casts on the pixels.
A contour correction device is provided having a video image judging unit which executes an edge detection process to detect a change of a signal in a video image as an edge portion and a texture detection process to detect a texture portion in which a change of signal smaller than the edge portion in the video image repeatedly appears and a contour component gain adjusting unit which applies contour correction processes which differ from each other to the edge portion and the texture portion.
Image tone adjustment using local tone curve computation may be utilized to adjust luminance ranges for images. Image tone adjustment using local tone curve computation may reduce the overall contrast of an image while maintaining local contrast in smaller areas such as in images capturing brightly lit scenes where the difference in intensity between brightest and darkest areas is large. A desired brightness representation of the image may be generated including target luminance values for corresponding blocks of the image. For each block one or more tone adjustment values may be computed that when jointly applied to the respective histograms for the block and neighboring blocks results in the luminance values that match corresponding target values. The tone adjustment values may be determined by solving an under-constrained optimization problem such that optimization constraints are minimized. The image may then be adjusted according to the computed tone adjustment values.
An image display apparatus that displays an image on the basis of input image signals corresponding to sub-pixels forming one pixel includes a shift-amount storing unit that stores shift amounts of display positions of the sub-pixels relative to given reference positions in a display image an image-signal correcting unit that corrects the input image signals according to the shift amounts and an image display unit that displays an image on the basis of the image signals corrected by the image-signal correcting unit.
A method is disclosed that includes receiving multiple sequential images captured by an image capture device. The method includes selecting a subset of the multiple sequential images that are aligned to each other. The method further includes averaging pixel values from each image in the subset of the multiple sequential images to produce a combined image.
A method for enhancing a three-dimensional 3D image comprising at least two depth layers wherein each depth layer comprising image objects. The method comprising the steps of determining a near field and a far field comprising at least one depth layer each identifying the image objects in the near field and the far field respectively applying a first correction curve to the image objects identified in the near field and applying a second correction curve to the image objects identified in the far field.
Disclosed is an image processing apparatus for converting an original image. Processing of blurring an input original image is performed to generate a blurred image. A difference image that is the difference between the original image and an adjusted image obtained by adjusting the density of the blurred image is generated. The difference image and the original image are composited based on the density of the difference image and the density of the original image. This allows to easily obtain a painting-like effect even in for example a low-contrast portion of an image.
A system and method for enhancing a content file is disclosed. The system comprises a histogram module a contrast stretching module and a brightness module. The histogram module generates a histogram including data that describes one or more pixel intensities for one or more channels included in a content file. The contrast stretching module adjusts the one or more pixel intensities for the one or more channels included in the content file based at least in part on the histogram. The brightness module is communicatively coupled to the contrast stretching module for determining whether a brightness level for the content file is within a range describing one or more acceptable brightness levels. The brightness module adjusts the brightness level for the content file responsive to determining that the brightness level for the content file is outside the range.
Photon starvation causes streaks and noise and seriously impairs the diagnostic value of the CT imaging. To reduce streaks and noise a new scheme of adaptive Gaussian filtering relies on the diffusion-derived scale-space concept in one embodiment of the current invention. In scale-space view filtering by Gaussians of different sizes is similar to decompose the data into a sequence of scales. As the scale measure the variance of the filter linearly relates to the noise standard deviation of a predetermined noise model in the new filtering method. The new filter has only one optional parameter that remains stable once tuned. Although single-pass processing using the new filter generally achieves desired results iterations are optionally performed.
An image display apparatus that displays an image on the basis of input image signals corresponding to sub-pixels forming one pixel includes a shift-amount storing unit that stores shift amounts of display positions of the sub-pixels relative to given reference positions in a display image an image-signal correcting unit that corrects the input image signals according to the shift amounts and an image display unit that displays an image on the basis of the image signals corrected by the image-signal correcting unit.
A method is disclosed that includes receiving multiple sequential images captured by an image capture device. The method includes selecting a subset of the multiple sequential images that are aligned to each other. The method further includes averaging pixel values from each image in the subset of the multiple sequential images to produce a combined image.
A method for enhancing a three-dimensional 3D image comprising at least two depth layers wherein each depth layer comprising image objects. The method comprising the steps of determining a near field and a far field comprising at least one depth layer each identifying the image objects in the near field and the far field respectively applying a first correction curve to the image objects identified in the near field and applying a second correction curve to the image objects identified in the far field.
Disclosed is an image processing apparatus for converting an original image. Processing of blurring an input original image is performed to generate a blurred image. A difference image that is the difference between the original image and an adjusted image obtained by adjusting the density of the blurred image is generated. The difference image and the original image are composited based on the density of the difference image and the density of the original image. This allows to easily obtain a painting-like effect even in for example a low-contrast portion of an image.
A system and method for enhancing a content file is disclosed. The system comprises a histogram module a contrast stretching module and a brightness module. The histogram module generates a histogram including data that describes one or more pixel intensities for one or more channels included in a content file. The contrast stretching module adjusts the one or more pixel intensities for the one or more channels included in the content file based at least in part on the histogram. The brightness module is communicatively coupled to the contrast stretching module for determining whether a brightness level for the content file is within a range describing one or more acceptable brightness levels. The brightness module adjusts the brightness level for the content file responsive to determining that the brightness level for the content file is outside the range.
Photon starvation causes streaks and noise and seriously impairs the diagnostic value of the CT imaging. To reduce streaks and noise a new scheme of adaptive Gaussian filtering relies on the diffusion-derived scale-space concept in one embodiment of the current invention. In scale-space view filtering by Gaussians of different sizes is similar to decompose the data into a sequence of scales. As the scale measure the variance of the filter linearly relates to the noise standard deviation of a predetermined noise model in the new filtering method. The new filter has only one optional parameter that remains stable once tuned. Although single-pass processing using the new filter generally achieves desired results iterations are optionally performed.
Imaging methods and systems providing wavelength diversity compensation to images distorted by turbulence includes capturing a subject image set in a single image frame with the images in the set being captured at diverse wavelengths. The compensation includes using an error metric insensitive to variation in object brightness between a region of interest of an image and a corresponding region of interest in a second image in the set that is at a diverse wavelength.
An image processing apparatus includes: a line noise detection section for detecting line noise pixels included in input image data; a segmentation process section for determining a pixel in a text region; and a line noise removal process section for i determining a replacement-target line noise pixel by excepting from the line noise pixels the pixel in the text region and a pixel within a first distance from the pixel in the text region and ii replacing the replacement-target line noise pixel with another pixel other than the line noise pixels which another pixel is included in the input image data.
A method for estimating signal-dependent noise includes defining a plurality of pixel groups from among the image pixels. The method further includes computing for one or more signal levels of the image a difference value between two pixel groups whereby a respective one or more difference values are computed collectively. The method determines an estimated noise response of the image as a function of the one or more computed difference values.
An image processing device performs image processing on image data obtained by receiving light emitted from a light source and then reflected from an object to be read with a light receiving element. The image processing device includes a determination unit configured to determine whether or not a color of each pixel in the image data belongs to a predetermined correction target color range and a correction unit configured to perform correction to reduce the density of a pixel of the color belonging to the correction target color range.
An image enhancement method for improving color perception of colorblind viewers has an image input step an image difference area analyzing step an image color distribution adjusting step and an image output step. In such method a normal image and a colorblindness-simulative image are input and calculated to produce a colorblindness-optimized image. Color vision obtained by a colorblind person from the colorblindness-optimized image is substantially identical to that obtained by a person with normal color perception from the normal image.
According to one embodiment an image processing apparatus includes following units. The correlation calculation unit calculates correlations between a first region and predetermined first basis vectors. The distance calculation unit calculates distances between the first region and second regions on a subspace generated by the second basis vectors selected from the first basis vectors. The feature quantity calculation unit calculates a feature quantity based on the correlations. The weight calculation unit calculates weights based on the distances and the feature quantity. The pixel value calculation unit calculates a weighted average of pixel values according to the weights to generate an output pixel value.
Disclosed is an apparatus to blend a high dynamic range HDR image or a plurality of images captured with different exposure settings to multiple images and a method thereof. A multiple image blender receives a high dynamic range HDR image or a plurality of images captured with different exposure settings and controls setting of one or more areas of interest or setting of one or more gradation levels and combines and blends the HDR image or the plurality of images captured with different exposure settings corresponding to each area of interest or at each gradation level and generates at least one multi-exposure image.
Techniques for generating a preview image in an image editing application in response to detecting user input that changes the value of an adjustable parameter of a digital image undergoing adjustment. According to one technique instead of processing the digital image through a filter chain to generate an updated preview image a blended image is generated through interpolation of two previously generated versions of the digital image. The previously generated versions may be generated through the filter chain. The blended image may be generated in a shorter amount of time in response to the user s adjustment than the time needed to process the digital image through the filter chain. Thus the current preview image may be updated with the blended image sooner than is possible if the current preview image is updated by processing the digital image through the filter chain.
A technique of enhancing a scene containing one or more off-center peripheral regions within an initial distorted image captured with a large field of view includes determining and extracting an off-center region of interest hereinafter &#x201c;ROI&#x201d; within the image. Geometric correction is applied to reconstruct the off-center ROI into a rectangular or otherwise undistorted or less distorted frame of reference as a reconstructed ROI.
A first image stream has a first dynamic range and a first color space. First and the second image streams are received in a layered codec. The second image stream has a second dynamic range which is higher than the first dynamic range. The first image stream is in the codec s base layer; the second image stream is in its enhancement layer. The first image stream is encoded to obtain an encoded image stream which is decoded to obtain a decoded image stream. The decoded image stream is converted from the first non-linear or linear color space to a second different color space to obtain a color converted image stream. A higher dynamic range image representation of the color converted image stream is generated to obtain a transformed image stream. Inverse tone mapping parameters are generated based on the transformed image stream and the second image stream.
An image processing apparatus includes a first acquisition unit configured to obtain identification information for a plurality of blocks of an image a second acquisition unit configured to obtain information to be used for image processing from a pixel value of a region of the image determined based on the identification information and an image processing unit configured to perform image processing of the image based on the information obtained by the second acquisition unit.
In some implementations a method includes identifying one or more face regions of an image the face regions including pixels that depict at least a portion of one or more faces of persons. The face regions are identified based on identifying facial landmarks of the faces. The method determines an associated face mask for each of the faces based on the face regions where each face mask indicates which pixels in the image depict the corresponding face. Face pixels can be selected for processing by applying the face masks and image pixels outside the faces can be selected by inversely applying the face masks. The selected pixels can be provided to a processing operation for adjustment of the selected pixels.
A system for editing a digital image comprises a low pass filter for receiving a source image and for filtering high spatial frequency components of the source image to generate a smoothed image. An arithmetic operator unit subtracts color values of the smoothed image from color values of the source image to produce a first image value on pixel-by-pixel basis. A gradient reversal analyzer compares gradient values of the smoothed image to gradient values of the source image and generates a control signal. A boost controller generates a new value for each pixel of a boost parameter map according to the control signal. The boost controller applies the boost parameter map to modify the first image value to generate a second image value. The arithmetic operator unit is further configured to generate an edge enhanced image according to color values of the source image and the second image value.
In some implementations of edge-aware smoothing a method includes determining a boundary map for an input image where the boundary map associates one of multiple different labels to each pixel of the input image and the labels indicate one or more edges in the input image. The method determines a set of input pixels of the input image eligible to influence an output pixel of an output image the output pixel corresponding to a pixel of the input image. A blurred pixel value for the output pixel is determined where the blurred pixel value is based on the set of input pixels and associated labels from the boundary map that correspond to the set of input pixels. The associated labels are used to reduce blurring in the output image of any of the one or more edges present in the set of input pixels.
A computer-implemented method for automatically retrieving information regarding optical properties of a scattering medium including receiving a first digital image and a first image quality value associated with the first digital image and sharpness of an edge of the first digital image producing an optimized image transforming the optimized image into an optimized optical transfer function receiving a second digital image and a second image quality value associated with the second digital image and sharpness of an edge of the second digital image identifying either the first or second digital image as an optimized digital image and transforming the optimized optical transfer function into an optimized value of the optical parameter.
A method includes implementing through a processor communicatively coupled to a memory and/or a hardware block a Bilateral Filter BF including a spatial filter component and a range filter component and implementing the spatial filter component with a low-complexity function to allow for focus on the range filter component. The method also includes determining through the processor filter tap value s related to the range filter component as a function of radiometric distance between a pixel of a video frame and/or an image and other pixels thereof based on a pre-computed corpus of data related to execution of an application in accordance with a filtering requirement of the pixel by the application. Further the method includes constraining through the processor the filter tap value s to a form i&#xd7;base based on the BF implementation. i is an integer and base is a floating point base.
Techniques and tools are described for performing perspective correction using a reflection. Reflective properties of a surface being photographed can be used to determine a rotation of the device taking the photograph relative to the surface. Light sourced or produced by the device can be used to create a reflection spot in the picture. A position of the reflection spot within the picture is calculated and used to determine the rotation. The rotation can be used for performing perspective correction on the picture or on another picture taken by the device.
A method and apparatus are provided to generate automatically a mip-map chain of texture images from a portion of texture image data such that it may be used in texturing a computer graphic image. A portion of the texture image data is stored temporarily and is filtered to generate at least one lower level of mip-map data from the texture data. This lower level of mip-map texture image data is then stored for use in texturing. Preferably these are stored on a tile-by-tile basis where a tile is a rectangular area of the image being displayed.
An image processing device for generating a composite image using multi-viewpoint image data before color interpolation captured by a camera array image capturing device includes a unit configured to acquire information of a pixel value and a pixel position in the multi-viewpoint image data a pixel position determination unit configured to determine the pixel position in the composite image in the pixel position of each pixel of the multi-viewpoint image data in accordance with an arbitrary focus position based on optical parameters at the time of the image capturing a color derivation unit configured to derive the color of each pixel of the multi-viewpoint image data and a pixel value calculation unit configured to calculate the pixel value of each pixel of the composite image using the determined pixel position in the composite image and the pixel value of the multi-viewpoint image data corresponding to the derived pixel color.
An image composition apparatus 1 is provided with an information acquisition section 53 an image adjustment section 54 and a synthesis section 56. The information acquisition section 53 acquires numerical values relating to brightness of image regions with a particular hue in corrected exposure image data among plural sets of image data that are sequentially captured with the exposure duration being varied. The synthesis section 56 performs pixel addition of the plural sets of image data by changing a degree of addition of the plural sets of image data based on the numerical values thus acquired and generates composite image data with a widened dynamic range.
A phase retrieval method for differential phase contrast imaging includes receiving data corresponding to a differential phase image generated from a measured signal. The measured signal corresponds to an X-ray signal detected by a detector after passing through a subject located with a grating arrangement between an X-ray source and the detector. The method further includes generating a phase image corresponding to the integration of the differential phase image. Generating the phase image includes performing an iterative total variation regularized integration in the Fourier domain.
A Mixed Media Reality MMR system and associated techniques are disclosed. The MMR system provides mechanisms for forming a mixed media document that includes media of at least two types e.g. printed paper as a first medium and digital content and/or web link as a second medium . The present invention provides a system method and computer program product for creating an ad hoc association between users. Captured digital images of paper documents or portions associated with a user are received. Document recognition features are extracted from the captured digital image. An ad hoc association is created between the user and another user associated with an existing document recognition feature similar to the extracted document recognition features.
A method for enhancing functional image data includes obtaining functional image data obtaining anatomical image data corresponding to the functional image data and generating enhanced functional image data by diffusing the functional image data based on the functional image data and the anatomical image data.
An image processing apparatus includes an attention region estimation unit that estimates an attention region which is estimated as a user paying attention thereto on a stereoscopic image a parallax detection unit that detects a parallax of the stereoscopic image and generates a parallax map indicating a parallax of each region of the stereoscopic image a setting unit that sets conversion characteristics for correcting a parallax of the stereoscopic image based on the attention region and the parallax map and a parallax conversion unit that corrects the parallax map based on the conversion characteristics.
An apparatus and method for generating a High Dynamic Range HDR image from which a ghost blur is removed based on a multi-exposure fusion. The apparatus may include an HDR weight map calculation unit to calculate an HDR weight map for multiple exposure frames that are received a ghost probability calculation unit to calculate a ghost probability for each image by verifying a ghost blur for the multiple exposure frames an HDR weight map updating unit to update the calculated HDR weight map based on the calculated ghost probability and a multi-scale blending unit to generate an HDR image by reflecting the updated HDR weight map to the multiple exposure frames.
Embodiments of the present disclosure include methods apparatuses and systems for identifying regions to be filtered during processing of an image. A map generator is configured to receive pixels of an image and to determine a map for the image. The map indicates a number of islands within blocks of pixels of the image where individual ones of the islands include either a single dark pixel or two or more contiguous dark pixels bordered by light pixels and/or one or more edges of the blocks of pixels. An index generator sets based at least on the number of islands within the individual ones of the blocks of pixels that correspond to regions of the scanned image filter indices for the regions of the scanned image. An image filter component based on the filter indices filters the regions of the scanned image.
A symmetric filter arithmetic apparatus includes a first data shuffling unit which reads a first data string that is a plurality of consecutive pieces of data from a register file and extract from the first data string a left-side data string that is a plurality of consecutive pieces of data to be multiplied by a left-side filter coefficient that is a filter coefficient on a left side of a center of the coefficients and a second data shuffling unit which reads a second data string that is a plurality of consecutive pieces of data from the register file and extract from the second data string a right-side data string that is a plurality of consecutive pieces of data to be multiplied by a right-side filter coefficient that is a filter coefficient on a right side of the center and is the same value as the left-side filter coefficient.
Described are methods systems and apparatus including computer program products for locating one or more markers associated with IT equipment. An image of a scene including the one or more markers is acquired by a mobile computing device. A band-pass filter is applied by the mobile computing device to first pixel data associated with a first pixel in the image to generate a first band-pass filter result wherein a pass-band of the band-pass filter is based on the light emitted by the one or more markers. A first pixel score is determined by the mobile computing device based on at least the first band-pass filter result. First indicia of the first pixel score is stored by the mobile computing device in a map at a first map location corresponding to a first image location of the first pixel in the image.
An image processing apparatus includes: a data storage section configured to store image data as a density image containing a fingerprint or a palm print and ridge pattern direction distribution data which shows a direction distribution of a ridge pattern in a fingerprint or a palm print; a direction usage image enhancing section configured to execute ridge direction usage image enhancement processing on the density image based on the ridge pattern direction distribution data; and a direction extracting section configured to extract a first direction distribution of a first pattern which is contained in a ridge direction usage image enhanced image from the ridge direction usage image enhanced image as a result of the ridge direction usage image enhancement processing to the density image. The direction usage image enhancing section executes first direction usage image enhancement processing on the density image based on first direction distribution data which shows a first direction distribution.
A digital image processing apparatus and method are provided. The digital image processing apparatus includes: a Y component processing unit receiving a Y component and performing edge enhancement processing and first noise reduction processing on the Y component by using a memory allocated to the Y component; and a CbCr processing unit receiving a Cb component and a Cr component and performing false color suppression processing and second noise reduction processing on the Cb component and the Cr component by using a memory allocated to the Cb component and the Cr component where the Y component the Cb component and the Cr component are variables of the YCbCr color space.
An image processing module is provided. A de-mosaic unit in the image processing module includes an edge direction detection unit and a multi-pixel directional interpolation unit. The edge direction detection unit is used to determine a first color row luminance difference according to a plurality of first color pixels of a pixel row of raw data and determine a first color column luminance difference according to a plurality of first color pixels of a pixel column of raw data. The multi-pixels directional interpolation unit is used to determine pixel luminance of a third color array according to the first color column luminance difference the first color row luminance difference the third color pixels adjacent to a first color pixel and the third color pixels adjacent to a second color pixel.
An adaptive filter includes: an edge direction detection section which discriminates directionality of an input image in each of a plurality of unit regions constituting the input image; a region classification section which classifies the each of the plurality of unit regions into one of a plurality of unit region groups in accordance with to which of a plurality of predetermined groups the directionality of the input image in the each of the plurality of unit regions belongs the directionality having been discriminated by the edge direction detection section; and a filter process section which calculates a pixel value of the each pixel of an output image by use of a filter coefficient group optimized for a unit region group to which a unit region including the each pixel belongs.
A method and apparatus for deblurring a non-uniform motion blur using a multi-frame including a blurred image and a noise image is provided. The apparatus may provide a clearer image by estimating non-uniform motion blur information of the blurred image using the multi-frame and performing estimation of the non-uniform motion blur information and obtaining of a latent image iteratively thereby improving accuracy for estimating the non-uniform motion blur information and reducing a processing time.
A structure descriptor for an m&#xd7;n pixel block of an image may be determined. The m&#xd7;n pixel block may contain a primary pixel having a primary pixel value and a plurality of secondary pixels having respective secondary pixel values. The structure descriptor may include a plurality of structure indicators each associated with a respective secondary pixel. The respective structure indicators may be based on the primary pixel value and the respective secondary pixel value of the associated secondary pixel. Based on the structure descriptor a structure value for the m&#xd7;n pixel block may be determined. Based on the structure value image processing may be applied to the m&#xd7;n pixel block.
Reference-free compensated imaging makes an estimation of the Fourier phase of a series of images of a target. The Fourier magnitude of the series of images is obtained by dividing the power spectral density of the series of images by an estimate of the power spectral density of atmospheric turbulence from a series of scene based wave front sensor SBWFS measurements of the target. A high-resolution image of the target is recovered from the Fourier phase and the Fourier magnitude.
A method for reconstructing an image of an object includes acquiring a set of measured projection data reconstructing the measured projection data using a first algorithm to generate a first reconstructed image dataset reconstructing the measured projection data using a second algorithm to generate a second reconstructed image dataset the second algorithm being utilized to improve the temporal resolution of the second reconstructed image dataset and generating a final image dataset using both the first and second image datasets.
A temporal noise reduction method and a temporal noise reduction device are provided. The temporal noise reduction device includes a temporal filter unit that performs a temporal filtering operation using pixel values CP of an N&#xd7;M array in a current frame and pixel values FP of an N&#xd7;M array located at the same position in a neighboring frame separated by a distance TP from the current frame and a motion filter unit that detects a motion of a pixel image from the resultant values of the temporal filter unit and that eliminates noise of a motion-abundant pixel value using a spatial filter. It is possible to effectively reduce noise of an image to prevent deterioration in image quality of the image and to improve performance of post-processing techniques.
The present disclosure relates to image filtering techniques for enhancing image quality. In one embodiment two filtering techniques are applied on an image. Firstly an adaptive weighted median filtering operation is performed on an acquired low contrast image corrupted by impulsive noise. Subsequently a guided image filtering on the image obtained from adaptive weighted median filtering operation to de-blur and enhance the contrast that ultimately assures to preserve the edges of the images. In addition the image filtering for enhancing image quality is enhanced by several variations of data adaptive guided image filtering and adaptive window sizes for guided image filtering techniques.
Disclosed are a depth image noise removal apparatus based on a camera pose which includes: a depth image obtaining unit for obtaining a plurality of depth images; a camera pose converting unit for converting camera poses of the plurality of depth images into a camera pose of a reference depth image; and a depth image filtering unit for filtering the reference depth image by using a weighted average of each pixel of the reference depth image and a method using this apparatus.
A system for enhancing an input image including receiving an input image and filtering the input image with a plurality of non-linear smoothing filters providing a respective plurality of filtered outputs. The system processes a plurality of the filtered outputs with respect to at least one of another of the filtered outputs and the input image to determine a plurality of detail layers. The system filters the plurality of detail layers with a plurality of non-linear smoothing filters providing a respective plurality of smoothed layers. The system adjusts the plurality of smoothed layers in such a manner that regions closer to an edge are enhanced to a lesser extent than regions farther from an edge and combining the adjusted the smoothed layers to provide an enhanced output image.
An image may be processed to normalize and/or remove noise from the image. The processing of the image may involve decomposition of the image into multiple components and subsequent gray scale registration across multiple scales.
A denoising apparatus comprising an image input unit which receives pixel data including color information of pixels included in a correction target image a denoising unit which denoises the pixel data by a weight based averaging method wherein the weight is set to a maximum value when a difference value between a correction target block and a comparison target block in the correction target image is zero decreases linearly to zero as the difference value increases until it reaches a threshold value and is set to zero when the difference value is greater than or equal to the threshold value and an image output unit which outputs the pixel data processed by the denoising unit. The denoising unit assigns a corrected weight value to at least a guaranteed number of comparison target blocks for an impulse block where an impulse block is a correction target block for which the number of non-zero weight valued comparison target blocks is less than a predetermined guaranteed number.
Devices systems apparatuses methods and other embodiments associated with bit resolution enhancement are described. In one embodiment an apparatus includes logic configured to produce a high-resolution pixel from a low-resolution pixel. The apparatus includes logic configured to classify the high-resolution pixel as being in a smooth region of an image based on at least one of a gradient value and a variance value associated with the low-resolution pixel. The apparatus includes logic configured to selectively re-classify the high-resolution pixel as not being in the smooth region of the image based on a set of neighboring high-resolution pixels associated with high-resolution pixel. The apparatus includes logic configured to selectively filter the high-resolution pixel based on whether the high-resolution pixel remains classified as being in the smooth region of the image.
Sub-regions within a face image are identified to be enhanced by applying a localized smoothing kernel to luminance data corresponding to the sub-regions of the face image. An enhanced face image is generated including an enhanced version of the face that includes certain original pixels in combination with pixels corresponding to the one or more enhanced sub-regions of the face.
An image processing method of performing an image restoration processing of an image includes the steps of generating a plurality of first optical transfer functions depending on a position of the image using coefficient data depending on an image pickup condition of the image generating a plurality of second optical transfer functions by rotating the first optical transfer functions around a center of the image or around an optical axis of an image pickup optical system generating an image restoration filter based on the first optical transfer functions and the second optical transfer functions and performing the image restoration processing of the image using the image restoration filter.
Electronic devices may have camera modules that include an image sensor and processing circuitry. The image sensor may capture an interleaved image having rows of long-exposure pixel values that are interleaved with rows of short-exposure pixel values. The image sensor may separate the interleaved image into first and second images each having empty image pixel values. The processing circuitry may generate interpolated long-exposure and interpolated short-exposure images by generating chroma-filtered interpolated pixel values for the empty pixel values in the first and second images. The processing circuitry may perform interpolation operations along one or more directions for the empty image pixels based on whether the empty image pixels are within a texture area or on a dominant edge of the captured image. The processing circuitry may combine the interpolated long-exposure image and the interpolated short-exposure image to generate a high-dynamic-range image.
A method of processing ultrasound images the method including operations of receiving color image data including a plurality of frames; determining one or more key-frames from among the plurality of frames based on a brightness value of each of the plurality of frames; setting a region of interest ROI in each of the one or more key-frames based on brightness values of a plurality of regions included in each of the one or more key-frames; performing image compensation on the plurality of frames based on the ROIs of the one or more key-frames; and reconstructing the color image data by using the image-compensated frames.
An image processing method includes: obtaining an input image; enhancing an object in the input image; and after the input image is enhanced applying a low-pass filter using a processor to obtain a processed image. A computer product includes a non-transitory medium storing a set of instructions an execution of which causes a method to be performed the method comprising: obtaining an input image; enhancing an object in the input image; and after the input image is enhanced applying a low-pass filter to obtain a processed image.
A method of compensating ultrasound image comprising demarcating a plurality of a main material regions of an ultrasound image; executing a full compensation process to generate a full compensation image according to a first attenuation curve of the main material region; generating a brightness comparison table including a plurality of brightness zones which are correspond to a plurality of brightness compensation values according to a plurality of first pixel brightness values of the ultrasound image and a plurality of second pixel brightness values of the full compensation image; executing a linear sum process to generate a compensation image including a second attenuation curve according to the brightness compensation values; generating a compensation curve according to the first and second attenuation curve; and executing space comparison process to the compensation image to generate a better compensation image according to the compensation curve.
Noise reduction processing for measured spectrum data is performed without any information loss due to discrete data characteristics of the measured spectrum data. Optical spectra in one or more cross-sections are measured through use of a signal correlated with a substance distributed in a biological tissue and a biological tissue image having reduced noise is reconstructed from the spectra.
A processing method for a pair of stereo images is provided. The method includes: extracting a pair of edge images from the stereo images each edge image having edge pixels each edge pixel of one of the edge images being associated with an overlap record and a disparity record; providing a plurality of image lateral shifts to sequentially determine a plurality of overlap levels between the pair of edge images; and updating the overlap record and the disparity record associated with a selected edge pixel to a maximum overlap level and a most-likely disparity respectively. The maximum overlap level is a maximum among a plurality of associated overlap levels to which the selected edge pixel contributes. The most-likely disparity corresponds to the maximum overlap level.
A method for distorting a digital image comprising receiving the coordinates of one or more than one image reference point defined by a user within the digital image receiving one or more than one spatial offset assigned by the user and associated with the coordinates of the one or more than one defined image reference point providing a mixing function algorithm embodied on a computer-readable medium for distorting the digital image calculating an offset matrix by applying the mixing function algorithm based on the one or more than one spatial offset and the coordinates of the one or more than one defined image reference point; and distorting the digital image by application of the offset matrix. A graphic tag may be associated with each of the defined image reference points and displayed over the digital image and the assignment of the spatial offset may be accomplished by movement of the graphic tag with the pointing device. Abstract image reference points may be used to limit distortion.
An image processing method includes: receiving image data from a frame buffer wherein each pixel of the image data has only one color information; estimating four second color information corresponding to up down left and right sides of the target pixel respectively according to a first color information of the target pixel per se and color information of the neighboring pixels for a target pixel of the image data; calculating four color difference gradients corresponding to up down left and right sides of the target pixel respectively according to the four second color information of the target pixel; determining an edge texture characteristic of the target pixel according to the four color difference gradients of the target pixel; and determining whether to modify the bit value of the first color information of the target pixel stored in a frame buffer according to an edge texture characteristic of the target pixel.
A method for deriving a blur kernel from a blurred image is provided herein. The method may include the following steps: obtaining a blurred image B being a product of a blur kernel k applied to an original image I; calculating f&#x3b8; x =Rd*P&#x3b8; B x for every angle &#x3b8; wherein R denotes an autocorrelation operator P&#x3b8; denotes a projection operator of based on angle &#x3b8; and d denotes a one dimensional differentiation filter; estimating spectral power of the blur kernel based on a given support parameter; estimating the blur kernel k using a phase retrieval algorithm based on the estimated spectral power of the blur kernel; updating the support parameters; and repeating the estimating of the spectral power the estimating of the kernel and the updating of the support parameters in an iterative to yield the blur kernel.
An image processing apparatus includes: an image obtaining device; an image dividing device that divides the image through a fine structure retrieving filter and a basic structure retrieving filter into a detail signal component and a basic signal component the detail signal component including an edge component a texture component and a noise component and the basic signal component being other than the detail signal component; an image correcting device that retrieves a focused picture cell determines whether the focused picture cell represents the noise corrects the detail signal component to reduce the noise component in the focused picture cell when the focused picture cell represents the noise; and an image synthesizing device that synthesizes a basic structure image provided by the basic signal component and a corrected fine structure image provided by the corrected detail signal component.
An image processing apparatus includes a smoothing processing unit which performs smoothing processing a thinning processing unit which performs thinning processing an edge direction determination unit which determines an edge direction with respect to each pixel of the image data and a blending processing unit which decides a pixel value of each pixel of when the thinning processing and the smoothing processing are realized at same time. In the image processing apparatus the blending processing unit decides a pixel value of a target pixel of when the thinning processing and the smoothing processing are realized at the same time depending on a combination of whether the thinning processing is performed or not and whether the smoothing processing is performed or not on the target pixel.
An RGB color image and an infrared intensity image of a live video are received. The RGB color image is converted to a colorspace image comprising a channel corresponding to a brightness value. Each pixel of the converted colorspace image is evaluated to determine whether the brightness channel of the pixel exceeds a threshold value. If the brightness channel of the pixel exceeds the threshold value the infrared intensity value of a corresponding pixel from the infrared intensity image is mixed into the pixel s channel value that corresponds to brightness. The converted colorspace image is converted back to an RGB color image.
Described herein are devices and techniques for providing adaptable Local Area Processing LAP contrast enhancement of imagery by redistributing pixel intensity values in a dynamic range of an imaging device according to a packed statistical distribution function wherein the redistribution is achieved according to a recursive packing factor.
A global spatial domain detail controlling method for an image processor includes adjusting at least one detail parameter corresponding to each pixel during an image processing according to each space position of the each pixel in an image; and performing the each pixel with the image processing according to the at least one detail parameter of the each pixel.
Techniques and apparatus for automatic upright adjustment of digital images. An automatic upright adjustment technique is described that may provide an automated approach for straightening up slanted features in an input image to improve its perceptual quality. This correction may be referred to as upright adjustment. A set of criteria based on human perception may be used in the upright adjustment. A reprojection technique that implements an optimization framework is described that yields an optimal homography for adjustment based on the criteria and adjusts the image according to new camera parameters generated by the optimization. An optimization-based camera calibration technique is described that simultaneously estimates vanishing lines and points as well as camera parameters for an image; the calibration technique may for example be used to generate estimates of camera parameters and vanishing points and lines that are input to the reprojection technique.
Some embodiments of the present invention pertain to an apparatus method and a computer program that is configured to cause a processor to construct an upper envelope and lower envelope for an input image based on a statistically computed window parameter in a real-time system using multi-thread processing and smooth the upper envelope and lower envelope based on a sum of elements in a window wherein the sum of elements in the window is divided by a number of non-zero elements in the sum of elements in the window.
An image editing device of the present invention for editing a combined photographic image formed by combining a plurality of images comprises a combined photograph editing section for carrying out editing of the combined photograph using the combined photographic image and the images that have been expanded an image quality control parameter calculating section for calculating image quality control parameters for combined photograph data that has been edited by the combined photograph editing section in accordance with first image quality control parameters for when creating the combined photograph and second image quality control parameter for when creating the compressed image wherein in the case where a combined photograph that has been edited by the combined photograph editing section is subjected to image compression the image quality control parameters that have been calculated by the image quality control parameter calculating section are used.
Methods apparatus and computer-readable storage media for video completion that may be applied to restore missing content for example holes or border regions in video sequences. A video completion technique applies a subspace constraint technique that finds and tracks feature points in the video which are used to form a model of the camera motion and to predict locations of background scene points in frames where the background is occluded. Another frame where those points were visible is found and that frame is warped using the predicted points. A content-preserving warp technique may be used. Image consistency constraints may be applied to modify the warp so that it fills the hole seamlessly. A compositing technique is applied to composite the warped image into the hole. This process may be repeated until the missing content is filled on all frames.
There is provided an apparatus and a method of evaluating an effect of chroma downsampling in a compression process of an input image. According to examples of the presently disclosed subject matter the method can include: computing an error for a target chroma downsampling &#x201c;CDS&#x201d; block based on characteristics of DCT coefficients in the U and/or V planes of a respective CDS candidates group in the input image and further based on a diversity of the DCT coefficients in the U and/or V planes of the respective CDS candidates group in the input image; and computing an estimated perceptual effect of CDS over the input image based on a plurality of target CDS blocks error values.
Embodiments of the present disclosure can include devices for storing and exchanging color space encoded images. The encoded images can store input data into high capacity multi-colored composite two-dimensional pictures having different symbols organized in specific order using sets in a color space. The encoding can include performing two-level error correction and generating frames based on the color space for formatting and calibrating the encoded images during decoding. The decoding can use the frames to perform color restoration and distortion correction. The decoding can be based on a pseudo-Euclidean distance between a distorted color and a color in a color calibration cells. In some embodiments an encoded image can be further divided into sub-images during encoding for simplified distortion correction.
An image synthesis apparatus acquires one or plural images including one or plural pictures of one person or plural people as an object determines an aspect of the one or plural pictures extracts a part of the one or plural pictures in accordance with the aspect of the one or plural pictures and synthesizes the extracted one or plural images.
A signal processing device that processes sharpening of an image with respect to an input signal SR that represents the image and outputs an output signal SO that represents the sharpened image includes an oversampler that generates an oversampled signal by interpolating a signal in order to increase a sampling frequency with respect to an input signal SR and a sharpening processing unit to which the oversampled signal is inputted and which generates a sharpened signal in which high frequency band components in the oversampled signal are nonlinearly monotonically increased in a broad sense and the sharpened signal is outputted as the output signal SO .
An image processing method is configured to denoise three-dimensional image data. The image processing method includes an image transform step of performing a frequency transform for the three-dimensional image data in the optical axis direction and of calculating three-dimensional transformed image data an image modulation step of reducing an absolute value of the three-dimensional transformed image data in a specific frequency region and of calculating three-dimensional modulated image data and an inverse image transform step of performing an inverse frequency transform corresponding to the frequency transform for the three-dimensional modulated image data in the optical axis direction and of calculating three-dimensional inversely transformed image data. The specific frequency region is a part of a predetermined.
A hardware architecture is applied to the calculation of a Difference-of-Gaussian filter which is typically employed in image processing algorithms. The architecture has a modular structure to easily allow the matching of the desired delay/area ratio as well as a high computational accuracy. A new solution is provided for the implementation of multiply-accumulators which allows a significant reduction of area with respect to the conventional architectures.
A filtering method and apparatus for anti-aliasing takes advantage of improved existing hardware by using as input the data stored in the multisampling anti-aliasing MSAA buffers after rendering. The standard hardware box-filter is then replaced with a more intelligent resolve implemented using shader programs. Embodiments find scene edges using existing samples generated by Graphics Processing Unit GPU hardware. Using samples from a footprint larger than a single pixel a gradient is calculated matching the direction of an edge. A non-linear filter over contributing samples in the direction of the gradient gives the final result.
Methods and apparatus for specifying complex continuous gradients. A field blur tool may provide a user interface through which users may apply instances of a field blur pattern. The field blur tool allows the user to place one two or more pins over the image and to specify the blur amount blur radius at each field blur pin. A blur algorithm distributes the blur values for the one or more instances of the field blur pattern over the entire image applying the blur according to the locations of the pin s and blur parameters at the pin s . If the input indicates the location and the value for the blur radius of each of two or more instances of the field blur pattern the two or more instances of the field blur pattern are combined in a blur mask by multiplying normalized radius fields of each of the instances.
A method for stereo rectifying a pair of images include: for each image of the pair of images determining a position of an epipole in an image plane associated with a first camera orientation of a camera that captures the image; for each image of the pair of images positioning the epipole in a center of a virtual image plane associated with a second camera orientation of the camera; subsequent to the positioning aligning the pair of images relative to each other by rotating around a stereo base line that intersects the epipoles of the pair of images and rotating the virtual image planes to position the virtual image plane substantially parallel to the stereo base line and their normal vectors substantially parallel to each other so as to obtain a stereo rectified pair of image planes. An embodiment of the invention also relates to a method and system for accurately determining the epipoles when they are unknown.
An image processing system combines higher-resolution panchromatic images and lower resolution multispectral images using a hyperspherical color space pan-sharpening technique. By converting the multispectral images into a hyperspherical color space the intensities of the multispectral images can be intensity matched to the intensities of the panchromatic image and then retransformed back to the original color space. The intensity matching can utilize a number of techniques including but not limited to direct substitution of the intensities of the panchromatic image for the intensities of the multispectral images modification of the intensities of the multispectral images based on predefined statistical models and modification of the intensities of the multispectral images based on dynamically generated statistical models and a selected sharpening parameter &#x3b2;.
A method for correcting a rolling shutter effect is provided. The method includes: obtaining feature point pairs in images wherein each of the feature point pairs corresponds to a motion vector; obtaining sampling points between two consecutive images in time; setting a moving velocity and an angular velocity of an image capturing unit at each of the sampling points as variables; obtaining estimating motion vectors according to the variables a focal length of the image capturing unit and row locations where the feature point pairs are located; executing an optimization algorithm according to a difference between the motion vectors and the estimating motion vectors to calculate the moving velocity and the angular velocity corresponding to the variables; varying locations of pixels in an image according to the moving velocity and the angular velocity to generate a first corrected image. Thereby the rolling shutter effect in an image is removed.
A method to detect and remove noise in image reconstruction. The method includes integration of filters and phase unwrapping algorithms for removing speckle noise residual noise and noise at the lateral surface of height discontinuities. The method is used for generating a noise-free unwrapped phase map and hence a successful image reconstruction of an object image.
Spatial and temporal metrics are computed for a picture or regions within a picture to determine the impact of coding and quantization on the quality of an encoded picture. Prediction mode decisions and quantization optimization algorithms are used to create a compressed bit stream that minimizes coding artifacts. Pre-processing techniques are also used to suppress coding artifacts that reduce picture quality.
Embodiments of methods systems and storage media associated with enhancing glyphs in a scanned image are disclosed herein. Based on properties of a glyph one or more stroke kernels representing the glyph may be identified or generated. The stroke kernels may be compared to both the glyph and one another and one or more preferred stroke kernels may be identified. The preferred stroke kernels may be stored and applied to the glyph to enhance the glyph.
An image conversion apparatus calculates based on a first value for obtaining first coordinate values in a second image before first conversion which correspond to coordinate values of one pixel in a first image after first conversion a second value for obtaining second coordinate values in the second image which correspond to coordinate values of a pixel adjacent to the one pixel in the first image. The apparatus converts the second coordinate values into third coordinate values for second conversion of converting a third image into the second image and converts the third image into the first image. In the calculation of the second value addition or subtraction using a constant and a result of the calculation is iteratively executed for sequentially outputting values corresponding to results of multiplication of coordinate values of each pixel in the first image and the constant.
An apparatus method and other embodiments associated with performing interpolations to compute gain values that correct for varying spatial intensity are described. In one embodiment a method includes determining by an apparatus that processes image data a gain value for a pixel in the image data for which there is no gain value available in the apparatus by interpolating related gain values associated with corners of a rectangle bounding the pixel wherein the interpolating includes determining at least two partial coefficients by interpolating pairs of the related gain values. Noise is filtered from the image data using a noise threshold and the noise threshold is modified by using the at least two partial coefficients. The method also applies the gain value to the pixel in the image data.
An image processing apparatus includes an acquisition unit configured to acquire a first finite spatial filter having image resolution anisotropy and a calculation unit configured to compute a second spatial filter by convolving a finite filter with respect to the first spatial filter the finite filter having a sum of elements being 0 and at least two of the elements being non-0.
The invention relates to an imaging apparatus for imaging an object of interest. An analytical reconstruction unit 12 analytically reconstructs an analytical image of the object from detection data in particular from projection data and an iterative reconstruction unit 13 iteratively reconstructs an iterative image of the object from the detection data wherein a combination unit 14 combines the analytical image and the iterative image for generating a combination image. An iterative image can comprises shading artifacts which may be caused by preprocessing the detection data before performing the iterative reconstruction. An analytical image shows reduced shading artifacts in particular shows no shading artifacts at all. Thus by combining the analytical image and the iterative image a combination image can be generated in which the shading artifacts are reduced in comparison to an iterative image thereby improving the quality of the reconstructed final image of the object of interest.
Bi-level pixel values are generated from a set of input pixel values corresponding to an image. Various described methods and apparatus are well suited for applications with limited computational capability and/or limited available resources to be used for performing image processing. Corresponding to an individual input pixel being processed a plurality of windows including the pixel are evaluated to determine statistics including a variance for each window. Based upon the determined variances one of a plurality of binarization threshold generation functions is selected. A binarization threshold for the input pixel is determined using the selected binarization threshold generation function. A bi-level pixel value is generated based on a comparison of the input pixel value to the generated binarization threshold. In various embodiments the binarization threshold determination functions use non-zero integer powers of one or more variances and intentionally avoid performing a square root operation thus limiting computational complexity.
A method of applying a post-render motion blur to an object may include receiving a first image of the object. The first image need not be motion blurred and the first image may include a first pixel and rendered color information for the first pixel. The method may also include receiving a second image of the object. The second image may be motion blurred and the second image may include a second pixel and a location of the second pixel before the second image was motion blurred. The method may additionally include locating the first pixel in the first image using the location of the second pixel before the second image was motion blurred. The method may further include coloring the second pixel using the rendered color information for the first pixel.
An image processing device includes: a first edge strength calculation part that calculates a first edge strength for a focus pixel based on pixel values in a first region that includes the focus pixel in an input image; a second edge strength calculation part that calculates a second edge strength for the focus pixel based on pixel values in a second region that is smaller than the first region and that includes the focus pixel; and a filter processing part that determines a filter coefficient such that a first smoothing strength is higher than a second smoothing strength and that filters the input image using the filter coefficient. The first smoothing strength is obtained where the first edge strength is higher than a first reference value and where the second edge strength is lower than a second reference value and the second smoothing strength is obtained in other cases.
The present invention relates to a method and device for obtaining an image of a crumpled document from an image of this document when it is crumpled. The method comprises a step of determining a three-dimensional geometric model of the surface of the crumpled document by triangulation of three-dimensional points defined from the pattern of a target extracted from the image of this document when it is crumpled; the method is characterized in that it comprises a step of determining a projection of the three-dimensional geometric model onto a so-called acquisition plane by means of error minimization of this projection under constraints of preserving defined geometric characteristics in the vicinity of the three-dimensional points and in that it comprises a step of superimposing the textures associated with the three-dimensional model onto the projection of this model thus determined. The present invention likewise relates to target patterns that make it possible to improve the quality of the image resulting from the method to be improved and/or to reduce the cost for computing said image.
An image processing apparatus including a first image processing unit and a second image processing unit. The first image processing unit is configured to calculate a parameter for image processing based on a first image but not based on a second image and execute the image processing on the first image using the parameter. The second image processing unit is configured to execute the image processing on the second image using the parameter.
A method and apparatus are described including determining an inter-frame object displacement for each object in a left eye image frame pair determining an inter-frame object displacement for each object in a right eye image frame pair determining a convergence shifting field between each object in the left eye image and the right eye image pair determining an amount of motion blur responsive to the inter-frame object displacement for each object in the left eye image frame pair the inter-frame object displacement for each object in the right eye image frame pair and the convergence shifting field between each object in the left eye image and the right eye image pair and adjusting the motion blur by the amount of motion blur.
A system includes a source that rotates about an examination region and emits radiation that traverses the examination region a radiation sensitive detector array that detects radiation traversing the examination region and generates projection data indicative of the detected radiation and a projection data de-noiser that de-noises the projection data wherein the de-noiser de-noises a projection based on a number of detected photons for the projection.
A content-adaptive edge and detail enhancement apparatus is described for image/video processing. Both 2D peaking and LTI/CTI are used in sharpening pictures. Image analysis is performed to generate a blending factor to control the use of the two peaking techniques. The strength or likelihood of edges or transitions is measured and such a strength or likelihood measurement will be transformed into the blending factor controlling the blending of the LTI/CTI and peaking outputs.
In embodiments of optical flow accounting for image haze digital images may include objects that are at least partially obscured by a haze that is visible in the digital images and an estimate of light that is contributed by the haze in the digital images can be determined. The haze can be cleared from the digital images based on the estimate of the light that is contributed by the haze and clearer digital images can be generated. An optical flow between the clearer digital images can then be computed and the clearer digital images refined based on the optical flow to further clear the haze from the images in an iterative process to improve visibility of the objects in the digital images.
In a method and device for improving image rendition by contrast and/or sharpness enhancement the sharpness enhancement is made dependent on the local average luminance value. A mix is made of spatially enhanced image signals is used wherein for various signal differing spatial frequencies are boosted. The mixing factors for mixing of the boosted signals are dependent on a local average luminance value such that the distribution over frequency bands shifts to higher frequencies and sharper enhancement as the luminance value increases.
A method for correcting overfocus of a digital image created from coherent imaging using centered fractional Fourier transforms or mathematical equivalents is described. A received image is presented to a numerical processor and a first numerical value for an imaginary power variable is selected and used in an iterative algorithm numerical procedure system architecture etc. A centered discrete fractional Fourier transform of an imaginary power and a phase restore operator associated are applied to the image file to produce a modified image. A change in mis-focused is determined and used in adjusting the specified imaginary power for a next iteration.
An edge-preserving filtering method and apparatus. The edge-preserving filtering method includes: acquiring an upper edge pixel P x y&#x2212;n a lower edge pixel P x y+m m+n left edge pixels P x&#x2212;p y ; and m+n right edge pixels P x+q y ; of a pixel to be filtered P x y wherein &#x201c;x&#x201d; &#x201c;y&#x201d; &#x201c;m&#x201d; &#x201c;n&#x201d; &#x201c;p&#x201d; and &#x201c;q&#x201d; are all positive integers and &#x201c;y&#x201d; takes an integer larger than &#x201c;y&#x2212;n&#x201d; and less than &#x201c;y+m&#x201d; in turn; acquiring a filtered pixel value of the pixel to be filtered by using pixel values of the pixel to be filtered the upper edge pixel the lower edge pixel the left edge pixels and the right edge pixels. The edge-preserving filtering method and apparatus in accordance with an embodiment utilize edge information around the pixel to be filtered to swiftly acquire a set of pixels for filtering the pixel to be filtered and thus implement edge-persevering filtering.
Method and apparatus for processing edges in an image are provided. The method in an embodiment includes the following steps. With respect to a cross-shaped patterned centered at a target pixel of an input image a first-direction gradient along a first direction and a second-direction gradient along a second direction are calculated. According to the first-direction and second-direction gradients it is determined whether to compensate the target pixel based on pixel values of a first plurality of pixels along the second direction or pixel values of a second plurality of pixels along the first direction within the cross-shaped pattern or to output a pixel value of the target pixel.
A method for reducing spatial noise of images includes the following steps. A target pixel is obtained and an operating block is built accordingly. Pixel values of the target pixel and multiple neighboring pixels in the operating block are operated to obtain a variance corresponding to the operating block. Whether the target pixel is characteristic is judged according to the variance. If the target pixel is not characteristic the multiple pixels in the operating block are filtered to obtain a modulated pixel value. The pixel value of the target pixel is updated to the modulated pixel value.
A gradation-correcting curve to correct a gradation of an input image is generated. Gradation correction based on the gradation-correcting curve is made to a boundary pixel of a color-reproduction space at the same saturation as that of a target lattice point and at a hue of the target lattice point. An equal-saturation line is set by using the boundary pixel of the color-reproduction space after the gradation correction. A saturation-correction amount of the target lattice point is decided based on the gradation-correcting curve and the equal-saturation line.
Systems and devices for and methods of motion-compensated temporal filtering based on variable filter parameters. A method embodiment includes a determining by a processor having memory a pixel-related residue image based on a set of differences between a current pixel intensity of a current frame and a corresponding pixel intensity of a previous frame wherein the corresponding pixel intensity is augmented by a motion-compensated vector of the previous frame; b determining an intensity weight based on the determined pixel-related residue image and a temporal filtering parameter; and c filtering the pixel intensity of the current frame based on the determined intensity weight and the motion compensated vector of the previous frame.
A method is provided. The method includes acquiring a first dataset at a first energy spectrum and a second dataset at a second energy spectrum. The method also includes extracting a metal artifact correction signal using the first dataset and the second dataset or using a first reconstructed image and a second reconstructed image generated respectively from the first and the second datasets. The method further includes performing metal artifact correction on the first reconstructed image using the metal artifact correction signal to generate a first corrected image.
A classifier training system trains a classifier for evaluating image deblurring quality using a set of scored deblurred images. In some embodiments the classifier training system trains the classifier based on a number of sub-images extracted from the scored deblurred images. An image deblurring system applies a number of different deblurring transformations to a given blurry reference image and uses the classifier trained by the classifier training system to evaluate deblurring quality thereby finding a highest-quality deblurred image. In some embodiments the classifier training system trains the classifier in the frequency domain and the image deblurring system uses the classifier trained by the classifier training system to evaluate deblurring quality in the frequency domain. In some embodiments the image deblurring system applies the different deblurring transformations iteratively.
A repeated integral images method filters image data in only two passes e.g. the first pass filters horizontal rows of pixels and a second pass filters vertical columns of pixels or in a single pass. The filter performs at least one infinite impulse response IIR filter and at least one finite impulse response FIR filter on the image data. A plurality of IIR filters and FIR filters maybe performed to approximate a Gaussian filter. By minimizing the number of passes the data flow between the processing unit and the storage unit is greatly reduced compared to conventional repeated integral images method thereby improving computation time.
There is provided an image processing apparatus including a vector detection unit which detects flow vectors of pixels in an inputted image a vector-coherency calculation unit which calculates vector coherency based on the flow vectors detected by the vector detection unit a deformation-characteristic computation unit which computes a deformation characteristic by using the vector coherency calculated by the vector-coherency calculation unit the deformation characteristic being used for deforming a tap shape of a filter used for each of the pixels and a painterly conversion unit which converts the inputted image based on the deformation characteristic computed by the deformation-characteristic computation unit.
Methods and apparatus for use in reducing noise in one or more video frames. An expected value corresponding to each area e.g. pixel of a plurality of areas within the video frame is determined. A surprise value associated with each area is calculated based at least in part on the expected value and an actual value corresponding to the area. The surprise value represents a divergence of the actual value from the expected value. The response of one or more noise filters is attenuated with respect to a first area of the plurality of areas based on the surprise value associated with the first area.
Among other disclosed subject matter a computer-implemented method includes receiving illustrated content. The illustrated content includes half-tone content. The method includes blurring at least part of the illustrated content. The blurring is performed according to a blur radius. The method includes downscaling the blurred illustrated content to an output size.
Disclosed are apparatus and methods for denoising a video stream of a camera. A current frame of the video stream and a temporally adjacent frame of the video stream that has been previously spatially and temporally denoised are obtained. The current frame is first spatially denoised while preserving edges in such current frame to generate a plurality of spatially denoised pixels for the current frame. A particular pixel of the current frame is then both spatially and temporally denoised based on a weighted averaging of the particular pixel s associated spatially denoised pixel from the current frame and a plurality of pixels from the temporally adjacent frame that have already been spatially and temporally denoised.
A moving subject detection map is generated by performing moving subject region determination based on input image information from an image capture portion and is used to set an exposure pattern for a moving subject detected pixel region. The exposure pattern is cyclically arranged with multiple different exposure times. The exposure time for a stationary subject region is set according to the brightness of the subject. Regarding an image captured based on the exposure time control an output image is generated by computing pixel values for a moving subject region using pixel value combination processing that utilizes the pixel values of pixels with a plurality of different exposure times being set and by computing pixel values for the stationary subject region by multiplying a gain according to the exposure time. This achieves the acquisition of a dynamic range image while keeping deterioration of the resolution to a minimum.
A system and method that reduce or eliminate step-contouring generated by compression algorithms are provided because many types of compression algorithms introduce a step-contoured artifact for images and video with slow gradients. The system and method restores the gradient to a piece of content by detecting a start and end of the step contour in each row and column of the piece of content and increments a pixel in certain regions of the row or the column to restore the gradient in the piece of content.
Various embodiments of methods and apparatus for motion deblurring are disclosed. In one embodiment an estimate of a latent image of a blurred image at a current scale from an estimate of a latent image at a previous coarse scale is generated using an upsampling super-resolution function and a blur kernel is estimated based on the estimate of the latent image and the blurred image; and are repeated from a course to fine scale. A final image estimate is generated. The generating the final image estimate includes performing a deconvolution of the latent image using the blur kernel and the blurred image.
Provided is a method and apparatus for deblurring a non-uniform motion blur in an input image that may restore a clearer image by dividing a large scale input image into tiles corresponding to partial areas selecting among the divided tiles an optimal tile for a partial area most suitable for estimating non-uniform motion blur information and effectively removing an artifact in an outer portion of a tile through padding of each tile.
An image processing apparatus includes an image acquiring unit that acquires an image; an information acquiring unit that acquires image information indicative of a content of the image; and a correcting unit that corrects the image based on the image information such that some of warping of the image is left. The horizontal direction component of the warping may be completely or nearly completely eliminated while a predetermined portion of a vertical direction component of the warping is left when the image information indicates the content of the image is a person. Alternatively there is an analyzer which generates the image information indicating that the content of the image is a erson when the analyzing determines that the image contains two or more persons.
A method for determining the coordinates of a point on the surface of an object is provided. A source system such as an OBIRCH system is used to analyze and detect faults in an integrated circuit on a semiconductor die. The die includes three reference points and the detected fault s are defined with reference to the reference points. When the die is transferred to a FIB or other system for fault analysis a processor determines the coordinates of the fault s for the FIB system using the three reference points.
