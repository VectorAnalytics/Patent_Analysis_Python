A system for determining the orientation of digital ink is provided having a sensing pen and a processor. The system measures the orientation of the pen during writing by the pen on a surface printed with tags. Each tag encodes data on an identity of the surface associated with a digital description of the surface and on the respective location of that tag on the surface. The digital ink is generated by associating the digital description with the data encoded by the tags sensed by the pen during said writing. The orientation of the digital ink is determined using the measured orientation of the pen.
A method for extracting line segments from an edge image comprises receiving a digital image comprising a plurality of edge pixels and processing the plurality of edge pixels using a breadth first search to determine a plurality of breadth first search pixels in a breadth first search order for a connected component. The connected component comprises a plurality of components. The method continues by processing the plurality of breadth first search pixels in an order related to the breadth first search order to determine a plurality of component pixels for at least one component of the plurality of components. Each of the plurality of components comprises a line segment. The method concludes by processing the plurality of component pixels to determine a plurality of line segment pixels for the line segment.
A method for edge mapping images for use in image processing. Edge mapping includes identifying base and non-base color components. A search window in the base color component is opened and the non-base color components are compared with the base component picture. The number of matched or unmatched edge points is then calculated. The best match can then be determined through testing or manual selection.
A method for matching images is disclosed. The method includes selecting a template image and a target image from a batch of images and sampling the template image so as to obtain a template-sampled image and sampling the target image so as to obtain a target-sampled image wherein the sampling of both the template image and the target image is according to a sample interval. The method further includes matching the template-sampled image and the target-sampled image and matching the template image and the target image if the template-sampled image and the target-sampled image are matched successfully.
An apparatus 100 for handwriting recognition has a touch-sensitive display screen 240 providing a hand writing input area 270 capable of detecting hand-made user input. The apparatus also has a processing device 300 coupled to the touch-sensitive display screen and providing a user interface to a user. The handwriting input area 270 includes a writing start area 280 capable of switching between a first two-dimensional scope 282 and a second two-dimensional scope 282 ; larger than the first two-dimensional scope. The processing device 300 is configured to handle said handmade user input as either a logical mouse event associated with a control operation for said user interface or a logical pen event associated with handwriting. User input within the writing start area when having its first two-dimensional scope is handled as a logical mouse event and causes the writing start area to switch to its second two-dimensional scope Furthermore user input that starts within the writing start area when having its second two-dimensional scope is handled as a logical pen event and causes interpretation of the user input 252 as a symbol 254 from a plurality of predefined symbols.
Described is searching directly based on digital ink input to provide a result set of one or more items. Digital ink input e.g. a handwritten character sketched shape gesture drawing picture is provided to a search engine and interpreted thereby with a search result or results returned. Different kinds of digital ink can be used as search input without changing modes. The search engine includes a unified digital ink recognizer that recognizes digital ink as a character or another type of digital ink. When the recognition result is a character the character may be used in a keyword search to find one or more corresponding non-character items e.g. from a data store. When the recognition result is a non-character item the non-character item is provided as the result without keyword searching. The search result may appear as one or more item representations such as in a user interface result panel.
Illustrative embodiments provide a computer implemented method a data processing system and a computer program product for transforming character data input between a first writing system and a second writing system. The computer implemented method comprises receiving character data input of a first writing system and ensuring the character data input contains normalized characters. A predefined transform is selected based on the character data input of the first writing system and output to a second writing system to transform the normalized characters of the first writing system to character data output of the second writing system and providing the character data output to a display process.
Techniques described herein may recognize handwritten characters that are written at least partially over the top of one another that are input to a computing device. The handwritten characters may be formed of one or more strokes. A user may write characters or parts of words over approximately the same area of graphical user interface i.e. on top of each other without having to wait for a timeout between character input and without having to select a button or provide another input indicating the character is complete before entering input for another character. Once a character is at least partially recognized a graphical indication corresponding to the user input displayed on a screen may be altered. Such alterations may include fading or changing size or location of the graphical indication.
Techniques described herein may recognize handwritten characters that are written at least partially over the top of one another that are input to a computing device. The handwritten characters may be formed of one or more strokes. A user may write characters or parts of words over approximately the same area of graphical user interface i.e. on top of each other without having to wait for a timeout between character input and without having to select a button or provide another input indicating the character is complete before entering input for another character. Once a character is at least partially recognized a graphical indication corresponding to the user input displayed on a screen may be altered. Such alterations may include fading or changing size or location of the graphical indication.
Embodiments of the present invention provide a method and a module for identifying a background of a scene depicted in an acquired stream of video frames that may be used by a video-analysis system. For each pixel or block of pixels in an acquired video frame a comparison measure is determined. The comparison measure depends on difference of color values exhibited in the acquired video frame and in a background image respectively by the pixel or block of pixels and a corresponding pixel and block of pixels in the background image. To determine the comparison measure the resulting difference is considered in relation to a range of possible color values. If the comparison measure is above a dynamically adjusted threshold the pixel or the block of pixels is classified as a part of the background of the scene.
A model-based object recognition system operates to recognize an object on a predetermined world surface within a world space. An image of the object is acquired. This image is a distorted projection of the world space. The acquired image is processed to locate one or more local features of the image with respect to an image coordinate system of the image. These local features are mapped a world coordinate system of the world surface and matched to a model defined in the world coordinate system. Annotations can be arranged as desired relative to the object in the world coordinate system and then inverse-mapped into the image coordinate system for display on a monitor in conjunction with the acquired image. Because models are defined in world coordinates and pattern matching is also performed in world coordinates one model definition can be used by multiple independent object recognition systems.
The invention is a method for assessing image quality value of a distorted image with respect to a reference image. The method comprises the following steps: computing for each pixel of the distorted image at least one quality level with respect to the reference image; adding for the distorted image the quality levels associated to each pixel by weighting them by a weight depending on a perceptual interest of the pixel in order to get the image quality value the weight being lower for a pixel of high perceptual interest.
The present invention provides an image processing system which can reduce calculation time by alleviating a calculation load in assessing the occurrence of tampering of an image. For example the image processing system of the present invention first identifies a type of a form of an image to be assessed in assessing the occurrence of tampering. Next a characteristic amount of a certain region flexible region corresponding to the identified type of a form is extracted as a characteristic amount of the image to be assessed. Then the extracted characteristic amount of image to be assessed and the characteristic amount extracted from a certain region in an original image are compared and the compared result is notified as the assessment result. A flexible region to which a user writes is preferably specified as said certain region.
A method and a system for forming an inset image are disclosed. The method includes identifying a region of interest in an original image. An inset is generated based on the region of interest. A region of low interest is identified in the original image. The inset is applied to the region of low interest to form an inset image. The region of interest is scaled differently from the inset in the inset image. The method can proceed automatically or substantially automatically without the need for significant user input.
A method of classifying and organizing digital images utilizing optical metadata captured using multiple sensors on the camera may define semantically coherent image classes or annotations. The method defines optical parameters based on the physics of vision and operation of a camera to cluster related images for future search and retrieval. An image database constructed using photos taken by at least thirty different users over a six year period on four different continents was tested using algorithms to construct a hierarchal clustering model to cluster related images. Additionally a survey about the most frequent image classes shot by common people forms a baseline model for automatic annotation of images for search and retrieval by query keyword.
Provided is an improved apparatus and method for recognizing pattern data. The method including extracting a high frequency component with Y data from pattern data sensed through a camera equipped in a mobile station to more clearly recognize edge portions. The high frequency component and the Y data are weighted with predetermined weights and input data is generated using the high frequency component and Y data weighted with the pre-set weights. Accordingly edge portions of the input data are more clearly defined thereby increasing a recognition rate of the pattern data.
A method of detecting generally rectangular objects in an image comprises determining candidate rectangles in the image based on detected corners in the image ranking the candidate rectangles on the basis of a set of differentiating factors and detecting objects in the images based on the ranked candidate rectangles.
To accurately discriminate a dot region within an image the image processing apparatus includes first through fourth isolated dot discriminating portions each judging for each of a plurality of pixels included in the image whether the pixel corresponds to a center pixel of an isolated dot an isolated dot size determining portion detecting an isolated dot size a dot region discriminating portion judging whether a target pixel is included in a dot region based on a position of the pixel judged as being the center pixel of the isolated dot and a dot region determining portion determining the dot region based on a position of the target pixel judged as being included in the dot region and the detected isolated dot size.
Systems and methods for descriptor vector computation are described herein. An embodiment includes a identifying a plurality of regions in the digital image; b normalizing the regions using at least a similarity or affine transform such that the normalized regions have the same orientation and size as a pre-determined reference region; c generating one or more wavelets using dimensions of the reference region; d generating one or more dot products between each of the one or more wavelets respectively and the normalized regions; e concatenating amplitudes of the one or more dot products to generate a descriptor vector; and f outputting a signal corresponding to the descriptor vector.
An adversarial approach in detecting inappropriate text content in images. An expression from a listing of expressions may be selected. The listing of expressions may include words phrases or other textual content indicative of a particular type of message. Using the selected expression as a reference the image is searched for a section that could be similar to the selected expression. The similarity between the selected expression and the section of the image may be in terms of shape. The section may be scored against the selected expression to determine how well the selected expression matches the section. The score may be used to determine whether or not the selected expression is present in the image.
A system and method for automatically recognizing words or phrases in text.
System for implementing user handwriting according to the present invention comprising : a handwriting input module 120 for receiving user handwriting including at least 100 to 200 characters by a user with sample sentences; a feature determining module 150 ; a distance determining module 160 for determining a vertical distance between an uppermost point mark and a lowermost point mark between 2 characters and their segments and a horizontal distance between a leftmost point mark and a rightmost point mark between 2 characters and their segments; a position determining module 170 for determining positions of the uppermost and lowermost point marks and the leftmost and rightmost point marks between 2 characters and their segments; a handwriting combining module 180 for combining several handwriting base on data recognized by the feature determining module 150 the distance determining module 160 and the position determining module 170 ; and a handwriting output module 200 for outputting handwriting combined by the handwriting combining module 180 .
A region extraction system includes a temporary region extractor for temporarily extracting a to-be-extracted region from measured data with a region growing technique an initial position determiner for determining an initial position of a standard model for the to-be-extracted region using the to-be-extracted region temporarily extracted and a to-be-extracted region extractor for extracting the to-be-extracted region from the measured data with a model fitting technique using the standard model.
Systems methods and program products for converting a first image to an intensity image using principal components analysis where the intensity image is based on a first principal component. The intensity image is analyzed to identify a plurality of scale invariant features in the intensity image each identified feature associated with a score. An adaptive threshold is applied to the identified features to establish a set of features for the first image.
The present invention discloses a multilevel method of bitmapped image analysis that comprises a whole image data representation via its components&#x2014;objects of different levels of complexity&#x2014;hierarchically connected therebetween by spatially-parametrical links. The said method comprises preliminarily generating a classifier of the objects that possibly may be present in the image consisting of one or more levels differing in complexity; parsing the image into objects; attaching each object to one of predetermined levels; establishing hierarchical links between objects of different levels; establishing links between objects within the same level; and performing an object feature analysis. The objects feature analysis comprises at least generating and examining a hypothesis about object features and correcting the object s features of the same and other levels in response to the hypothesis examination results. The step of object features analysis may also comprise execution of a recursive RX-cut within the same level.
Disclosed are systems and methods to identify text-like pixels from an image by providing an image and classifying line segments of pixels within the image by edge-bounded averaging.
In an object detecting apparatus for detecting whether or not a detection object is present in a monitoring area by comparing a present image with a background image photographed when the detection target is not present in the monitoring area a background contour line information extracting means extracts contour line information of an article photographed in the background image. An object detecting means extracts contour line information other than the contour lines of the background image from the present image. Also the object detecting means detects whether or not the detection object is present in the monitoring area based upon such a fact as to whether or not the contour line information can be extracted from the present image.
A method of processing a plurality of still images. The method includes the steps of: detecting an object photographed for each of the still images; arranging the object detected by the step of detecting an object with respect to the plurality of still images and detecting an object photographed by the plurality of still images; relating objects having a strong relationship out of the plurality of objects detected by the step of arranging the object; selecting a still image including at least one of the objects detected by the step of relating objects from the plurality of still images; and outputting the still image selected by the step of selecting a still-image.
An attribute-information-area extracting unit extracts an attribute information area in which attribute information is displayed when the attribute information area does not change between certain frames of adjacent scenes obtained by dividing a video content by a scene dividing unit. A character-areas extracting unit extracts character areas in which video attribute information in individual characters that is metadata of the video content of the attribute information area are present and a character-area-meaning assigning unit assigns meanings to the character areas. A character-area reading unit reads the video attribute information from the character areas to which meanings are assigned thereby outputting the video attribute information.
An image processing apparatus includes: a data obtaining section for obtaining input image data; a memory in which reference image data or features of a reference image is stored; and a similarity determination process section for performing a determination process in which it is determined whether the input image data is image data corresponding to the reference image or not. The similarity determination process section changes the determination process in accordance with related information of the input image data. Consequently it is possible to realize an image processing apparatus capable of determining a similarity between input image data and a reference image and restricting a process on the input image data in accordance with the result of the determination.
There is a need to provide simple accurate fast and computationally inexpensive methods of object and hand pose recognition for many applications. For example to enable a user to make use of his or her hands to drive an application either displayed on a tablet screen or projected onto a table top. There is also a need to be able to discriminate accurately between events when a user s hand or digit touches such a display from events when a user s hand or digit hovers just above that display. A random decision forest is trained to enable recognition of hand poses and objects and optionally also whether those hand poses are touching or not touching a display surface. The random decision forest uses image features such as appearance shape and optionally stereo image features. In some cases the training process is cost aware. The resulting recognition system is operable in real-time.
A method for classifying text comprises receiving data containing text and parsing a plurality of tokens out of the text. A plurality of metatokens are generated for each token wherein the metatokens comprise strings of text and groupings of strings of text. The method further comprises calculating a probability that the data falls into a certain category using the tokens and metatokens. The probability is compared to a threshold value and the data is classified into the certain category if the probability is greater than the threshold value.
An image processing apparatus includes a feature point calculating section for extracting two or more connected components from a document image of interest and calculating the feature point from the centroid defined in each of the connected components a features calculating section for calculating the features of the document image from the distance between the feature points a voting processing section for voting one of the registered images which is similar to the document image as reviewing the features and a similarity judging process section for judging the similarity from the result of the voting wherein the description of the processing to be executed for the output is determined from the result of the similarity judgment.
A method aligns a character to a sampling grid of an image where an outline of the character is specified by input pen commands. Points and contours of the input pen commands are determined. An orientation of each contour is determined. A first directed acyclic graph DAG is constructed indicating a hierarchical relationship of related contours. Radicals are determined using the first DAG. Simple segments of the contours are determined and merged independently for each radical. Segment pairs and their hinted coordinates are determined. The segment pairs are sorted and a second DAG is constructed for the sorted segment pairs. Collisions between the segment pairs are resolved using the second DAG. The segments pairs x-free points and y-free points are fitted to the sampling grid independently for each radical and a result of the fitting is stored in output pen commands.
An apparatus for use with a single modality imaging system configured to generate uncorrected imaging data of a patient the single modality imaging system includes two gamma cameras and a patient stretcher disposed between the two gamma cameras the apparatus for compensating for downward stretcher deflection at the extended end of the patient stretcher that occurs during stretcher extension. The apparatus includes a single sag sensor for sensing the downward deflection of the patient stretcher a subtracting device configured to generate a sag correction factors based on a baseline stretcher height and an input received from the sag sensor and a compensator configured to modify at least a portion of the uncorrected imaging data to compensate for sag using the using the sag correction factor to generate a unified image.
A text input device receives in its information input circuit a letter indicating a destination of transmission as information on the destination of transmission. The text input device stores in its word-finder with learning function an input text and an output text in a state correlated with the information on the destination of transmission or its attribute. The text input device in its text learning circuit controls a change in storage caused by correlating an input text matched to a text entered with the information on the destination of transmission or its attribute stored and coincident with the information on the destination of transmission or its attribute entered. When a text matched to the text entered is output the text input device in its text converter takes out and outputs at least one output text stored.
A method of imaging a coding pattern disposed on a surface of a substrate. The method comprises the steps of: a operatively positioning an optical reader relative to the surface and capturing an image of a portion of the coding pattern; b sampling and decoding x-coordinate data and y-coordinate data contained in the imaged portion; and c determining a position of the pen. The imaged portion has a diameter of at least one tag diameter and less than two tag diameters. The x-coordinate data and y-coordinate are each replicated in the tag.
A method of imaging a coding pattern disposed on a surface of a substrate. The method comprises the steps of: a operatively positioning an optical reader relative to the surface and capturing an image of a portion of the coding pattern; b sampling and decoding x-coordinate data and y-coordinate data within the imaged portion; and c determining a position of the pen. The coding is specially adapted to minimize space occupied by coordinate data. The imaged portion has a diameter of at least l+q &#x221a;2 and less than 2 l &#x221a;2 where l is the length of a square tag in the coding pattern and q is the width of a central column or row of data within each tag.
Pixels of a binary image obtained by binarizing an image are scanned in a predetermined direction labels are assigned to the pixels according to binarization information about the respective pixels information about the assigned labels is stored sequentially for each of a plurality of lines along the predetermined direction information about coordinate values in the binary image of pixels assigned the same label is stored a determination is made as to whether or not in a current line among the plurality of lines there is a pixel assigned the same label as a label assigned to a pixel contained in a line which was scanned immediately before the current line when a determination is made that there is no pixel assigned the same label a feature point in a connected component formed by connecting together pixels specified by the coordinate values is calculated based on the stored information about the coordinate values a feature vector representing a feature of the image is calculated based on the calculated feature point and a similarity to reference image is determined based on the calculated feature vector.
A face model providing portion provides an stored average face model to an estimation portion estimating an affine parameter for obtaining a head pose. An individual face model learning portion obtains a result of tracking feature points by the estimation portion and learns an individual face model. The individual face model learning portion terminates the learning when a free energy of the individual face model is over a free energy of the average face model and switches a face model provided to the estimation portion from the average face model to the individual face model. While learning the individual face mode an observation matrix is factorized using a reliability matrix showing reliability of each observation value forming the observation matrix with emphasis on the feature point having higher reliability.
System and method for mapping a location of each of a plurality of devices in a data center. In one embodiment the method comprises receiving image data comprising an image of at least a portion of the data center from a source; processing the image data to locate visual identifiers displayed in the image wherein each of the visual identifiers is associated with one of the devices or with a spatial reference point; extracting the located visual identifiers and determining spatial coordinates for each of the identified visual identifiers from the image; and determining the spatial reference points from the image. The method further comprises developing groups based on extracted visual identifiers and spatial coordinates thereof and the spatial reference points wherein allowances are made for an angle of the image wherein each group comprises a subset of related ones of the devices; for each group comparing each of the visual identifiers of the group with a key to determine information regarding the associated device to obtain processing results; and combining processing results corresponding to multiple images to remove redundant information and produce final results.
To appropriately evaluate a surface shape of an object to be inspected regardless of the relative positions of a light source and an image-taking device with respect to the object. When evaluating a surface shape it includes a shape recognition step for recognizing the surface shape of the object to be evaluated a representative point extraction step for extracting a representing point from the recognized surface shape of the object to be evaluated a shape specifying step for specifying a shape for a predefined area around the extracted representing point a vector defining step for defining a light source direction vector with respect to each of the representing points a representing point select step for selecting from among all of the representing points only representing points for which imaginary reflection vectors corresponding to the light source direction vectors are contained within a predefined range from an imaginarily defined direction and a highlight line creation step for creating a highlight line that is imaginarily generated on the surface of the object to be evaluated based on the highlight point group i.e. a group of all of the selected representing points wherein an evaluation of the surface shape of the object to be evaluated is performed based on the created highlight line.
In storing of a document page index of a reference image in association with each hash value calculated for each reference image by the features calculating section a storage processing section determines whether the number of document page indexes which have already been stored in association with each hash value is larger than or equal to a preliminarily setup upper limit value or not. The storage processing section stores the document page index of a reference image in a hash table in association with the hash value calculated by the features calculating section when the number of document page indexes which have already been stored is smaller than the upper limit value or invalidates the hash value when the number of document page indexes which have already been stored is larger than or equal to the upper limit value.
A method and system for discovering from a database an object which is confusingly similar with a known object. A database such as the internet is searched for objects which when discovered may be duplicated and stored. A determination is then made if any object from the database is confusingly similar with a known object. A computer-readable storage medium storing program for causing a processing system to perform the steps of duplicating objects from a database to produce duplicated objects; storing the duplicated produce to produce stored duplicated objects; and determining if any stored duplicated object is confusingly similar with a known object.
A method includes receiving one or more query images and identifying multiple features associated with an object or an activity using the one or more query images. The method also includes accessing a sparse representation index using the identified features. The sparse representation index includes a multi-dimensional polytope having multiple vertices and the features identify a point in the polytope. The method further includes identifying multiple vertices in the sparse representation index that are associated with the identified point and providing one or more images associated with the identified vertices. In addition the method includes identifying one or more clusters of features associated with the identified vertices and providing one or more additional images associated with the one or more identified clusters. The one or more clusters may be identified using a clustering index identifying the clusters and features of training images associated with the clusters.
Systems and methods for operating an avionics component to a level of certification. Steps include: receiving and sending data to a data monitor and an integrity monitor the data monitor operating at a first level of certification and the integrity monitor operating at a second higher level; using the integrity monitor determining where a feature of the data should appear on a display; checking if the feature properly appears and if not an error condition appears. The system includes: a sensor for sensing an aircraft condition; a data monitor for receiving and rendering data from the sensor the data monitor certified to a first category level; an integrity monitor for receiving the data from the sensor and for calculating where a feature of the data should appear on a data display the integrity monitor certified to a second higher level. If the feature does not properly appear an error condition appears.
A method for decomposing a target circuit pattern containing features to be imaged into multiple patterns. The process includes the steps of separating the features to be printed into a first pattern and a second pattern; performing a first optical proximity correction process on the first pattern and the second pattern; determining an imaging performance of the first pattern and the second pattern; determining a first error between the first pattern and the imaging performance of the first pattern and a second error between the second pattern and the imaging performance of said second pattern; utilizing the first error to adjust the first pattern to generate a modified first pattern; utilizing the second error to adjust the second pattern to generate a modified second pattern; and applying a second optical proximity correction process to the modified first pattern and the modified second pattern.
Various technologies and techniques are disclosed for providing bi-handwriting directional handwriting recognition and correction. A combined handwriting recognizer is provided that supports left-to-right and right-to-left language recognition by using a combined dictionary. The combined dictionary includes a dictionary from a language in a first direction along with a backwards version of a dictionary from a language in a second direction. The combined recognizer is used with the combined dictionary to generate a most likely recognition result for mixed direction hand written input received from a user. Character by character correction is provided for mixed left-to-right and right-to-left text. The most likely recognition result is displayed in a visual order. The user can correct a particular character to a different character. When recognized text needs to be sent to a separate application an inverse bi-directional process is performed to convert the text from the visual order to the logical order.
An automated image processing system and method are provided for class-based segmentation of a digital image. The method includes extracting a plurality of patches of an input image. For each patch at least one feature is extracted. The feature may be a high level feature which is derived from the application of a generative model to a representation of low level feature s of the patch. For each patch and for at least one object class from a set of object classes a relevance score for the patch based on the at least one feature is computed. For at least some or all of the pixels of the image a relevance score for the at least one object class based on the patch scores is computed. An object class is assigned to each of the pixels based on the computed relevance score for the at least one object class allowing the image to be segmented and the segments labeled based on object class.
A remote sensing and probabilistic sampling based method for determining carbon dioxide volume of a forest can correlate aerial data such as LiDAR CIR and/or Hyperspectral data with actual sampled and measured ground data to facilitate obtainment e.g. prediction of an accurate forest inventory and corresponding carbon dioxide volume thereof.
According to one aspect a method for identifying an object in an image includes steps of determining a center of the object; calculating a radius for scanning the image; scanning along a scan circle defined by the center and the radius; and identifying the object according to scanned data of the image along the scan circle.
An image processing method for deriving text characteristic images from an input image includes: performing a plurality of edge detecting processes upon the input image to generate a plurality of edge images respectively and deriving a first text characteristic image according to the edge images. The image detecting processes include: performing a first edge detecting process upon the input image to derive a first edge image according to a first upper threshold and a first lower threshold and performing a second edge detecting process upon the input image to derive a second edge image according to a second upper threshold and a second lower threshold.
Systems methods and computer program products for shape clustering and applications in processing various documents including an output of an optical character recognition OCR process. Clip images defined in a received OCR output are classified into a plurality of clusters of clip images. Clip images in each of the plurality of clusters are processed to generate a cluster image for each cluster. Shape differences between the cluster images of a first cluster and a second cluster and between the cluster images of the first cluster and a third cluster are used to determine a level of confidence in one or more first OCR character codes assigned to the first cluster.
A reading unit supplies card information that has been read from a card to a management unit by way of a read-out unit. The management unit assigns a high order of priority to card information that has been newly read and stores the card information to which this order of priority has been given in a memory unit. A fingerprint scanner supplies input fingerprint information to a selection unit by way of a generation unit. The selection unit upon receiving the input fingerprint information supplies this input fingerprint information to a collation unit and further selects a plurality of items of registered fingerprint information that are stored in the memory unit starting in order with items having the highest order of priority. The collation unit upon receiving the input fingerprint information collates this input fingerprint information with the registered fingerprint information in the order selected by the selection unit and determines whether registered fingerprint information that matches the input fingerprint information is present within the plurality of items of registered fingerprint information.
A pattern recognition system compares a set of unlabeled images or other patterns having a variation of state in a set-by-set comparison with individual data sets of multiple labeled images or other patterns also having a variation of state. The individual data sets are each mapped to a point on a parameter space e.g. a Grassmannian manifold a Stiefel manifold a flag manifold etc. and the set of unlabeled images is mapped to a point in the same parameter space. If the point associated with the set of unlabeled images satisfies a distance criterion on the parameter space with regard to one of the points on the parameter space the data set of unlabeled images is assigned to the class attributed to that point.
Techniques for performing page verification of a document are provided. The techniques include performing a recognition technique on a document to recognize one or more objects in the document excluding the one or more recognized objects from the document and performing page verification of the document wherein page verification comprises visual inspection of the document excluding the one or more recognized objects.
A ruled-line extraction section can be performed with high precision by providing a main-scanning ruled-line extraction section for determining whether a target pixel of binary image data of a document image is a black pixel or a white pixel for counting the number of black pixels connected one after another upstream in a main scanning direction with respect to the target pixel of the binary image data and for when the target pixel of the binary image data is a black pixel and when a value counted for the target pixel is not less than a main-scanning run determination threshold value that has been set in advance generating ruled-line image data by correcting to pixel values corresponding to black pixels pixel values of a predetermined number of pixels connected to the target pixel upstream in the main scanning direction.
As a user writes using a handheld writing device such as an electronic pen or stylus handwriting input is received and initially displayed as digital ink. The display of the digital ink is converted to recognized text inline with additional digital ink as the user continues to write. A user may edit a word of recognized text inline with other text by selecting the word. An enlarged version of the word is displayed in a character correction user interface that allows a user to make corrections on an individual character basis and also provides other correction options for the word.
In embodiments consistent with the subject matter of this disclosure a user may input one or more strokes as digital ink to a processing device. The processing device may produce and present a recognition result which may include a misrecognized portion. A user may indicate a desire to correct the misrecognized portion and may further select one or more strokes of the misrecognized portion. The processing device may then present the one or more recognition alternates corresponding to the selected one or more strokes of the misrecognized portion. In some embodiments the processing device may permit a user to rewrite the selected one or more strokes of the misrecognized portion with newly entered digital ink. Features such as rewriting and correction of the input digital ink may be discoverable in some embodiments.
An input pattern feature amount is decomposed into element vectors. For each of the feature vectors a discriminant matrix obtained by discriminant analysis is prepared in advance. Each of the feature vectors is projected into a discriminant space defined by the discriminant matrix and the dimensions are compressed. According to the feature vector obtained projection is performed again by the discriminant matrix to calculate the feature vector thereby suppressing reduction of the feature amount effective for the discrimination and performing effective feature extraction.
A method for detecting an image edge is provided. Pixel data of neighbor lines of an image are read to generate a first and a second inclined edge areas between two neighbor lines. The incline edge areas are determined by detecting whether a difference of two corresponding pixel data exceeds a preset edge threshold. Then whether there is an overlapped or nearby portion between the inclined edge areas is determined so as to find an incline edge.
When images are classified into categories which of the categories has important images can be understood easily without a burned on a user. For this purpose a category weight calculation unit statistically calculates a weight of each of the categories obtained by classification of the images based on at least one of characteristic quantities comprising the number of images therein found by considering similar images therein a total photography time thereof a rate of similar images therein a rate of human images therein and an average number of human faces therein.
A method is disclosed for automatically classifying and graphically visualizing image objects that are segmented and given undershooting of a prescribed distance and compliance with a similarity criterion are combined to form clusters. In at least one embodiment for object classification the method includes preselecting result data using a prescribable selection criterion from a result set of an application executed in the background on an image data record of an imaging system for feature extraction and automatic pattern recognition of segmented and clustered image objects and/or rendered image data of an image rendering application executed in the background for two-dimensional and/or three-dimensional graphic visualization of these image objects; and/or marking the data in a graphically visible fashion as preselected on a screen of a screen terminal.
Described is a system for anomaly detection to detect an anomalous object in an image such as a concealed object beneath a person s clothing. The system is configured to generate a subspace model for a normal class using training images. The normal class represents normal objects in a common class. The system receives a novel image having an object in the common class. A set of geometric landmarks are identified in the object in the novel image for use in registering the image. The novel image is registered by warping the image so that the geometric landmarks coincide in the novel image and the training images resulting in a warped novel image having an object. Thereafter the system determines if the object in the warped novel image is anomalous by measuring the distance of the warped novel image from the subspace model. Finally if anomalous an operator is notified accordingly.
In a system for providing an illegal use research service for image data the image data received from a terminal apparatus is registered as a research subject a research condition for research whether or not the image data being registered is illegally used by a Web site on the network is set image data that are identical or similar to the image data being the research subject from a web site on the network are searched for based on a feature amount and the research condition and a search result is informed as a research report to the research client using said terminal apparatus.
A linear transformation matrix calculating apparatus linearly transforms a plurality of dictionary subspaces which belong to respective categories by a linear transformation matrix respectively selects a plurality of sets of two dictionary subspaces from the plurality of linearly transformed dictionary subspaces calculates a loss function using similarities among the selected sets of dictionary subspaces respectively calculates a differential parameter obtained by differentiating the loss function by the linear transformation matrix calculates a new linear transformation matrix from the differential parameter and the linear transformation matrix by Deepest Descent Method and updates the new linear transformation matrix as the linear transformation matrix used in the linear transformation unit.
A number of regions and partitions may be created based on input handwritten atoms and a grammar parsing framework. Productions for tabular structures may be added to the grammar parsing framework to produce an extended grammar parsing framework. Each of the regions may be searched for a tabular structure. Upon finding a tabular structure a type of tabular structure may be determined. Configuration partitions may be created based on the added productions and added to the created partitions. A set of configuration regions may be created based on the configuration partitions and added to the created regions. The productions for tabular structures and productions of the grammar parsing framework may be applied as rewriting rules to the atoms to produce possible recognition results. A best recognition result may be determined and displayed. A mechanism for correcting misrecognition errors which may occur while recognizing tabular structures may be provided.
Browser controlling method and system using an image are provided. The method includes inputting an image; recognizing the image; and executing a command based on the recognized image. Accordingly the command based on the user s input image can be executed in the browser. Also since the browser does not need to display various function buttons the screen can be utilized more efficiently.
The number of pixels in an identified pixel region is counted a feature point of the pixel region is extracted and the number of the feature points is counted when the number of the pixels counted has been determined to be equal to or higher than a first threshold value whether the counted number of the feature points is equal to or lower than a second threshold value is determined features is calculated based on the feature point extracted from the pixel region when the number of the feature points has been determined to be above the second threshold value and the first threshold value is changed when the number of the feature points has been determined to be equal to or lower than the second threshold value. Image similarity determination process can be stably performed without any degradation in determination accuracy.
A method of forming a combined feature boundary based on boundaries of first and second overlapping features includes dividing the boundaries of the first and second overlapping features into line segments of known shape identifying crossing points formed by the line segments calculating parametric coordinates of the crossing points and determining a sequence of crossing point evaluation based on the parametric coordinates. The method also includes calculating a first cross product based on the line segments forming a first crossing point in the determined sequence and choosing a first path of the combined feature boundary according to a mathematical sign of the first cross product the first path extending from the first crossing point to the second crossing point in the determined sequence. The method further includes calculating a second cross product based on the line segments forming a second crossing point in the sequence and choosing a second path of the combined feature boundary extending from the second crossing point according to a mathematical sign of the second cross product wherein the combined feature boundary includes the first and second crossing points and portions of at least one of the first and second feature boundaries defining the first and second paths.
A system and method for determining inflection points in an image of an object includes obtaining the image of the object performing binary image processing on a border of the image to obtain border points selecting a predetermined number of the border points to fit a straight line calculating a vertical distance between each selected border point and the straight line and obtaining a total distance. The method further includes adding a new border point to the selected border points if the total distance is less than a predetermined value so as to fit a new straight line and do a loop cycle otherwise regarding a last border point of the selected border points as an inflection point and sequentially selecting the predetermined number of other border points to fit another new straight line.
In one embodiment a document authentication station for use with passports or the like includes a 2D image sensor e.g. CCD- or CMOS-based video camera and a computer device. The image sensor produces produce image data corresponding to a presented document. From this image data the computer extracts two or more identification data. One is a digital watermark. The other can be a bar code data glyphs OCR data etc. The processor then proceeds to check that the two identification data correspond in an expected fashion. If not the document is flagged as suspect or fake. Reliability of detection can be enhanced by processing plural frames of data from the image sensor before issuing a result.
A method for reconstructing three-dimensional plural views of images from two dimensional image data. The method includes: obtaining two-dimensional stereo digital data from images of an object; processing the digital data to generate an initial three-dimensional candidate of the object such process using projective geometric constraints imposed on edge points of the object; refining the initial candidate comprising examining spatial coherency of neighboring edge points along a surface of the candidate.
Systems and methods for visual language modeling for image classification are described. In one aspect the systems and methods model training images corresponding to multiple image categories as matrices of visual words. Visual language models are generated from the matrices. In view of a given image for example provided by a user or from the Web the systems and methods determine an image category corresponding to the given image. This image categorization is accomplished by maximizing the posterior probability of visual words associated with the given image over the visual language models. The image category or a result corresponding to the image category is presented to the user.
An interest point detection technique is presented. More particularly for each of possibly multiple image pyramid resolutions a cornerness image is generated. One or more potential interest point locations are identified in the cornerness image. This involves finding locations associated with a pixel that exhibits a higher corner strength value than pixels in a prescribed-sized surrounding pixel neighborhood. The potential interest point locations are then clustered to identify groups that likely derive from a same 2D structure. Potential interest point locations in one or more of the identified groups are respectively combined to produce a single location that represents the combined group. The representative location of each group having one is then designated as an interest point. An optional location refinement can also be implemented.
A near-infrared night vision device to which a pedestrian detection device is applied includes a near-infrared projector a near-infrared camera a display and an ECU. By executing programs the ECU constitutes a pedestrian candidate extraction portion and a determination portion. The pedestrian candidate extraction portion extracts pedestrian candidate regions from near-infrared images. The determination portion normalizes the sizes and the brightnesses of the pedestrian candidates extracted by the pedestrian candidate extraction portion and then computes the degrees of similarity between the normalized pedestrian candidates. The determination portion determines that a pedestrian candidate having two or more other pedestrian candidates whose degree of similarity with the pedestrian candidate is greater than or equal to a predetermined value is not a pedestrian.
A handwriting apparatus includes unit acquiring first-handwriting data unit storing one-stroke-handwriting data and a first command as an instruction the instruction corresponding to the one-stroke-handwriting data and being executed with a device unit when the first-handwriting data corresponds to one stroke searching the storage unit for the first command corresponding to the one-stroke-handwriting data corresponding to the one stroke unit planning to execute the first command when the corresponding first command is searched out from the storage unit unit storing one-stroke-handwriting data and a second command as an instruction which corresponds to the one-stroke-handwriting data the second command being different from the first command unit regarding the first-handwriting data as one-stroke-handwriting data at time intervals and search the storage unit for the second command corresponding to the one-stroke-handwriting data and unit when the corresponding second command is searched out from the storage unit planning to execute the corresponding second command.
An image processing apparatus includes a command-data storage unit a handwritten-data recognizing unit and a matching unit. The command-data storage unit stores therein a command-data table that contains a command character and content of a command corresponding to the command character in an associated manner. The handwritten-data recognizing unit performs character recognition and image analysis on image data to extract handwritten information including a command graphic representing a command with respect to the image data and a command character handwritten near the command graphic. The matching unit matches the command character extracted by the handwritten-data recognizing unit with the command character in the command-data table.
A position and an area of a region to be processed that is a region from which image feature parameters are to be extracted are obtained and the number of pixels required for obtaining the usable image feature parameters is determined in accordance with types of the image feature parameters to be extracted. Then a required resolution is calculated in accordance with the determined number of pixels and the area of the region to be processed an image having a minimum resolution which is equal to or higher than the required resolution and which is usable to extract the usable image feature parameters is selected and the image feature parameters are extracted from a region to be processed in the selected image.
A reference image and features of the reference image are stored in a hash table in such a manner that the reference image and the features are related to each other. A storage region of the hash table is divided into a plurality of divided regions and each divided region is related to a storage condition under which a reference image is stored in the divided region. When a reference image is stored in the hash table a storage region where the reference image is to be stored is selected out of the plurality of divided regions in accordance with the storage condition. This allows shortening a time for updating a reference image and reducing a workload on means for updating the reference image.
Provided is an apparatus for improving the sharpness of an image. The apparatus includes an edge detector an effective edge judging unit an effective edge classifying unit an isolated edge judging unit and a 2-D HPF applying unit. The edge detector calculates an edge value using brightness relation with neighboring pixels with respect to each of pixels of an input image. The effective edge judging unit determines effective edge pixels. The effective edge classifying unit determines weak edge pixels and strong edge pixels. The isolated edge judging unit judges an isolated edge pixel included in an isolated edge. The 2-D HPF applying unit applies a first 2-D HPF to the weak edge pixels and applies a second 2-D HPF to the strong edge pixels to generate edge strengthening values. The edge strengthening value applying unit adds the edge strengthening values to brightness values of the respective pixels of the input image.
Techniques for shape clustering and applications in processing various documents including an output of an optical character recognition OCR process. The output of an OCR process is classified into a plurality of clusters of clip images and a representative image for each cluster is generated to identify clusters whose clip images were incorrectly assigned character codes by the OCR process.
Kernelized spatial-contextual image classification is disclosed. One embodiment comprises generating a first spatial-contextual model to represent a first image the first spatial-contextual model having a plurality of interconnected nodes arranged in a first pattern of connections with each node connected to at least one other node generating a second spatial-contextual model to represent a second image using the first pattern of connections and estimating the distance between corresponding nodes in the first spatial-contextual model and the second spatial-contextual model based on a relationship with adjacent connected nodes to determine a distance between the first image and the second image.
A form processing program which is capable of automatically extracting keywords. When the image of a scanned form is entered a layout recognizer extracts a readout region of the form image a character recognizer recognizes characters within the readout region. A form logical definition database stores form logical definitions defining strings as keywords according to logical structures which are common to forms of same type. A possible string extractor extracts as possible strings combinations of recognized characters each of which satisfies defined relationships of a string. A linking unit links the possible strings according to positional relationships and determines a combination of possible strings as keywords.
The present invention relates to a method for aligning a camera sensor to significant data which is text or barcode data to be recognized comprising the steps of:&#x2014;capturing an image of the significant data by means of the camera sensor; &#x2014;detecting a predominant alignment line of the significant data and detecting an angle thereof in relation to a horizontal line of the captured image; &#x2014;determining image sections within the edge and line enhanced image which contain most likely significant data lines; &#x2014;selecting a representative image section out of the determined image sections which is aligned with the predominant alignment line; &#x2014;capturing a following image of the significant data; tracking the representative image section and determining the predominant alignment line out of the representative image section to achieve a fast calculation and audio or tactile feedback of the alignment quality to the user.
Words possibly included in a scene image shot by a mobile camera can be efficiently extracted using a word dictionary or a map database. Positional information acquiring means 101 measures a current position of the device to acquire positional information. Directional information acquiring means 102 detects a direction of the device to acquire directional information. Character recognizing means 104 determines a range of shooting of a scene image based on the current positional information and the directional information. The character recognizing means 104 extracts from a map database 103 information such as store names building names and place names associated with positions in the shooting range. Then the character recognizing means 104 conducts character recognition using word knowledge such as the extracted store names building names and place names.
A method of detecting and compensating fail pixels in a holographic storage system. The method includes steps of: providing a plurality of image frames to show on a data plane for all pixels on the data plane being capable of outputting a light state or a dark state; sequentially recording the image frames into a storage medium; detecting the image frames by using a detecting apparatus for all pixels on the detecting apparatus being capable of outputting sensing signals corresponding to the light state and the dark state; defining a sensing difference value which is a difference of the sensing signal outputting the light state and the dark state generated by one pixel; comparing the sensing difference value with a threshold value; and defining the corresponding pixel is a fail pixel if the sensing difference value is smaller than the threshold value.
A face recognition system based on adaptive learning includes a specific person detection and tracking unit for detecting and tracking a specific person from a moving image. A facial feature extraction unit extracts a plurality of facial feature vectors from the detected and tracked specific person. A face recognition unit searches for a given registration model by comparing the extracted facial feature vectors with facial feature vectors of the registration models previously stored in a user registration model database. A learning target selection unit selects a facial feature vector to be added to a record of the given registration model from among the extracted facial feature vectors. A registration model learning unit adds and updates the selected facial feature vector to the record of the given registration model.
A method for determining a classification for a video segment comprising the steps of: breaking the video segment into a plurality of short-term video slices each including a plurality of video frames and an audio signal; analyzing the video frames for each short-term video slice to form a plurality of region tracks; analyzing each region track to form a visual feature vector and a motion feature vector; analyzing the audio signal for each short-term video slice to determine an audio feature vector; forming a plurality of short-term audio-visual atoms for each short-term video slice by combining the visual feature vector and the motion feature vector for a particular region track with the corresponding audio feature vector; and using a classifier to determine a classification for the video segment responsive to the short-term audio-visual atoms.
An image processing method comprises: clustering images of a set of images to generate a plurality of scenes each comprising an unordered cluster of images; ordering images within scenes respective to video coherence to generate ordered scenes comprising ordered sequences of images; and generating video content as images ordered in accordance with the ordered sequences of images comprising the scenes. In some embodiments the video content is converted to video comprising video frames played at a predetermined frame rate.
The present invention provides a technique of accurately extracting areas of characters included in a captured image even in a case where noise or dirt of a relatively large area occurs in a background image. A pixel value integration evaluation value is obtained by integrating pixel values in a character extracting direction B at each of the pixel positions in a character string direction A of an image including a character string. A waveform of the value is expressed as waveform data. A first threshold and a second threshold are set for the waveform data. An area in which the waveform data exceeds the first threshold is set as a character candidate area. In a case where an area in which the pixel value integration evaluation value exceeds the second threshold exists in the character candidate areas the character candidate area is regarded as a true character area and the characters are extracted.
The present invention provides a technique of accurately extracting areas of characters included in a captured image even in a case where noise or dirt of a relatively large area occurs in a background image. An integrated pixel value is obtained by integrating pixel values in a character extracting direction B for pixel positions in a character string direction A of an image including a character string. A standard deviation value is calculated along the character extracting direction for pixel positions in a character string direction A. The integrated pixel value and the standard deviation value are combined for pixel positions in a character string direction A. A threshold is set automatically or manually. A part of pixel positions in a character string direction A having the combined value of the integrated pixel value and the standard deviation value higher than the threshold is recognized as a character area to be extracted.
A system that offers a method of capturing analyzing and visualizing a matrix of data for object and feature extraction. This is accomplished by reading a matrix of data represented by a plurality of data types into a processor via a data capture system. The matrix of data is overlaid by a control grid to form a regular matrix having a plurality of cells. A data search spatial radius is created from a point in each cell. Data is then processed from the matrix and certain characteristics are captured and represent each variable in each cell of the matrix and then output respectively.
A system for correcting image characteristic data from a plurality of pixels comprises at least one field programmable gate array FPGA a lookup table and a correction module. The FPGA may include a plurality of configurable logic elements and a plurality of configurable storage elements. The lookup table may be accessible by the FPGA and may store a plurality of correction components associated with each pixel including a gain value an offset value and a bad pixel value. The correction module may be formed from the configurable logic elements and configurable storage elements and may receive the characteristic data and the correction components. The correction module may generate corrected data for each characteristic data by utilizing the gain value the offset value and the bad pixel value.
A computer-implemented system and method for retrieving a digital image through document image decomposition is provided. A stored digital image is retrieved. Generic visual features are extracted. The features are grouped into a primitive layer including word-graphs that each include words and features. The words are grouped into a layout layer including zone hypotheses that each include one or more of the words. Causal dependencies between the word-graphs and the zone hypotheses are expressed through zone models that include a joint probability defining a pair of probabilistic models generated through a learned binary edge classifier. Each pair of probabilistic models is expressed as an optimal set selection problem including a set of cost functions and constraints. The optimal set selection problem is evaluated through a heuristic search of the cost functions and constraints and a non-overlapping optimal set of the zone hypotheses is provided that characterize the stored digital image.
A method and system corrects for drift in spectrum images resulting from collection signals. Signals resulting from a scan are collected. A reference image is obtained for determining initial pixel locations. A correction image is extracted validated and correction vectors generated.
In an exemplary embodiment of the present invention an automated computerized method is provided for processing an image. According to a feature of the present invention the method comprises the steps of generating spatio-spectral information for the image defining a constraint as a function of the spatio-spectral information and performing an optimization operation as a function of the constraint to generate an intrinsic image corresponding to the image.
An inspection apparatus and method outputs an accurate matching position even if a search image contains a pattern similar to a template. An image search unit includes a relative position comparing unit which compares the relative position of a template in a template selection image with the relative position of a location currently being searched for in a search image and outputs the amount of position mismatch between the relative positions. A matching position determining unit determines a matching position by taking into consideration the amount of position mismatch in addition to search image similarity distribution information.
The present invention relates to a system and a method for comparing information contained on at least two documents belonging to an entity. The present invention includes at least one device configured to receive information from at least one first document and at least one second document; then compare at least one first document information and at least one second document information; and determine whether at least one second document contains at least one first document information. The present invention then outputs a result of whether the at least one second document contains at least one first document information.
There is provided an image processing apparatus including a character recognition section that executes character recognition on an input document image and outputs a character recognition result an item name extraction section that extracts a character string relevant to an item name of an information item from the character recognition result an item value extraction section that extracts a character string of an item value corresponding to the item name from the vicinity of the character string relevant to the item name in the document image and an extraction information creation section that creates extraction information by associating the character string of the item value extracted by the item value extraction section to the item name.
A method performed by a mobile terminal may include receiving an image that includes text translating the text into another language and superimposing and displaying the translated text over the received image.
An information processing apparatus includes a selecting unit for selecting extraction information concerning contents to be extracted from among a plurality of contents organized in time sequence the extraction information prepared on a per content basis for the contents to be extracted and including a feature contained in the content to be extracted and an extraction range that is represented with respect to the position of the feature a detecting unit for detecting from the contents the same feature as the feature contained in the extraction information selected by the selecting unit and an extracting unit for extracting a predetermined content in accordance with the extraction range contained in the extraction information selected by the selecting unit if the detecting unit detects the same feature as the feature contained in the extraction information.
A driver s eye condition detection is conducted by an eye condition detection apparatus including a right/left near-infrared light sources a camera and an ECU installed therein. The right side near-infrared light source is positioned on a right side relative to the camera in a driver s view and a light axis of the right side near-infrared light source is tilted to the right by 15 to 45 degrees relative to an imaging direction of the camera. Further the left side near-infrared light source is positioned on a left side relative to the camera in a driver s view and a light axis of the right side near-infrared light source is tilted to the left by 15 to 45 degrees relative to an imaging direction of the camera. In this manner detection errors of the driver s eye condition are reduced.
A medical image processing method for image processing of a medical image picking up an image of a living mucous comprises a boundary information detecting step for detecting boundary information corresponding to a boundary portion of a living mucous from the medical image and a mucous feature detecting step for detecting presence of a living mucous with a different feature on the basis of the boundary information detected at the boundary information detecting step.
A plurality of type identifiers are stored that contains one or a plurality of image identifiers each for identifying each of a plurality of reference images and thereby identifies a type of a document. Then it is determined whether each of a plurality of obtained document images is similar to a reference image. When a document image is determined as being similar to a reference image an image identifier that identifies the reference image is selected from among a plurality of image identifiers. Then a type identifier is identified that contains the selected image identifier. Then document images each similar to a reference image are classified for each identified type identifier.
A method and system for automatically analyzing and searching a database of images or other digital content includes a process for analyzing images to identify portions capable of receiving text. In one implementation user input is received where the user input helps construct a profile matrix representing image features desired by the user. The constructed profile matrix is compared to profile matrices of the database of images and images are retrieved with profile matrices corresponding to the constructed profile matrix.
According to an embodiment an image processing apparatus includes a generation unit. The generation unit generates a texture image by searching for a similar pixel area to a processed pixel area near a processing target pixel in the texture image from a neighboring area at a position corresponding to the processing target pixel in a sample texture image and assigning the processing target pixel a pixel value near the similar pixel area in accordance with a positional relationship between the processed pixel area and the processing target pixel. The generation unit searches for the similar pixel area based on a similarity between a pixel value in a pixel area in the neighboring area and a pixel value in the processed pixel area and a determination result indicating whether each pixel in the neighboring area expresses a same object as that expressed by the processing target pixel.
A device for forming a random set of playing cards comprises a card in-feed area a shuffling system a card removal area and a card reading system located within the device the card reading system employing a complementary metal-oxide semiconductor CMOS sensor and a hardware component the hardware component capable of converting signals from the CMOS sensor into vector sets and comparing the vector sets to known vectors to determine rank and suit.
A sensing apparatus is provided for the determination of at least one of rank or suit of a playing card. The sensing apparatus includes an imaging array capable of sensing at least an area of a playing card that represents rank and or suit. A position sensor is provided for determining card position. A hardware component receives signals from the imaging array and the card position sensor. The hardware component forms a vector set from the output from the imaging array and card position sensor and compares the vector set to known reference vector sets to determine rank and suit of a card.
The present invention discloses an identifying method of hand-written Latin letter. The present invention considers many hand-written styles of Latin letter extract many stable characteristics of Latin letter of different hand-written styles and classify the Latin letter aggregation each time with one characteristic so that the whole standard Latin letter aggregation is classified into many small Latin letter aggregations with intersection to be the coarse classification candidate letter aggregations to be identified. When identifying the inputted hand-written Latin letter obtain the coarse classification candidate letter aggregation that matches with the characteristics of the inputted hand-written Latin letter. Many stable characteristics ensure the identifying rate. The multilayer coarse classification candidate letter aggregations regulate the searching path and increase the identifying speed.
The automatic Arabic text image optical character recognition method includes training a text recognition system using Arabic printed text using the produced models for classification of newly unseen Arabic scanned text and generating the corresponding textual information. Scanned images of Arabic text and copies of minimal Arabic text are used in the training sessions. Each page is segmented into lines. Features of each line are extracted and input to Hidden Markov Model HMM . All training data training features are used. HMM runs training algorithms to produce codebook and language models. In the classification stage new Arabic text is input in scanned form. Line segmentation where lines are extracted is passed through. In the feature stage line features are extracted and input to the classification stage. In the classification stage the corresponding Arabic text is generated.
Embodiments of a computer system a method and a computer-program product e.g. software for use with the computer system are described. These embodiments may be used to identify and correct errors in financial information that was extracted using character-recognition software such as optical character recognition software and/or intelligent character recognition software. In particular potential errors may be identified by comparing the financial information for a current financial transaction of a user with expected financial information from one or more previous financial transactions of the user. Error metrics for these potential errors may be determined and used to correct at least some of the potential errors. For example values of the Levenshtein edit distance may be determined based on the comparison and one or more potential errors associated with one or more minimum values of the Levenshtein edit distance may be corrected.
The present invention provides a 3D handwriting recognition system that allows users to freely write words or characters in a 3D space in a touchless manner without requiring any physical medium such as a pad or a tablet. The users handwriting input in a 3D space will be tracked by an input device of the system that generates corresponding 3D motion data and wirelessly transfers the 3D motion data to a recognition device of the system. The 3D motion data will be converted and then mapped onto a 2D plane to generate corresponding 2D images for handwriting recognition. In this way the users inputting will never be limited to any screen pad or plane and the users will have more flexibility and enjoyable writing experience.
This invention describes an efficient super-resolution method for image enhancement that leverages prior knowledge about the specific task for which detail information is recovered. The particular case of barcode scanning is considered. The barcode localization and decoding algorithm of the present invention employs a subpixel-accurate search algorithm which allows for estimating barcode bit values at a higher resolution than that available in the image data itself. It thus allows for the synthesis of image detail from multiple frames with the result containing more detail than any of the input frames. For efficiency it leverages special properties of the quadrilateral target object as well as prior knowledge about constant patterns in the barcodes of interest. This allows for real-time software implementations on portable devices such as camera-equipped cell phones where super-resolution helps to overcome some of the typical camera resolution and processing power constraints.
A system and method for identifying an image based on singular value decomposition is provided. The system includes: a feature point extracting module for extracting at least one of feature points from an input image using strength of a Gaussian curvature of each pixel from the input image; an identifier detecting module for detecting a local identifier based on SVD singular value decomposition for blocks adjacent to the extracted feature points; and a matching module for determining whether an image is duplicated or not by comparing the detected local identifier from the identifier detecting module with an image database storing at least one of images.
A method for visual recognition of an object in an electronic image includes extracting unique points of an object to be learned and/or a target object. The unique points are obtained by cross-correlating the image with a structure. Generally the structure and/or the size of the structure may vary to detect extremum information associated with the learned object and/or target object. An icon corresponding to each of the unique points is extracted. The size of the icon corresponds to the scale of the unique point. After extraction of the various icons an object becomes a collection of icons. Each of these icons is un-rotated and normalized or resized to a constant size so it can be compared with other icons. One of the unique properties of these icons is their stability over scale and angle. Thus this invention allows the recognition of an image s or object s from large number of trained images or objects very quickly.
Aspects of the present invention relate to systems methods and devices for detection of text in an image using an initial text classification result and a verification process.
The present invention relates to a method of and apparatus for image analysis and in particular may relate to the detection of cross-fades in film or video sequences. The invention relates in particular to a method of analysing an image of a sequence of images to determine a cross-fade measure based on determined temporal picture information transitions associated with picture elements of the image. In particular the cross-fade measure may be determined based on the extent to which the temporal picture information transitions are uniform. The method and apparatus of the invention can provide a measure of likelihood of a cross-fade in a single pass. In addition the described method can be accomplished in real-time or close to real-time. In addition the cross-fade detection results are comparable with or better than the results achieved by the prior art methods.
According to one embodiment an electronic apparatus extracts face images of persons from video content data and outputs timestamp information indicating time points at which each extracted face image appears in the video content data and displays face images in each column of a plurality of face image display areas arranged in a matrix based on the time stamp information. The apparatus detects presence or absence of a face area in each frame consisting of the video content data and decides a cutout range of the detected face area. And the apparatus adjusts a case in which the cutout range of the decided face area protrudes outside the frame.
Embodiments of computer implemented methods and systems for object clustering and identification are described. One example embodiment includes receiving an unclustered video object determining a first distance between the unclustered video object and an arbitrary representative video object the arbitrary representative video object being selected from representative video objects estimating distances between the unclustered video object and the representative video objects based on the first distance and precalculated distances between the arbitrary representative video object and the representative video objects and based on the estimated distances selectively associating the unclustered video object with a video cluster thereby producing a clustered video object.
Statistical approaches to large-scale image annotation are described. Generally the annotation technique includes compiling visual features and textual information from a number of images hashing the images visual features and clustering the images based on their hash values. An example system builds statistical language models from the clustered images and annotates the image by applying one of the statistical language models.
A media analysis tool is provided for defining dynamic regions of a digital media segment. The dynamic regions may contain at least part of a visible feature of the segment. Correlation of the defined regions with external data quantifying attention of a subject viewing the segment to locations on the screen provides measures of interest level and attention to visible features in the segment. The dynamic regions may be defined in only some of the frames of a segment. The dynamic region may be interpolated or extrapolated for frames in which it is not explicitly defined.
Embodiments of the invention disclose a system and a method for determining points of parabolic curvature on a surface of a specular object from a set of images of the object is acquired by a camera under a relative motion between a camera-object pair and the environment. The method determines directions of image gradients at each pixel of each image in the set of images wherein pixels from different images corresponding to an identical point on the surface of the object form corresponding pixels. The corresponding pixels having substantially constant the direction of the image gradients are selected as pixels representing points of the parabolic curvature.
An image processing apparatus sets respective pixel values of a template block which includes a pixel to be determined for each pixel to be determined set in sequence in an image arranges a plurality of reference blocks so as to surround the template block obtains respective block matching errors between the respective pixel values of the plurality of reference blocks and the respective pixel values of the template block and determines that the pixel to be determined is in an edge area when a smallest value from among the block matching errors is a deviated value from all the block matching errors.
A method for comparing a first drawing and a second drawing generated by a shape-based computer system includes: a In no particular order: 1 identifying shapes present in the first drawing; and 2 identifying shapes present in the second drawing. b In no particular order: 1 identifying deleted shapes; the deleted shapes being present in the first drawing and not present in the second drawing; and 2 identifying new shapes; the new shapes being present in the second drawing and not present in the first drawing. c In no particular order: 1 indicating the deleted shapes in the first drawing; and 2 indicating the new shapes in the second drawing.
A method and electronics circuit for processing very high resolution images or very high frame rate images in real time. Each pixel within a frame of pixels is compared to the neighboring pixels within the frame to determine if the pixel is part of a blob group. If the pixel is part of the blob group the characteristics of the pixel are added to the statistics for the blob group. When a pixel overlaps two target blob groups the two blob groups are combined to form one blob group. When the end of the frame is reached information about the blob groups in the frame is made available.
A matching apparatus and method compares a set of feature points of two objects projected to an N-dimensional space and determines the similarity between the objects and includes mapping the set to a one-dimensional space creating a set of pairs of a feature point of first object that is the most approximate to a feature point of second object partly extracting the pairs in small order of the pair distance from the set of the pairs of the feature points and creating a partial set of the pairs of the feature points calculating a rating-scale of the pair belonging to the partial set of the pair of the feature points and determining the similarity between the first object and the second object on the basis of an average value of the distance.
A method for correlating or finding similarity between two data sets. The method can be used for correlating two images with common scene content in order to find correspondence points between the data sets. These correspondence points then can be used to find the transformation parameters which when applied to image 2 brings it into alignment with image 1. The correlation metric has been found to be invariant under image rotation and when applied to corresponding areas of a reference and target image creates a correlation surface superior to phase and norm cross correlation with respect to the correlation peak to correlation surface ratio. The correlation metric was also found to be superior when correlating data from different sensor types such as from SAR and EO sensors. This correlation method can also be applied to data sets other than image data including signal data.
A system and method for displaying groups of cluster spines is provided. Groups of cluster spines are obtained. Each group includes one or more spines with one or more clusters each associated with at least one concept. Group concept score vectors are generated for each of the spine groups by aggregating the concepts for that spine group. The group concept score vectors for the spine groups are compared and those spine groups that are unique are identified. The unique spine groups are placed into a display by arranging the unique spine groups at equal distance angles around a center ring provided in the display.
The object of the invention is to achieve a correctly positioned print in duplex-printing mode. A method for the detection of marks 1 1 ; 1 ; by a sensor array 10 for a printing machine has been provided whereby the marks 1 on the first recto printing side 5 of a sheet 3 are detected the sheet is turned over and shifted in a direction transverse to the transport direction and the marks 1 ; on a second verso printing side 6 of said sheet are detected. Furthermore a printing machine is provided with an alignment device 40 for shifting a sheet 3 in a direction transverse to the transport direction for the detection of marks 1 ; on the second printing side said marks being offset relative to the marks 1 on the first printing side after said sheet 3 has been turned over.
Described is a technology by which online recognition of handwritten input data is combined with offline recognition and processing to obtain a combined recognition result. In general the combination improves overall recognition accuracy. In one aspect online and offline recognition is separately performed to obtain online and offline character-level recognition scores for candidates hypotheses . A statistical analysis-based combination algorithm an AdaBoost algorithm and/or a neural network-based combination may determine a combination function to combine the scores to produce a result set of one or more results. Online and offline radical-level recognition may be performed. For example a HMM recognizer may generate online radical scores used to build a radical graph which is then rescored using the offline radical recognition scores. Paths in the rescored graph are then searched to provide the combined recognition result e.g. corresponding to the path with the highest score.
Disclosed is a device and method for inputting characters or drawings on a mobile terminal using a virtual screen. To input characters or drawings through a virtual screen the mobile terminal includes an electronic pen a virtual screen generator a position detector for detecting the electronic pen position and a character recognition algorithm for recognizing a trail as a character. When a signal is input from the electronic pen the mobile terminal detects the originating position of the signal and its trail. The mobile terminal recognizes the detected trail as a character and generates a virtual screen with the recognized character.
An image registration system for aligning first and second images. The novel system includes a first system for extracting a region of interest ROI from each image and a second system for coarsely aligning the regions of interest. The first system determines the size and location of the ROI based on the number of features contained within the region. The size of the ROI is enlarged until a number of features contained in the ROI is larger than a predetermined lower bound or until the size is greater than a predetermined upper bound. The second system computes a cross-correlation on the regions of interest using a plurality of transforms to find a coarse alignment transform having a highest correlation. The image registration system may also include a third system for performing sub-pixel alignment on the regions of interest.
Aspects of the present invention relate to methods and systems for determining image characteristics in a digital image.
An object recognition device includes: a model image processing unit having a feature point set decision unit setting a feature point set in a model image and detecting the feature quantity of the feature point set and a segmentation unit segmenting the model image; a processing-target image processing unit having a feature point setting unit setting a feature point in a processing-target image and detecting the feature quantity of the feature point; a matching unit comparing the feature quantities of the feature points set in the model image and in the processing-target image so as to detect the feature point corresponding to the feature point set and executes a matching; and a determination unit determining the processing result in the matching unit so as to determine presence/absence of a model object in the processing-target image.
A method for characterizing a shape of an object surface includes acquiring image data including the object. The image data is analyzed at a locus of points that are at a predetermined distance from a point of interest proximate to the object surface to determine which of the locus of points represents a foreground and which of the locus of points represents a background. The shape of the object surface is characterized based on the characterization of the locus of points.
The image feature extraction method of the present invention includes: the step of performing k2 dividing process at least once on a given image so as to convert the given image into a multi-divided image where the k2 dividing process comprises the steps of: a creating matrix T based on image matrix X; b computing singular values of the matrix T; c determining whether or not minj|&#x3c3;j&#x2212;&#x3c3;j&#x2212;1|&#x3e;&#x3b5;; d if the result of the determination in the step c is &#x201c;No&#x201d; returning to the step c subsequent to computing the singular values of the enlarged matrix T&#x3b1;; e if the result of the determination in the step c is &#x201c;Yes&#x201d; obtaining U which satisfies T=USVT; f obtaining matrix T1=UTT; and g creating image matrix X1 based on matrix T1.
An image processing apparatus for processing a previous image having first pixels and a present image having second pixels. The image processing apparatus includes: a pixel difference calculating unit which calculates pixel differences between corresponding pairs of the first and second pixels and outputs pixel difference values; an edge processing unit which detects and compares edge types of the first and second pixels sums a number of the edge types that are the same and outputs a sum value; a noise level processing unit which calculates a noise level of the present image according to the sum value and the pixel differences; a blending value determining unit which determines a blending value according to the noise level; and an output unit which adds weights of the present and previous images according to the blending value and outputs an output image. An image processing method is also disclosed.
An image processing apparatus includes: an image pyramid forming section configured to form an image pyramid by hierarchically creating layered image data including differently scaled images from inputted image data; a position calculating section configured to determine an in-image-pyramid position as a height position in the image pyramid to which template image data having an image portion of a target object at a fixed scale corresponds; an upper-layer-side likelihood calculating section configured to determine a likelihood for a target object by matching between upper-side layer image data directly above the in-image-pyramid position and a state prediction; a lower-layer-side likelihood calculating section configured to determine a likelihood for a target object by matching between lower-side layer image data directly below the in-image-pyramid position and a state prediction; and a true likelihood calculating section configured to determine a true likelihood from the likelihoods determined by the upper-layer-side and lower-layer-side likelihood calculating sections.
A system includes a motion detection processor a motion tracking processor a people detection processor a controller a fusion processor an appearance model generator processor a database a fast search processor and a matching processor. The motion detection processor the motion tracking processor the controller the people detection processor the fusion processor and the appearance model generator processor comprise an analytics pipeline and the database and the fast search processor comprise a data index pipeline.
A device and method for processing an image to create appearance and shape labeled images of a person or object captured within the image. The appearance and shape labeled images are unique properties of the person or object and can be used to re-identify the person or object in subsequent images. The appearance labeled image is an aggregate of pre-stored appearance labels that are assigned to image segments of the image based on calculated appearance attributes of each image segment. The shape labeled image is an aggregate of pre-stored shape labels that are assigned to image segments of the image based on calculated shape attributes of each image segment. An identifying descriptor of the person or object can be computed based on both the appearance labeled image and the shape labeled image. The descriptor can be compared with other descriptors of later captured images to re-identify a person or object.
The invention relates to a method for handwriting detection using a handwriting tool 2 being arranged for communicating with a further device 2 and comprising the following steps: recognizing characters using detection of movements carried out by means of said handwriting tool 2 ; determining the probability factor of at least one input character corresponding to a given character; and using said probability factor in a step for correction completion and prediction of words being formed by said characters. The invention also relates to a device for such handwriting detection.
A feature point detection unit 153 and feature amount extraction unit 154 extract a plurality of features of an object from input image data. When there are unextracted features of the plurality of features a weight setting unit 155 sets weights for the extracted features. A facial expression determination unit 156 executes recognition processing of the object based on the features weighted by the weight setting unit 155 .
An image data processing system includes an extracting unit extracting from an image signal corresponding to one image a signal corresponding to a pixel block including plural pixels in the image a threshold calculating unit calculating a threshold for classifying the plural pixels into plural segments by linear calculation of display values of the plural pixels a representative value calculating unit calculating plural representative values corresponding to the plural segments a generating unit generating an arrangement pattern representing an arrangement of the representative values in the pixel block and a transmitting unit transmitting the representative values and the arrangement pattern.
Methods and apparatus for operating on images are described in particular methods and apparatus for interest point detection and/or description working under different scales and with different rotations e.g. for scale-invariant and rotation-invariant interest point detection and/or description. The present invention can provide improved or alternative apparatus and methods for matching interest points either in the same image or in a different image. The present invention can provide alternative or improved software for implementing any of the methods of the invention. The present invention can provide alternative or improved data structures created by multiple filtering operations to generate a plurality of filtered images as well as data structures for storing the filtered images themselves e.g. as stored in memory or transmitted through a network. The present invention can provide alternative or improved data structures including descriptors of interest points in images e.g. as stored in memory or transmitted through a network as well as data structures associating such descriptors with an original copy of the image or an image derived therefrom e.g. a thumbnail image.
An image processing apparatus is configured to precisely perform positioning of a plurality of document images containing a common part and to precisely extract an image of the common part from the plurality of document images.
A pose of an object is determine by acquiring sets of images of the object by a camera wherein the object has a thread arranged on a surface such that a local region of the object appears substantially spherical wherein the camera is at a different point of view for each set and wherein each image in each set is acquired while the scene is illuminated from a different direction. A set of features is extracted from each image wherein the features correspond to points on the surface having normals towards the camera. A parametric line is fitted to the points for each image wherein the line lies on a plane joining a center of the camera and an axis of the object. Then geometric constraints are applied to lines to determine the pose of the object.
In an apparatus for creating document data an acquiring unit acquires a handwritten figure; and a recognizing unit converts the handwritten figure acquired by the acquiring unit into a specific figure and recognizes a layout including the specific figure as a component as a user-specified layout. A storage unit stores therein data to be inserted into a desired one of a plurality of layout models. A selecting unit selects a layout model similar to the user-specified layout model from among the layout models as a similar layout model; and an inserting unit inserts the data stored in the storage unit into the similar layout model selected by the selecting unit.
A system and a method are disclosed for recognizing and representing activities in a video sequence. The system includes an activity dynamic Bayesian network ADBN an object/action dictionary an activity inference engine and a state output unit. The activity dynamic Bayesian network encodes the prior information of a selected activity domain. The prior information of the selected activity domain describes the ordering temporal constraints and contextual cues among the expected actions. The object/action dictionary detects activities in each frame of the input video stream represents the activities hierarchically and generates an estimated observation probability for each detected action. The activity inference engine estimates a likely activity state for each frame based on the evidence provided by the object/action dictionary and the ADBN. The state output unit outputs the likely activity state generated by the activity inference engine.
An interactive concept learning image search technique that allows end-users to quickly create their own rules for re-ranking images based on the image characteristics of the images. The image characteristics can include visual characteristics as well as semantic features or characteristics or may include a combination of both. End-users can then rank or re-rank any current or future image search results according to their rule or rules. End-users provide examples of images each rule should match and examples of images the rule should reject. The technique learns the common image characteristics of the examples and any current or future image search results can then be ranked or re-ranked according to the learned rules.
Described is a bio-inspired vision system for object recognition. The system comprises an attention module an object recognition module and an online labeling module. The attention module is configured to receive an image representing a scene and find and extract an object from the image. The attention module is also configured to generate feature vectors corresponding to color intensity and orientation information within the extracted object. The object recognition module is configured to receive the extracted object and the feature vectors and associate a label with the extracted object. Finally the online labeling module is configured to alert a user if the extracted object is an unknown object so that it can be labeled.
The position of a face image within an input image is detected based on results from applying a plurality of weak classifiers in sequence to each of sub-images extracted from the input image. A decision whether to interrupt the sequence and reject a currently extracted sub-image is made based on the sum of a total of weighted decision values obtained up to the current point in the sequence and a total of potential weighted decision values obtainable from the remaining weak classifiers if the extracted sub-image were a face image.
A method obtains media on a device provides identification of an object in the media via image/video recognition and audio recognition and displays on the device identification information based on the identified media object.
Category context models 64 and a universal context model 62 are generated including sums of soft co-occurrences of pairs of visual words in geometric proximity to each other in training images 50 assigned to each category and assigned to all categories respectively. Context information 76 about an image to be classified 70 are generated including sums of soft co-occurrences of pairs of visual words in geometric proximity to each other in the image to be classified. For each category 82 a comparison is made of i closeness of the context information about the image to be classified with the corresponding category context model and ii closeness of the context information about the image to be classified with the universal context model. An image category 92 is assigned to the image to be classified being based on the comparisons.
For each image sensing device an index in a sensed image is recognized and layout information of the recognized index in a coordinate system based on an image sensing device that has acquired the sensed image is calculated. Index information including identification information unique to the index and the layout information of the index is managed. If recognition of a first index in a first sensed image acquired by a first image sensing device has failed or the first index has erroneously been recognized the index information of the first index is varied on the basis of the layout information of the first index calculated by the above process for a second sensed image acquired by a second image sensing device other than the first image sensing device.
A device for identifying a traffic sign in an image includes a Hough transformer implemented to identify a plurality of line sections running in different directions through the image in the image or in an edge image derived from same. The device further includes a shape detector implemented to detect a predefined shape in the image or in the edge image derived from same based on the identified line sections. The device apart from that includes a pattern identifier implemented to select an image section corresponding to the detected predefined shape based on the detected predefined shape and to identify a traffic sign based on the selected image section.
The image signature extraction device includes a first feature extraction means for extracting from an image first features corresponding to the respective dimensions of a feature vector; a second feature extraction means for extracting from the image second features which are different from the first features corresponding to the respective dimensions of a feature vector; a feature type determination means for analyzing at least one of the image and the extracted first features as a subject for analysis to determine whether or not the feature vector constituted of the extracted first features has effectiveness in discriminating an image and if the feature vector has the effectiveness determining the first features to be the type of the features used for the respective dimensions while if the feature vector does not have the effectiveness determining the second feature to be the type of the features used for at least part of the dimensions and determining the first features to be the type of the features used for the remaining dimensions; and a feature vector generation means for generating a feature vector of the image from the extracted first features and the extracted second features according to the determined type of the features used for the respective dimensions.
Techniques are described to employ image recognition techniques to content. In an implementation one or more images are identified in content using a signature derived from the one or more images. Metadata associated with the content is then supplemented based on the identified one or more images.
A method and a system for searching images with figures and a recording medium storing metadata of image are provided. The searching method is divided into an image analysis stage and an image search stage. In the image analysis stage figures between images are compared with each other and assigned with an identity respectively. A representative image of each identity is then evaluated from the image collection. In the image search stage the representative images are displayed for user to select some of them as a searching criterion so as to search and display the images matching the searching criterion in the image collection. Accordingly the images required by user can be found through intelligent analysis of figures intuitive definition of searching criterion and simple comparison of identities so that both time and effort of organization for searching images with figures can be substantially saved.
An image storage device includes a storing unit a background recognizing unit an attribute-information generating unit and an image-data processing unit. The storing unit stores therein image data and first attribute information for each pixel. The background recognizing unit recognizes a background of the image. The attribute-information generating unit generates second attribute information for each pixel based on the background of the image recognized by the background recognizing unit. The image-data processing unit processes the image data based on the second attribute information generated by the attribute-information generating unit.
A favorable noise reduction process that is optimized for capturing conditions and that prevents the occurrence of residual image components is enabled. Provided is an imaging system including: a first extraction section that extracts a local region that includes a pixel of interest from an image signal; a second extraction section that extracts from another image signal captured at a different time a local region located at almost the same position as said local region; a first noise reduction section that performs a noise reduction process by using the local regions; a noise estimation section that estimates an amount of noise included in the pixel of interest; a residual image detection section that detects a residual image component included in the local region based on the estimated amount of noise; and a second noise reduction section that performs a noise reduction process based on the detected residual image component.
A method for performing a high-performance closed-form single-scan calculation of oblong-shape rotation angles from binary images of arbitrary size on a processor using running sums is disclosed. Running sums are calculated and stored throughout each scan and the results are obtained in closed form by simple post-scan computation. An algorithmic embodiment may execute on one or more hardware processors with limited or constrained computation power available instruction cycles available memory etc. Exemplary hardware processors are found in one or more CPUs of a desktop laptop tablet or handheld computing device and may be an embedded processor or a signal processor chip. The resulting method may be used for touch or optical user interfaces real-time image recognition real-time machine vision and other purposes.
A method and apparatus of comparing the results of medical imaging by for example PET scanning dispenses with the need for intensity normalization. The relationships between features extracted from relevant regions of interest in the image are studied. In one example mean intensities in the principle brain lobes are compared to each other and a short image ID is constructed and used to derive population statistics and diagnosis. The population statistics are compared with &#x2018;reference&#x2019; statistics in order to assess abnormality. Comparison by a number of methods is possible and the invention further provides concerns a novel voting mechanism which derives abnormality scores for each region.
An image processing apparatus determines whether a reference image and an image of interest are different or the same. A determination unit determines whether a comparative image formed by a part or entirety of the image of interest and an image corresponding to the comparative image in the reference image are different or the same. A decision unit decides whether a next comparative image should be a part or entirety of the image of interest in accordance with the result of the determination. An acquisition unit acquires the comparative image from the image of interest in accordance with result of the decision.
The subject matter disclosed herein relates to the processing of graphical rating images.
An analysis and classification tool compares at least a portion of a captured image and a reference image of nominally the same scene. One of the captured and reference images is taken with flash and the other is taken without flash. The tool provides a measure of the difference in illumination between the captured image and the reference image. The tool compares the measure with a threshold and segments a foreground region from a background region based on the measure.
Systems methods and computer program products on storage devices for shape clustering and applications in processing various documents including an output of an optical character recognition OCR process. The output of an OCR process is classified into a plurality of clusters of clip images and a representative image for each cluster is generated to identify clusters whose clip images were incorrectly assigned character codes by the OCR process.
In embodiments of the present invention improved capabilities are described for scanning a data set for the presence of a target string. The data set may be received at a computing facility and cause a scanning program to execute. A first character pair in the data set may be identified where each character making up the first character pair is identified in a vector map. It may then be confirmed that the first character pair matches a positive indicated bitmask in a bitmap matrix and verify that the position of the first character pair matches a position of a matching character pair in the target string. An action may be caused to be taken as a result of the verification.
Two images are compared to determine how similar they are. First a process normalizes each image then horizontal and vertical byte sequences are derived from each image. A similarity formula is used to obtain a similarity value that represents the similarity between the two images. An approximate pattern matching algorithm is used to determine the error distance between the horizontal byte sequences for the images and to determine the error distance between the vertical byte sequences for the images. The error distances and the length of the byte sequences are used to determine the similarity value. Padding is used to make the aspect ratios the same.
Systems methods and apparatus including software tangibly stored on a computer readable medium involve identifying text in an electronic document. An electronic document that includes an image object is received. In a first region of the image object a first set of text characters having a first orientation in the image object are recognized. In a second region of the image object a second set of text characters having a second orientation in the image object are recognized. The electronic document is modified to include a first text object containing an identification of the first set of text characters and a second text object containing an identification of the second set of text characters. The identification of the first set of text characters includes a first set of values. Each value in the first set of values represent an individual text character recognized in the first region. The identification of the second set of text characters includes a second set of values. Each value in the second set of values represent an individual text character recognized in the second region.
Recognizing handwritten words at an electronic device. A plurality of strokes is received at a common input region of an electronic device. The plurality of strokes in combination defines a word comprising a plurality of symbols a relative geometry of a first subset of the plurality of strokes defines a first symbol and a relative geometry of a second subset of the plurality of strokes defines a second symbol such that the relative geometry of the first subset of the plurality of strokes is not related to the relative geometry of the second subset of the plurality of strokes and at least one stroke of the first subset of the plurality of strokes is spatially superimposed over at least one stroke of the second subset of the plurality of strokes. The word is determined using a processor of the electronic device based on the plurality of strokes without requiring recognition of the plurality of symbols wherein a word is determined based at least in part on an entry sequence of subsets of the plurality of strokes.
In a first exemplary embodiment of the present invention an automated computerized method is provided for processing an image. According to a feature of the present invention the method comprises the steps of providing an image file identifying a boundary in the image calculating a representation of the boundary extending to segments of the image at either side of the boundary performing feature calculations on the representation and classifying the boundary as caused by a material change as a function of the feature calculations.
The time segment representative feature vector generation device includes an intra-time segment feature vector group selection means for selecting for each time segment and from a feature vector series for respective frames feature vectors of a plurality of frames included in a time segment; and a dimension selection means for selecting for each time segment and from the selected feature vectors of different frames in the time segment features of different dimensions of the feature vectors and generating a time segment representative feature vector which is a feature vector representing the time segment.
Method and system for utilizing multiple phenomenological techniques to resolve closely spaced objects during imaging includes detecting a plurality of closely spaced objects through the imaging of a target area by an array and spreading electromagnetic radiation received from the target area across several pixels. During the imaging different phenomenological techniques may be applied to capture discriminating features that may affect a centroid of the electromagnetic radiation received on the array. Comparing the locations of the centroids over multiple images may be used to resolve a number of objects imaged by the array. Examples of such phenomenological discriminating techniques may include imaging the target area in multiple polarities of light or in multiple spectral bands of light. Another embodiment includes time-lapse imaging of the target area to compare time lapse centroids for multiple movement signal characteristics over pluralities of pixels on the array.
Systems methods and computer program products on storage devices for shape clustering and applications in processing various documents including an output of an optical character recognition OCR process. The output of an OCR process is classified into a plurality of clusters of clip images and a representative image for each cluster is generated to identify clusters whose clip images were incorrectly assigned character codes by the OCR process.
A decoding method for a two dimensional dot code includes the steps of defining coordinates of boundary dots in the two dimensional dot code performing extrapolation and interpolation according to the coordinates of the boundary dots to create coordinates of a plurality of virtual code dots and comparing a code dot in the two dimensional dot code with the virtual code dots to extract information intended to be reproduced from the two dimensional dot code.
In a known method for machine-cutting a plate-shaped workpiece position and/or geometry and/or dimensions of the workpiece are detected without contact by means of a camera and the corresponding data are subjected to an evaluation by means of image processing. Starting from this to permit a precise and reproducible detection of the position and/or geometry and/or dimensions of the workpiece to be treated without spending a lot of time it is suggested according to the invention that the recording of the data should comprise a method step for the coarse localization of a workpiece edge in which the camera is operated in a first operative mode with lower optical resolution and a second method step for determining the exact positional data of the found workpiece edge in which the camera is operated in a second operative mode with higher optical resolution.
Provided is an image processing method for cropping at least first and second images for presentation in a template the first image having a first feature and the second image having a second feature the template comprising a first image boundary shape and a second image boundary shape the method comprising: determining the location of the first feature in the first image and the second feature in the second image; calculating a constraint on the locations of the first image boundary shape on the first image and the second image boundary shape on the second image the constraint based on an alignment criterion specifying the alignment of the first feature in the first image and the second feature in the second image when the first and second images are presented in the template;
An image processing device capable of high-speed detection of a specific shape in an image. In the image processing device a candidate position calculation section 106 obtains a first candidate position of the center point of a first circle in contact at three points with three sides contained in the shape of an object to be detected. An angle calculation section 106 obtains an angle formed by a normal line drawn from each of the three sides to the first candidate position and a standard line oriented in a specific direction and passing a point at which the normal line and each of the three sides cross. A relative relationship calculation section 106 obtains a relationship of the angle relative to the first candidate position. A recognition section 108 recognizes the shape contained in the given image based on the relative relationship of the angle and a relative relationship of a shape stored in advance.
There are provided: a pattern detection process section for extracting a partial image made of pixels including a target pixel from input image data; a displaced image generation section for generating a self-displaced image by displacing at least a part of the partial image through a predetermined method; and a matching test determination section for determining whether an image pattern included in the partial image matches an image pattern included in the self-displaced image or not. When the matching test determination section determines that the matching exists a target pixel in the partial image or a block made of pixels including the target pixel is regarded as a feature point. Consequently even when image data is subjected to a process such as enlarging and reducing it is possible to extract a feature point that properly specifies the image data regardless of the enlarging/reducing process.
The present invention generally describes a method for classifying a line segment of a handwritten line into a reference feature set wherein said handwritten line comprises one or several curves representing a plurality of symbols. First sample data representing said handwritten line is received. Next a sample line segment in said received sample data is identified by detecting a sample line segment start point SLSSP and a sample line segment end point SLSEP . Then a sample feature set of said identified sample line segment is determined. Finally the determined sample feature set is matched to a reference feature set among a plurality of reference feature sets.
An image classification device includes a characteristic value set calculation unit 11 that calculates a characteristic value set of the whole image for each of multiple sets of image data in an image database 51 detects an edge of the set of the image data and calculates a characteristic value set of the detected edge portions; a first clustering unit 12 that classifies the multiple sets of image data into multiple clusters on the basis of the characteristic value sets of the whole images; a second clustering unit 13 that further classifies the multiple clusters classified by the first clustering unit 12 into multiple clusters on the basis of the characteristic value sets of the edge portions; and a cluster integration unit 14 that determines which pixels constitutes a subject in each of the multiple sets of image data based on the composition of the image and integrates some of the multiple clusters classified by the second clustering unit 13 together based on the pixels constituting the subject.
A similar image retrieving device 1 comprises: an image database 21 for storage of sets of image data and sets of keywords each associated with a corresponding image data; a cluster classification section 11 to read the sets of image data provide a respective one of the sets of image data with a compatibility value as an index representative of a set of compatibilities of a corresponding one of the sets of keywords and classify the sets of image data into clusters thereof in accordance with the compatibility value; an optimum cluster extracting section 12 to provide the set of query image data with a compatibility value and select one of clusters to which the query image data is to belong to minimize an error caused in a Projection onto Convex Sets using the clusters; and a similar image extracting section 13 to output as a similar image a set of image data provided a close compatibility value among the sets of image data belonging to the cluster selected by the optimum cluster extractor.
An image processing system includes a computer and an image processing apparatus. A control portion of the apparatus controls so that a whole of one side and the other side of a transparent sheet are optically read and the obtained image data of the front and rear sides is transmitted to the computer. A control portion of the computer controls so that character information for each of data area corresponding to containing ranges of the respective document on the transparent sheet is obtained by a character recognition with respect to each front and rear side image data received and the recognized character information of the both sides is related each other for each of the data area based on previously associated front and rear information showing a front-and-rear position relation between one side and the other side of the document and stored in a data storing portion.
A method for comparing a plurality of geometrical data representations each representing a spatial boundary surface of a corresponding geometrical object which surface changes over a selected extent of the object bounded thereby through providing the plurality of geometrical data representations on a common format basis including scaling so as to each to have a common selected extent to thereby result in a plurality of standardized spatial boundary surface geometrical data representations and comparing them at a plurality of matching section locations along each of the common extents at each of which there is a section outline curve representations. Comparing selected features of the commonly scaled section outline curve representations for such representations at corresponding ones of the selected matched section locations provides a basis for determining similarity therebetween.
An image recognition device has a first resolution converter 202 that lowers resolution of an input image an area reader 203 that reads out a processing area from an output of the first resolution converter 202 a second resolution converter 204 that lowers the resolution of the processing area sliced out by the area reader to be lower than in the first resolution converter 202 and a pattern comparator 205.
Computer-readable media systems and methods for flexible matching with combinational similarity are described. In embodiments an object image is received a query image is received and the query image is compared with the object image. In various embodiments matching information is determined based upon combinational similarity and the matching information is presented to a user. In various embodiments comparing the query image with the object image includes dividing the object image into agents creating a gradient histogram for the agents determining map areas for the query image creating a gradient histogram for the map areas and creating a similarity array for each of the agents. Further in various embodiments determining matching information includes creating a combinational array by combining the similarity arrays for each agent and determining whether the combinational array includes a peak value.
There are provided: a pattern detection process section for extracting a partial image made of pixels including a target pixel from input image data; a rotated image generating section for generating a self-rotated image by rotating the partial image; and a matching test determination section for determining whether an image pattern included in the partial image matches an image pattern included in the self-rotated image. When it is determined that matching exists a target pixel in the partial image or a block made of pixels including the target pixel is regarded as a feature point. Consequently even when image data has been read while skewed with respect to a predetermined positioning angle of a reading position of an image reading apparatus or image data has been subjected to enlarging reducing etc. a feature point properly specifying the image data can be extracted regardless of skew enlarging reducing etc.
Described is a technology in which video shots are clustered based upon the location at which the shots were captured. A global energy function is optimized including a first term that computes clusters so as to be reasonably dense and well connected to match the possible shots that are captured at a location e.g. based on similarity scores between pairs of shots. A second term is a temporal prior that encourages subsequent shots to be placed in the same cluster. The shots may be represented as nodes of a minimum spanning tree having edges with weights that are based on the similarity score between the shots represented by their respective nodes. Agglomerative clustering is performed by selecting pairs of available clusters merging the pairs and keeping the pair with the lowest cost. Clusters are iteratively merged until a stopping criterion or criteria is met e.g. only a single cluster remains .
A method to recognize a facial image is described. An input facial image is normalized by scaling and rotation angle using methods of eye pupil centers detection. The input facial image is further normalized by lighting intensity. Template images are obtained either by the processing of certain images taken from different face positions or by a preliminary reconstruction of a 3D face model based on stereo-pair images. Using the 3D model template facial images are generated at different rotation angles. Distances between the input facial image and the template image are calculated from the Discrete Cosine Transformation DCT features defined by overlapped blocks of these images. The facial image is recognized based on these distances.
A device and method for efficient computation of statistical information such as a mean co-variance or histogram of the image pixels over discrete image regions. The computation employs integral computations to determine the statistical information over image regions of arbitrary shape including irregular polygonal shaped regions. The integral computations are simplified by categorizing corner points of boundaries of image regions. The computation can be applied to calculate descriptors or signatures of persons or objects within an image. The computation also has a low computational cost enabling fast calculation of image statistics.
An image file for storing a still digital image and metadata related to the still digital image the image file including digital image data representing the still digital image and metadata that categorizes the still digital image as an important digital image wherein the categorization uses a range of levels and the range of levels includes at least three different integer values.
A method and system for container identification are disclosed. The method comprises obtaining a plurality of digital images of a character sequence on the container extracting the character sequences from the images combining the character sequences into at least one identification code candidate and selecting one of the candidates as the identification code. The system comprises at least one camera and a computer system that is electrically coupled to the camera whereby when the computer system receives a trigger signal said computer system takes a plurality of digital images from the camera produces character sequences as partial recognition results for the plurality of digital images and combines the partial recognition results together to produce the identification code.
A technique that can contribute to a reduction in an operation burden in managing a processing result of semantic determination processing applied to objects included in an image is provided. An object included in an image of image data is extracted. A semantic of the object in a layout of the image data is determined. When it is determined that plural objects have an identical semantic a display unit is caused to notify information concerning the plural objects which are determined as having the semantic in association with information concerning the semantic.
The present invention firstly roughly classifies an analysis range specified by the operator in the color image data of a form into background a character frame and a character precisely specifies a character frame on the basis of the classification result eliminates the character from the color image data from which the background is eliminated and recognizes the remaining character.
A technique that facilitates modifying e.g. erasing or smudging digital ink includes selecting a digital ink drying time based on a selected digital ink type. An ink stroke associated with the selected digital ink type is then tracked. The ink stroke may then be modified prior to an end of the digital ink drying time without using a dedicated tool.
A quadrangular or rectangular area on a medium surface of a printed material is defined as a block. A straight line in a vertical direction and a horizontal direction along an edge of the block is defined as a reference lattice line. A virtual lattice point is disposed at a predetermined interval on the reference lattice line. A reference lattice point dot is disposed on a virtual lattice point on a horizontal reference lattice line. A straight line connecting the reference grid point dots and virtual lattice points on a vertical line is defined as a lattice line. A point of intersection between lattice lines is defined as a virtual lattice point. A dot pattern is generated by arranging one or more information dots having a distance and a direction on the basis of the virtual lattice point. Such a dot pattern is scanned as image information by an optical reading means. Then the dot pattern is converted into a numerical value and the information corresponding to the numerical information is read from a storage means. Then the information is outputted.
A method of identifying potential phishing abuse images includes: producing a first color map that represents a subset of color values and pixel locations within a base image; producing a second color map that represents color values and pixel locations within a target image; selecting an alignment the first color map with the second color map such that at least some pixel locations of the first color map align with at least some pixel locations of the second color map; determining a measure of color value matching of aligned pixel locations for the selected alignment; and repeating the acts of selecting and determining until a prescribed threshold measure of color value matching is determined for at least one of the selected alignments or until an evaluation limit is reached.
Embodiments of the present invention relate to systems methods and computer storage media for associating a known geographic location with a known identity. Feature matching of at least two images is performed in at least two iterations. The iterations are based on an orientation of feature vectors associated with points of interest in each image. A geometric model is applied to the matched points of interest to improve the matched pairs. Two images are identified as being related. As a result the known geographic location is associated with the known identity. Additional embodiments include augmenting feature vectors with a coordinate location of a related point of interest based on a geometric model. Further an exemplary embodiment includes an additional matching iteration based on the augmented feature vectors. In an exemplary embodiment the feature matching utilizes a Scale-Invariant Feature Transform SIFT .
The present invention is a method and system for automatically analyzing a category in a plurality of the categories in a physical space based on the visual characterization such as behavior analysis or segmentation of the persons with regard to the category. The present invention captures a plurality of input images of the persons in the category by a plurality of means for capturing images. The present invention processes the plurality of input images in order to understand the shopping behavior of the persons with the sub-categories of the category and analyzes the level of engagement and decision process at the sub-category level. The processes are based on a novel usage of a plurality of computer vision technologies to analyze the visual characterization of the persons from the plurality of input images. The physical space may be a retail space and the persons may be customers in the retail space.
A method of face categorization and annotation of a face image library includes automatically cropping a face within an acquired digital image or removing one or more non-facial items from the digital image or both and thereby generating a full-size face image. The full-size face image is stored with other indicia identifying a person corresponding to the face in a face image library of an embedded device such as a mobile camera phone or other handheld camera device.
Disclosed herein is a content management apparatus including: content inputting means for inputting a content with which position information is associated; position information acquisition means for acquiring the position information associated with the content inputted by the content inputting means; tree production means for producing binary tree structure data corresponding to a binary tree having leaves to which contents inputted by the content inputting means correspond based on the position information of the contents acquired by the position information acquisition means; and determination means for extracting a node which satisfies a predetermined condition from among nodes of the binary tree structure data produced by the tree production means and determining those of the contents which belong to the extracted node as one group.
This invention relates to rearranging a cluster map of voxels in an image aiming at the reduction of sub-cluster scatter. The cluster map that includes two or more cluster levels is displayed to the user along with the distribution of the voxels within each respective cluster levels. The aim is to enable the user to evaluate the quality of the cluster map and based on the evaluation to change the distribution of the voxels. Such a change in the distribution will result in an update of the cluster map.
A calibrated categorizer comprises: a multi-class categorizer configured to output class probabilities for an input object corresponding to a set of classes; a class probabilities rescaler configured to rescale class probabilities to generate rescaled class probabilities; and a resealing model learner configured to learn calibration parameters for the class probabilities rescaler based on i class probabilities output by the multi-class categorizer for a calibration set of class-labeled objects ii confidence measures output by the multi-class categorizer for the calibration set of class-labeled objects and iii class labels of the calibration set of class-labeled objects the class probabilities rescaler calibrated by the learned calibration parameters defining a calibrated class probabilities rescaler. In a method embodiment class probabilities are generated for an input object corresponding to a set of classes using a classifier trained on a first set of objects and are rescaled to form rescaled class probabilities using a resealing algorithm calibrated using a second set of objects different from the first set of objects. The method may further entail thresholding the rescaled class probabilities using thresholds calibrated using the second set of objects or a third set of objects.
A method and system are disclosed for matching input character sequences in a set of input patterns. The method comprises the steps of analyzing the set of input patterns creating a pattern cluster look-up table PCLT based on said input patterns and defining an offset value k. The PCLT is used to find for each sequence s and offset k a set of candidate patterns that can possibly match s the set of candidate patterns is searched for patterns that match s and all found matching patterns and sequences are reported.
In a document-image-data providing device a document image inputting unit is configured to input document image data. An area recognition unit is configured to recognize a text area of a document image element containing text data among document image elements constituting the document image data and another area of a document image element containing data other than the text data. A text data acquiring unit is configured to acquire text data contained in the recognized text area. A providing unit is configured to provide in response to a document image data request received from the information processing device both image data generated from the input document image data to have a resolution lower than a resolution of the input document image data and the text data acquired by the text data acquiring unit to the information processing device.
The present invention provides method and system for preprocessing an image including one or more of Arabic text and non-text items for Optical Character Recognition OCR . The method includes determining a plurality of components associated with one or more of the Arabic text and the non-text items wherein a component includes a set of connected pixels. A first set of characteristic parameters is then calculated for the plurality of components. The plurality of components are subsequently merged based on the first set of characteristic parameters to form one or more of one or more sub-words and one or more words.
An image processing system is disclosed that includes a buffer unit configured to store a predetermined pixel and peripheral pixels neighboring the predetermined pixel in image data in a first direction and a second direction perpendicular to the first direction; and a first edge-detecting circuit configured to calculate a maximum value and a minimum value of a set of pixels selected from the peripheral pixels that have the same color as the predetermined pixel to calculate a difference value between the maximum value and the minimum value.
An apparatus system and method are disclosed for product identification using image analysis and user interaction. The method may include comparing a retail product image to a plurality of candidate retail product images. In addition the method may include generating a candidate product set containing candidate retail product images satisfying image comparison criteria. The method may determine one or more product identity queries configured to solicit additional product identity information from a user. In addition the product identity queries may eliminate one or more members of the candidate product set. The method may query the user with these inquiries and determine a product match based on the user s response. Therefore a user may obtain information about a product using only a picture and a user s knowledge of the product.
Cell phones and other portable devices are equipped with a variety of technologies by which existing functionality can be improved and new functionality can be provided. Some relate to visual search capabilities and determining appropriate actions responsive to different image inputs. Others relate to processing of image data. Still others concern metadata generation processing and representation. Yet others relate to coping with fixed focus limitations of cell phone cameras e.g. in reading digital watermark data. Still others concern user interface improvements. A great number of other features and arrangements are also detailed.
Described is a technology in which face alignment data is obtained by processing an image using a component-based discriminative search algorithm. For each facial component the search is guided by an associated directional classifier that determines how to move the facial component if at all to achieve better alignment relative to its corresponding facial component in the image. Also described is training of the classifiers.
An image management apparatus may include an input image setting information acquiring unit configured to when image analysis information on an input image is set acquire setting information as input image setting information an available setting information acquiring unit configured to acquire setting information as available setting information an update necessity determining unit configured to determine whether or not an update of the image analysis information is necessary on the basis of a difference between the input image setting information and the available setting information and an image analysis information setting unit configured to when it is determined that an update of the image analysis information is necessary perform image analysis on the input image using the second image analysis processing unit so as to set new image analysis information.
A method and system for automatically extracting photography information is provided. The system for automatically extracting photography information includes an image input unit acquiring a preview image or a captured image as an input image a photography information extraction unit extracting photography information of the input image and a photography code generation unit generating a photography code indicating a user s photography pattern by using the extracted photography information.
A computing device may select a source tile from a source image. From the source tile the computing device may select a first rectangular feature and a second rectangular feature. Based on the first and second rectangular features the computing device may calculate a source feature vector. The computing device may also select a search area of a target image and a target tile within the within the search area. Based on the target tile the computing device may calculate a target feature vector. The computing device may determine that a difference between the source feature vector and the target feature vector is below an error threshold and based on this determination further determine a mapping between the source image and the target image. The computing device may then apply the mapping to the source image to produce a transformed source image.
An image signature to be used for matching is generated by the following generation method. First region features are extracted from respective sub-regions of a plurality of pairs of sub-regions in an image and for each of the pairs of sub-regions a difference value between the region features of two sub-regions forming a pair is quantized. Then a collection of elements which are quantization values calculated for the respective pairs of sub-regions is used as an image signature to be used for discriminating the image. The image signature matching device specifies from an image signature of a first image and an image signature of a second image generated by the above generating method a margin region of each of the images. The image signature matching device matches the image signature of the first image and the image signature of the second image in such a manner that a weight of an element in which at least one of two sub-regions forming a pair is included in the specified margin region is reduced.
A method executed by a computer system for detecting edges comprises receiving an image comprising a plurality of pixels determining a phase congruency value for a pixel where the phase congruency value comprises a plurality of phase congruency components and determining if the phase congruency value satisfies a phase congruency criteria. If the phase congruency value satisfies the phase congruency criteria the computer system categorizes the pixel as an edge pixel. If the phase congruency value does not satisfy the phase congruency criteria the computer system compares a first phase congruency component of the plurality of phase congruency components to a phase congruency component criteria. If the first phase congruency component satisfies the phase congruency component criteria the computer system categorizes the pixel as an edge pixel and if the first phase congruency component does not satisfy the phase congruency component criteria categorizes the pixel as a non-edge pixel.
A system and method for processing digital photo product templates to enhance a personalized photo product and to enable greater flexibility when selecting options for the photo product template. One or more photo product templates can be defined as a series of objects some of which are capable of being colorized by a user. Color sets applicable to the photo product template can be displayed based on a predefined set of colors and/or a user-defined &#x201c;seed color&#x201d;. The selected color sets can be automatically applied to the photo product template utilizing a predefined rank. The color sets can be ranked and complementary color set suggestions provided based on the evaluation of the colors in an image.
An image monitoring system including: an image data acquisition unit for taking in video signals from a camera to acquire image data; and an image recognition unit for carrying out image recognition processing using an inputted image obtained from the image data acquisition unit wherein the image recognition unit includes: a reference image registration means for registering a reference image selected from among the inputted images; a motion detection means for acquiring motion detection information from the inputted image; an image blur detection means for detecting image blur by comparison of the reference image with the inputted image for edge strength; a similarity computation means for computing a similarity between the reference image and the inputted image; and a camera anomaly detection unit for determining any anomaly in the camera from the motion detection information the image blur and the similarity wherein the comparison for edge strength and the computation for the similarity are carried out respectively for an image region excluding a region of a moving object extracted by the motion detection means.
An electronic image classification and search system and method are provided. Images are processed to determine a plurality of simple feature descriptors based upon characteristics of the image itself. The simple feature descriptors are grouped into complex features based upon the orientation of the simple feature descriptors. End-stopped complex feature descriptors and complex feature descriptors at multiple orientations are grouped into hypercomplex feature descriptors. Hypercomplex resonant feature descriptor clusters are generated by linking pairs of hypercomplex feature descriptors. Feature hierarchy classification can then be performed by adaptive resonance on feature descriptors and classifier metadata associated with the image can then be generated to facilitate indexing and searching of the image within a hierarchical image database.
Visual objects can be classified according to image type. In one embodiment the present invention includes capturing a visual object and decompressing the visual object to a colorspace representation exposing each pixel. The contribution of each pixel to a plurality of image types can then be determined. Then the contributions can be combined and the image type of the visual object can be determined based on the contributions.
An image retrieval program IRP may be used to query a collection of digital images. The IRP may include a mining module to use local and global feature descriptors to automatically rank the digital images in the collection with respect to similarity to a user-selected positive example. Each local feature descriptor may represent a portion of an image based on a division of that image into multiple portions. Each global feature descriptor may represent an image as a whole. A user interface module of the IRP may receive input that identifies an image as the positive example. The user interface module may also present images from the collection in a user interface in a ranked order with respect to similarity to the positive example based on results of the mining module. Query concepts may be saved and reused. Other embodiments are described and claimed.
A method of imaging a coding pattern disposed on a surface of a substrate. The method comprises the steps of: a positioning a nib of an optical reader on the surface and capturing an image of a portion of the coding pattern; b locating at least nine target elements in the imaged portion; c observing a perspective distortion of the target elements due to a 3D orientation of the reader relative to said surface; d calculating a 2D perspective transform using the target elements; and e determining a position of the nib on the surface using the 2D perspective transform and local tag data contained in the imaged portion. The imaged portion of the coding pattern has a diameter of at least one tag diameter and less than two tag diameters. The coding pattern is specially adapted for the method.
An image processing apparatus generates a 3-value image from a 2-value image wherein the first and second values from the 2-value image indicate foreground and background regions of an input image and the third value indicates an unknown region of predetermined width at the boundary therebetween. A ratio image is generated from the input image and the 3-value image having a fourth value indicating the ratio of the first value. The 3-value image is updated by defining a predetermined range near a pixel in the 3-value image corresponding to a pixel in the ratio image whose fourth value is greater than a minimum value and less than a maximum value and then sets all pixels within the defined range to the third value. If the updated 3-value image is determined to be identical or nearly identical to the pre-update 3-value image then the updated 3-value image is output.
After pre-printed cards are manufactured at least a corner of each card is imaged. It is then determined whether the position and orientation of markings in the image with respect to the corner are within tolerance. If not the card is rejected. If the markings are or include indicia these indicia may be identified to allow identification of the card. This allows a determination of whether the card is in an intended order or it allows selection of the batch into which the card is placed. It also means that cards in a given set of cards arranged in a first order can be randomized by first buffering cards in buffers and then outputting the cards to an output conveyor.
An exemplary method for online character recognition of East Asian characters includes acquiring time sequential online ink data for a handwritten East Asian character conditioning the ink data to produce conditioned ink data where the conditioned ink data includes information as to writing sequence of the handwritten East Asian character and extracting features from the conditioned ink data where the features include a tangent feature a curvature feature a local length feature a connection point feature and an imaginary stroke feature. Such a method may determine neighborhoods for ink data and extract features for each neighborhood. An exemplary Hidden Markov Model based character recognition system may use various exemplary methods for training and character recognition.
A gesture spotting detection method and apparatus employ a shoulder-line algorithm. The shoulder-line detecting method recognizes a GSD calling gesture that occurs in a shoulder-line head or higher part in a remote distance or a short distance although a user does not have a fixed posture. In the method an image of people is received and skin information of a person in the image is detected to detect a face area. Then the cloth color information of the person is modeled from the inputted image to detect a cloth area. An external space is defined from the image based on the body space area and an edge is extracted from the image based on the body space and the external space. Then shoulder-line information is acquired based on an energy function obtained based on the body space the external space and the edge.
Apparatus and method for extracting from a moving image a scene in which an intended person appears by simple operations are provided. A moving image editing apparatus identifies a person as an extraction target based on an instruction of a user tracks a face of the extraction target to thereby select a scene in which the extraction target appears in a moving image and extracts a partial moving image containing the selected scene from the moving image.
A high-density distance-measuring laser system and an associated computer that processes the data collected by the laser system. The computer determines a data partition structure and stores that structure as a header file for the scan before data is collected. As the scan progresses the computer collects data points until a predetermined threshold is met at which point a block of data consisting of the data points up to the threshold is written to disk. The computer indexes each data block using all three coordinates of its constituent data points using preferably a flexible index such as an R-tree. When a data block is completely filled it is written to disk preferably with its index and as a result each data block is ready for access and manipulation virtually immediately after having been collected. Also each data block can be independently manipulated and read from disk.
A method and system for generating a spatial signature for a frame of a video object. The method includes obtaining a frame associated with a video object and dividing the frame into a plurality of blocks. The plurality of blocks corresponds to a plurality of locations respectively each of the plurality of blocks includes a plurality of pixels and the plurality of pixels corresponds to a plurality of pixel values respectively. Additionally the method includes determining a plurality of average pixel values for the plurality of blocks respectively. Each of the plurality of blocks corresponds to one of the plurality of average pixel values. Moreover the method includes processing information associated with the plurality of average pixel values and determining a plurality of comparison values for the plurality of blocks respectively based on at least information associated with the plurality of average pixel values.
This invention relates to supervised or unsupervised classification of biological datasets. Specifically the invention relates to the use of Graph Embedding as a method of reducing dimensionality thereby improving supervised classification of classes both conventional and new ones.
The present invention relates to an apparatus and a method for classifying pixels in each frame of a motion picture as foreground or background. According to the invention the apparatus has a decision unit and adjustment unit. The decision unit classifies a pixel as a foreground pixel a background pixel or an undefined pixel based on a first threshold a second threshold and a distribution value of the pixel representing an occurrence probability of a pixel value of the pixel. The decision unit sorts each pixel into a foreground pixel or a background pixel based on the classification result of the decision unit.
Method and device for providing a summary of a plurality of images e.g. a video sequence. The method includes dividing the video sequence into a plurality of segments. The segments are analyzed with respect to content and a set of content descriptors are associated to the segments. Preferably additional textual information about the segments screenplay etc. is used to determine the content descriptors. A graph representing relations between the segments is constructed indicating relations between segments. Weights are associated to the relations so as to represent a measure of relation e.g. a logical correlation between segments. The weights are based on the calculated content descriptors. A relevance measure for a segment is determined based on all weights associated with relations to said segment. Finally a summary is generated by selecting the most relevant segments. The method can create an automatic summary of a film that preserves all the logical plot of the original but is shorter in duration e.g. 70% of the original film while the original playback rate is preserved.
An apparatus for capturing text found on an object. The apparatus comprises an image capture subsystem which includes a video camera configured to capture a plurality of images to form a video stream. The image capture subsystem is configured to generate a master image from the video stream. The apparatus additionally comprises an Optical Character Recognition &#x201c;OCR&#x201d; subsystem configured to process the master image to form a digital text that corresponds to at least some of the text on the object.
There are provided a word search apparatus a word search method and a computer program product. A words dictionary and a character recognition dictionary for storing coordinate data of a standard character pattern of a handwritten character and a character are used to thereby search for from the words dictionary a word including a character corresponding to one or a plurality of character patterns extracted by performing a pattern matching. Only a character string corresponding to one or a plurality of character patterns is extracted from a search result of the words dictionary to generate a part of character string. A selection of one part of character string among the generated parts of character strings is received and only a word including the selected part of character string is extracted from the search result based on the words dictionary so that the extracted word is displayed.
Image descriptor quantization technique embodiments are presented which quantize an image descriptor defined by a vector of number elements. This is generally accomplished by lowering the number of bits per number element to a prescribed degree. The resulting quantized image descriptor exhibits minimal loss of matching reliability while at the same time reducing the amount of storage space needed to store the descriptor in a database. Lowering the number of bits per number element also allows for increased matching speed.
Frame images captured in a continuous manner are acquired and temporarily stored. Characteristic points of faces in the acquired frame images are extracted. A sum expression change amount of distances between characteristic points of the face face parts in a current frame and the characteristic points of a preceding frame is calculated. The target frame image in which the expression change amount is largest and m frame images preceding and following the target frame image in which the expression change amount is largest are extracted as best image candidates. A best shot image is extracted from the best image candidates and stored in a storage medium. Thus only an image best shot image which contains a face which a user wishes to record can be efficiently extracted from among images captured in a continuous manner and stored.
A method medium and apparatus with estimation of background changes. The method includes generating an edge map based on a pre-learned background image and calculating a value representing the similarity between a foreground image extracted from an input image and the generated edge map and estimating a background change in the input image based on the calculated value. Therefore the method can reduce the effect of disturbances caused by the implementation environment of an image-based intrusion detection system and uncontrollable device defects which in turn reduces false alarms.
A method is provided for acquiring a reserved block in a holographic storage system. A symmetrical reference table is defined according to the characteristics of a known reference reserved block. Then the differences between respective unit blocks and the reference reserved block are calculated according to the symmetrical reference table so as to determine total match scores for respective unit blocks. Consequently the unit block having the highest match score is deemed as the reserved block.
An image processing device to convert a first image data into a second image data having a higher image quality includes: a predicted tap extracting unit to extract multiple pixels as a predicted tap for prediction computing; a level limit class tap extracting unit to extract multiple pixels as a level limit class tap for level limit classifying processing; a waveform class tap extracting unit to extract multiple pixels as a waveform class tap; a level limit classifying unit to classify the pixel of interest based on a ratio between a level width and a dynamic range of the pixels making up the level limit class tap; a waveform pattern classifying unit to classify the pixel of interest; a prediction coefficient output unit to output a prediction coefficient corresponding to a combination of a level limit class and a waveform pattern class; and a prediction computing unit.
A method and system for recognizing text in computer images comprising distorted text provides an adaptive iterative process wherein recognition rules are adapted added or omitted based on the present state of the recognition process. When the first pass through the recognition and adaptation is completed the remaining unrecognized words 15 are passed through the recognition system 1 using the modified set of recognition rules stored in 18 and the process is repeated. In most cases the recognition system 1 will identify further reliable recognized words which iteratively can be used to improve the recognition rules until the true text comprised in image 10 is recognized throughout the whole text. The steps of the method according to the present invention are thus repeated until convergence.
The present invention relates to systems and methods for identifying captions associated with images in media material. A captioner includes a selector module and a caption identifier module. The selector module identifies text-blocks potentially associated with images in the media material. The caption identifier module identifies which text-blocks are captions associated with images in the media material based on the textual and proximity features of the text-block and the images. The captioner may also include a caption feedback module to modify the determining of the caption identifier module.
A natural input system is described for creating and editing complex structures in a typeset application. The natural input system receives a typeset representation of an object and converts the typeset format to generate a standard digital ink representation. The natural input system provides the generated ink representation to a natural input application where can be manipulated by the user with a rich set of correction and editing features provided by the natural input application. Once the end user is satisfied with the recognition result in the natural input application the natural input system receives the recognition result based on the modified digital ink representation. The natural input system may convert the received recognition result to the typeset application format and provides the modified typeset representation to the typeset application for merging into the document the user is editing.
Automatic detection of chin positions is enabled from within digital images regardless of the facing directions of the faces. Faces having skin color are detected from input color images. Reference lines from center positions between eyes and center positions of mouths which are included in faces are calculated based on the faces detected by the face detecting section. Data that indicates statistical positional relationships among center positions between eyes center positions of mouths and chins therein are obtained. Probabilities that the reference lines calculated by the reference line calculating section include the positions of chins based on the data that indicates the statistical positional relationships and the reference lines are calculated. Probabilities of skin colored pixels being present on the reference line are calculated. Rates of brightness variations along the reference line are calculated. Positions of chins are calculated based on combinations of the above the results of calculation.
A product identification apparatus for determining whether an inspection target product to be identified is the same as a predetermined verification product includes: an extraction unit configured to extract an input pattern formed of asperities on the surface of a predetermined part of the inspection target product from a captured image obtained by capturing the image of the predetermined part of the inspection target product; and a comparison unit configured to compare the input pattern with an identification pattern extracted from a captured image obtained by capturing in advance the image of a part of the verification product so as to determine whether the input pattern is the same as the identification pattern or the input pattern includes the identification pattern.
A method for inspecting a uniformity of CD CD of a photo mask pattern increases a production yield. The method obtains a CD by precisely measuring a photo mask by using an electron microscope. Then a measurement image having a plurality of patterns formed in the photo mask is obtained by photographing the photo mask at a high speed through an optical microscope. A gray level based on the CD is calculated by capturing just a pattern area in the measurement image and an estimated value and a correlation coefficient is obtained when an open density of the measurement image is relatively low. Accordingly a uniformity of CD can be confirmed more clearly in a measurement of high speed for a measurement image having a relatively low open density.
The present invention provides a method and system for determining near-duplicate images. The method and system includes performing a Fourier-Mellin transform on each of a plurality of images. For each image of the plurality of images the method and system includes generating a signature based on the Fourier-Mellin transform. The method and system includes comparing the signature of at least one of the images to at least one of the signatures of the other plurality of images and determining any near duplicate images based on the comparing of the signatures.
An apparatus and method for labeling a video an apparatus and method for modifying a video a video searching method and an advertising method. The method for labeling a video includes labeling at least one object with its properties. The method for modifying a video includes replacing at least one object labeled as &#x201c;can be replaced&#x201d; with another object and modifying at least one object if the object has been labeled as &#x201c;can be modified.&#x201d; The video searching method includes labeling at least one object in at least one video with its properties and searching the video for an object of interest using the properties labeled on at least one object. The advertising method includes creating a video having an object labeled by an author s name modifying the video by replacing the labeled object with an advertising object or modifying the labeled object as an advertising object by the advertiser and distributing the video so that end user can watch the modified video.
A method for facilitating semantic event classification of a group of image records related to an event. The method using an event detector system for providing: extracting a plurality of visual features from each of the image records; wherein the visual features include segmenting an image record into a number of regions in which the visual features are extracted; generating a plurality of concept scores for each of the image records using the visual features wherein each concept score corresponds to a visual concept and each concept score is indicative of a probability that the image record includes the visual concept; generating a feature vector corresponding to the event based on the concept scores of the image records; and supplying the feature vector to an event classifier that identifies at least one semantic event classifier that corresponds to the event.
Multi-scale processing may be used to reduce the memory and computational requirements of optimization algorithms for image labeling for example for object segmentation 3D reconstruction stereo correspondence optical flow and other applications. For example in order to label a large image or 3D volume a multi-scale process first solves the problem at a low resolution obtaining a coarse labeling of an original high resolution problem. This labeling is refined by solving another optimization on a subset of the image elements. In examples an energy function for a coarse level version of an input image is formed directly from an energy function of the input image. In examples the subset of image elements may be selected using a measure of confidence in the labeling.
A computer implemented method apparatus and computer usable program code for detecting behavioral deviations in members of a cohort group. In one embodiment a member of a cohort group is identified. Each member of the cohort group shares a common characteristic. Respiratory metadata associated with the member of the cohort group is received in real-time as the respiratory metadata is generated. The respiratory metadata describes respiration associated with the member of the cohort group. Patterns of respiratory changes are identified using the respiratory metadata. The respiratory metadata is analyzed to identify the patterns of respiratory changes. In response to the patterns of respiratory changes indicating behavioral deviations in the member of the cohort group the member of the cohort group is identified as a person of interest.
An information processing system includes an image output unit an image reception unit and a determination unit. The image output unit outputs an image to a document to include first and second images. The first image includes at least one of a character and a symbol which represent at least part of a pair of an attribute name and an attribute value which are included in electronic data. The second image includes a first information image representing at least part of the attribute value or a second information image representing a storage location of the electronic data. The image reception unit receives the output image of the document and an image of a paper document. The determination unit determines as to whether or not allowing the image of the paper document to be registered.
Search terms are derived automatically from images captured by a camera equipped cell phone PDA or other image capturing device submitted to a search engine to obtain information of interest and at least a portion of the resulting information is transmitted back locally to or nearby the device that captured the image.
Search terms are derived automatically from images captured by a camera equipped cell phone PDA or other image capturing device submitted to a search engine to obtain information of interest and at least a portion of the resulting information is transmitted back locally to or nearby the device that captured the image.
A method and system for preprocessing an image for Optical Character Recognition OCR wherein the image includes a plurality of columns is disclosed. Each column includes one or more of Arabic text and non-text items. The method includes determining a plurality of components associated with one or more of the Arabic text and the non-text items wherein a component includes a set of connected pixels. On determining the plurality of components a line height and a column spacing is determined for the plurality of components. The plurality of components are then associated with a column of the plurality of columns based on the line height and the column spacing. Subsequently a set of characteristic parameters are calculated for each column and the plurality of components of each column are merged based on the set of characteristic parameters to form sub-words and words.
An information processing apparatus includes a storage unit configured to store dictionary data in which a locus and one or more pieces of content are registered in association with one another an input unit configured to input a locus in association with content a comparison unit configured to compare the locus input by the input unit and a locus registered in the dictionary data and an addition unit configured to add data to the dictionary data stored in the storage unit based on a comparison result generated by the comparison unit.
The invention relates to a method for image processing. First establish the initial image background information. And retrieve the instant image information. Then calculate the initial image background information and color intensity information of the instant image. Furthermore adjust the instant image information. Then calculate the moving-object information. Finally track the moving-object information. It can improve the accuracy rate of detection without the influence of erected height.
A new instrumental design is provided for in-gel detection and quantification of proteins. This new platform called Cumulative Time-resolved Emission 2-Dimensional Gel Electrophoresis utilizes differences in fluorescent lifetime imaging to differentiate between fluorescence from specific protein labels and non-specific background fluorescence resulting in a drastic improvement in both sensitivity and dynamic range compared to existing technology. The platform is primarily for image acquisition of two-dimensional gel electrophoresis but is also applicable to protein detection in one-dimensional gel systems as well as proteins electroblotted to e.g. PVDF membranes. Given the increase in sensitivity of detection and dynamic range of up to 5-6 orders of magnitude compared to existing approaches the described invention represents a technological leap in the detection of low abundance cellular proteins which is desperately needed in the field of biomarker discovery.
A method for removing shutter areas in an image in particular an x-ray image is provided. Edges are examined in a multi-resolution image pyramid and evaluated to determine potential shutter blade candidates defining the shutter areas. Heuristic rules and/or an automatic classifier such as a Neuronal Network are applied to distinguish true shutter blades from false positives. The rule set and the classifier are based on a set of features extracted from the potential shutter blade candidates as well as predetermined knowledge of the expected placement of the shutter human anatomy. Up to four shutter blades are expected to be detected and based on these blades the bright areas in the image that occur due to the shutters are removed.
An exemplary method for extracting discriminant feature of samples includes providing data for samples in a multidimensional space; based on the data computing local similarities for the samples; mapping the local similarities to weights; based on the mapping formulating an inter-class scatter matrix and an intra-class scatter matrix; and based on the matrices maximizing the ratio of inter-class scatter to intra-class scatter for the samples to provide discriminate features of the samples. Such a method may be used for classifying samples recognizing patterns or other tasks. Various other methods devices system etc. are also disclosed.
A clustering processing method for dividing a samples into a plurality of clusters based on a feature amount of each sample the plurality of clusters each belonging to one of a plurality of layers composed of M layers M=2 . . . K the clustering processing method comprises a sample allocating step of allocating a sample targeted for processing to a cluster belonging to a first layer based on a result of comparing the feature amount of the target sample with a representative feature amount of each of clusters belonging to the first layer; a determination step of determining whether to allocate a cluster belonging to an M&#x2212;1th layer to an Mth layer; and a cluster allocating step of allocating a cluster belonging to the M&#x2212;1th layer to the Mth layer if it is determined in the determination step to allocate a cluster belonging to the M&#x2212;1th layer to the Mth layer.
A method and system for side detection of an undetailed 3D ear impression is disclosed. In order to determine whether a received 3D undetailed ear impression is a left or right ear impression a local coordinate system of the 3D undetailed ear is defined based on side independent features of the 3D undetailed ear impression. A skeleton or center spline of the 3D undetailed ear impression is detected and it is determined whether the 3D undetailed ear impression is a left or right ear impression based on the skeleton and the local coordinate system.
A document matching process section retrieves a similar image on a basis of the result of a first comparison process for comparing features of a matching key image of first resolution that are stored in a features storage section with features of a matching reference image and the result of a second comparison process for extracting features from a matching key image of second resolution that is stored in an image data storage section and comparing the extracted features with features of the matching reference image that are stored in the features storage section. This allows accurately retrieving a matching reference image similar to the matching key image even when the matching key image is a zoomed image an N-up image or an image of low resolution.
A technique that improves image analysis efficiency by reducing the number of computations needed to detect constant regions. Constant region detection according to the present techniques includes determining whether an image analysis window at a current position contains a constant region by analyzing a new line of pixels in the image analysis window if a pixel at a predetermined location in the image analysis window in the current position has a value equal to a pixel at the predetermined location from a previous position of the image analysis window. Analyzing only the new line of pixels saves the computational time that would otherwise go into analyzing all of the pixels in the image analysis window.
A method for extracting a 3D terrain model for identifying at least buildings and terrain from LIDAR data is disclosed comprising the steps of generating a point cloud representing terrain and buildings mapped by LIDAR; classifying points in the point cloud the point cloud having ground and non-ground points the non-ground points representing buildings and clutter; segmenting the non-ground points into buildings and clutter; and calculating a fit between at least one building segment and at least one rectilinear structure wherein the fit yields the rectilinear structure with the fewest number of vertices. The step of calculating further comprises the steps of a calculating a fit of a rectilinear structure to the at least one building segment wherein each of the vertices has an angle that is a multiple of 90 degrees; b counting the number of vertices; c rotating the at least one building segment about an axis by a predetermined increment; and d repeating steps a - c until a rectilinear structure with the least number of vertices is found.
A fa&#xe7;ade rendering system is described. In various embodiments the fa&#xe7;ade rendering system identifies horizontal waveforms and vertical waveforms from an image of a structure combines the identified horizontal and vertical waveforms to generate fa&#xe7;ade waveforms that model a fa&#xe7;ade of the structure and renders the fa&#xe7;ade waveforms as a fa&#xe7;ade for the structure. The fa&#xe7;ade rendering system can include or employ information about the structure from which to create waveform information waveform information to create a fa&#xe7;ade waveform for modeling the structure and a component that renders the structure based on the waveform information.
A difference region extracting section 122 extracts differential regions based on screen data of a previous screen stored in transmission screen data storage section 124 and a current screen stored in a screen data storage section 121. A priority determining section 123 calculates change data density indicating a degree of a change of pixel values for every differential region. For example when a user operates an icon on the screen the change data density of the differential region corresponding to the icon becomes larger than the change data density of the differential region corresponding to the background portion of a video image. An encoding section 125 writes screen code data of each differential region in a transmission buffer 141 in descending order of the change data density.
Disclosed is a method for determining the absence or presence of one or more instances of a predetermined pattern in an image and for determining the location of each found instance within a multidimensional space. A model represents the pattern to be found the model including a plurality of probes. Each probe represents a relative position at which a test is performed in an image at a given pose each such test contributing evidence that the pattern exists at the pose. The method further includes a comparison of the model with a run-time image at each of a plurality of poses. A match score is computed at each pose to provide a match score surface. Then the match score is compared with an accept threshold and used to provide the location any instances of the pattern in the image.
The image processor is provided with: a detection unit that detects plural specified images each having a shape from an image read out by an image reading apparatus; a first determination unit that determines presence or absence of other specific image other than a specified image out of the plural specified images detected by the detection unit in a position determined in advance for the specified image; and a second determination unit that determines whether or not the specified image is to be subjected to a processing on the basis of a result of the determination of the presence or absence of the other specified image by the first determination unit.
Embodiments of the disclosed technology allow for the control monitoring and/or configuration of specialized hardware devices with proprietary interfaces from a central interface capable of interacting with one or a plurality of specialized hardware devices via respective proprietary interfaces. Such embodiments are especially useful in controlling medical equipment such as radiology equipment at a central and/or remote location where otherwise only a proprietary interface at a proximate location could be used to do same.
A method for handwriting input includes recognizing a first character inputted by handwriting; providing a plurality of recognition results each with a code based on the recognition of the first character; recognizing a second character inputted by handwriting; and determining the first character based on the recognition of the second character. A handwriting input system for carrying out the method is also provided.
The present invention provides a real-time motion recognition method for identifying whether an inertia-sensing device is in active state or not according to an angular velocity signal detected with respect to the device. The present invention further provides an inertia-sensing and trajectory-reconstruction device incorporated with the foregoing method for recording detected acceleration and angular velocity signals while the device is in operation so as to reconstruct a corresponding trajectory which is capable of being subsequently utilized to be a basis of writing recognition and motion analysis.
Scaleable video sequence processing with various filtering rules is applied to extract dominant features and generate unique set of signatures based on video content. Video sequence structuring and subsequent video sequence characterization is performed by tracking statistical changes in the content of a succession of video frames and selecting suitable frames for further treatment by region based intra-frame segmentation and contour tracing and description. Compact representative signatures are generated on the video sequence structural level as well as on the selected video frame level resulting in an efficient video database formation and search.
A system and method of image content analysis using a pattern generator that emits a regular and pre-calibrated pattern of non-visible electromagnetic radiation from a surface in range of a camera adapted to perceive the pattern. The camera captures images of the perceived pattern and other objects within the camera s range and outputs image data. The image data is analyzed to determine attributes of the objects and area within the camera s range. The pattern provides a known background which enables an improved and simplified image analysis.
A method is provided to predict the location of attention focus probability trajectories due to distractions in a test video. A peripheral sensitivity probability map is created base upon a nominal measurement map and an attention probability map which are both based on a test video input. A focus of attention probability map with distraction is produced based upon the peripheral sensitivity map the nominal measurement map the attention probability map and a distractibility control input.
A method which uses digital image comparison for imaging software development is described. The software under development is used to generate a set of test digital images from print data. The images are stored. The software of a reference system is used to generate a set of reference digital images based on the same print data. The test and reference images are tiled and image comparison is carried out on a tile-by-tile basis. A difference tile is generated for each test image tile and corresponding reference image tile and the tiles are stored together in an image file to be displayed to the human user. The test images and reference images are compared using an image comparison program. The result of the comparison is presented to the human software developer for further comparison and evaluation.
A method related to data capture from forms involving optical character recognition comprises detecting data fields on a scanned image; generating a flexible document description based on the detected data fields including creating a set of search elements for each data field each search element having associated search criteria; and training the flexible document description using a search algorithm to detect the data fields on additional training images based on the set of search elements.
Technologies for comparing observed intensities using a probabilistic similarity measure. In the probabilistic similarity measure example there is no attempt to estimate a true intensity. Rather the similarity of two observed intensities is defined as the likelihood that they each resulted from the same but unknown true identity while taking into account the noise characteristics of the camera observing the intensities. Since the true intensity is unknown all possible true intensities are taken into account rather than using a specific true intensity estimate. The probabilistic similarity measure indicates the degree to which two intensities correspond to the same intensity without estimating a true scene intensity value.
A method and system is provided for finding stable keypoints in a picture image using localized scale properties. An integral image of an input image is calculated. Then a scale space pyramid layer representation of the input image is constructed at mulitple scales wherein at each scale a set of specific filters are applied to the input image to produce an approximation of at least a portion of the input image. Outputs from filters are combined together to form a single function of scale and space. Stable keypoint locations are identified in each scale at pixel locations at which the single function attains a local peak value. The stable keypoint locations which have been identified are then stored in a memory storage.
A system and method for extracting feature data of dynamic objects selects sequential N frames of a video file up front where N is a positive integer and divides each of the N frames into N*N squares. The system and method further selects any n frames from the N frames selects any n rows and n columns of the n frames to obtain n*n*n squares where n is a positive integer. The system and method further extracts feature data from the video file by computing averages and differences for pixel values of the n*n*n squares.
A system and method is provided for using a first vascular image or more particularly a plurality of control points located thereon to identify a border on a second vascular image. Embodiments of the present invention operate in accordance with an intra-vascular ultrasound IVUS device and a computing device electrically connected thereto. Specifically in one embodiment of the present invention an IVUS console is electrically connected to a computing device and adapted to acquire IVUS data. The IVUS data or multiple sets thereof is then provided to or acquired by the computing device. In one embodiment of the present invention the computing device includes a plurality of applications operating thereon&#x2014;i.e. a border-detection application an extrapolation application and an active-contour application. These applications are used to i identify a border and control points on a first IVUS image i.e. any IVUS image ii extrapolate the control points to a second IVUS image i.e. another IVUS image iii identify a border on the second IVUS image and iv adjust the border on the second IVUS image in accordance with at least one factor. In one embodiment of the present invention the at least one factor is selected from a group consisting of gradient factor continuity factor and curvature factor.
A method and apparatus of processing image data comprises correlating received image data. Image statistics are computed based upon the correlated image and eccentricity is estimated based upon the computed image statistics. An entropy metric of the correlated received image data is determined. An interpretation based upon the image statistics estimated eccentricity and entropy metric is performed and a report including the content of the processed image data is generated.
An object detecting apparatus capable of suppressing an increase of processing loads with high accuracy and a learning apparatus for the same are provided. An object detecting apparatus includes an image window extracting portion 210 for extracting an image window as a partial area of an image in plural from an input image and a network identifier 590 for detecting a presence of an object from extracted image windows respectively by using a node network in which nodes each having an identifier for identifying the object stored in a storing portion 502 are connected as a network.
A method of matching a pose of a synthesized representation of a human or animal body to a captured image of that human or animal body is provided which can be used to generate a graphical model of the body when disposed on a plane such as a synthesized model of a football player on a field of play. The method includes receiving the captured image data determining from the captured image data a plurality of limb position estimates each position estimate corresponding to an amount by which limbs of the body are separated with respect to each other and deriving from the plurality of limb positions an estimated gait phase of the body. The estimated gait phase is then applied to a basis gait model in order to provide an estimated pose of the body the basis gait model comprising data which defines a displacement of the limbs or parts thereof with respect to a gait cycle period. The estimated pose is then matched to that of the synthesized representation of the body.
An image management method and system provides for storing indexing searching and/or retrieving image data. Keypoints are identified in images including keypoints in a query image of a query document and keypoints in potential target document images of a collection of potential target documents. Fingerprint information from the keypoints are generated and the fingerprint information of a query image is compared with fingerprint information of potential target document images found in the collection of potential target documents. A best match is determined between the fingerprint information of the query image and the potential target document images. At least one target document image is retrieved based on the determined best match. The retrieved at least one target image may then be displayed printed or transmitted.
In an example embodiment a method is provided for image categorization. Here images are displayed. In turn a user input that describes a characteristic shared between the images from a comparison between the images is received. The user input may then be classified into categorization data.
An automatic component teaching device which generates component teaching data accurately indicating a configuration of a component is provided regardless of size of the component. The automatic component teaching device includes a cover sheet 173 of which surface is evenly colored in blue and which is formed to be glossy a lighting fixture 171d which illuminates a peripheral area including the component with its back facing against a surface of the cover sheet 173 an image pickup device 171c which generates a colored image of the component by taking an image in color of the component illuminated by the lighting fixture 171d with one surface of the cover sheet 173 in blue as its background and in image processing unit 123 which identifies a configuration of the component and generates component teaching data from the colored image generated by the image pickup device 171c.
Properties of pixels in a digital image are sampled within different subdivisions of an editing tool impression to produce different property distributions. The different subdivisions can automatically alter their size geometry and/or location based on image content within one or more of the subdivisions in order to encompass a set of pixels having a substantially uniform distribution of a pixel property. Uniformity can be defined relative to the editing operation or context of the image. The property distributions from each region are classified to identify different edit classes within the property space which are then used to apply an edit effect to the digital image within the tool impression. The edit classes may be represented by an edit profile in two or more dimensions.
Disclosed herein is a method computer system and computer program product for identifying a writing system associated with a document image containing one or more words written in the writing system. Initially a document image fragment is identified based on the document image wherein the document image fragment contains one or more pixels from one or more of the words in the document image. A set of sequential features associated with the document image fragment is generated wherein each sequential feature describes one dimensional graphic information derived from the one or more pixels in the document image fragment. A classification score for the document image fragment is generated responsive at least in part to the set of sequential features the classification score indicating a likelihood that the document image fragment is written in the writing system. The writing system associated with the document image is identified based at least in part on the classification score for the document image fragment.
The invention relates to the devices for contactlessly measuring surface profiles and can be used for person identification in security systems. The inventive device for contactlessly controlling surface profile comprises a pulse illumination unit which is provided with a transparency and forms a transparency image on an object surface and image recording unit and a computer. Said device also comprises a control unit which is connected to the image recording unit in the form of a TV camera with field interlacing the pulse illumination unit and to the computer for synchronizing the illumination of the object surface by said pulse illumination unit with the TV camera field and for synchronizing the image processing by the computer with the TV interlacing. The transparency is embodied in the form of a line screen provided with an aperiodical different width band structure and a uniform transmission along each band thereby making it possible to identify the sequence of the line screen images on the object surface.
A method for dividing a digital image into regions comprises identifying potential region borders based on edge content in the digital image. The digital image is divided into regions based on user-selected ones of the potential region borders. A method of processing a region of a digital image comprises receiving gesture data for characterizing the region. A processing tool associated with the gesture data is automatically launched and the region is processed using the processing tool.
A similar image search apparatus includes a storage unit a search unit a text feature selection unit an image feature transformation unit and a similar image search unit. The storage unit stores images and pieces of text information associated with the respective images. The search unit retrieves candidate images. Each candidate image has a similar image feature to a image feature of a key image. The text feature selection unit select a text feature of the respective candidate images which satisfies a given selecting condition. The image feature transformation unit base on the selected text feature transforms the image features. The similar image search unit retrieves similar images from the candidate images based on the transformed image features. The image features of the similar images are similar to the image feature of the key image.
Even if an image processing apparatus which can recognize a certain character string is available on the network processing results of an OCR process are determined by character recognition ability of an image processing apparatus which has happened to perform the OCR process. Thus after an MFP performs a character recognition process based on image data contained in a character region of an image if it is determined that processing results of the character recognition process are highly likely to contain recognition errors the processing results are output to another MFP together with first information which indicates a high likelihood of the processing results containing recognition errors. Upon acquiring the processing results the other MFP with higher character recognition capabilities performs a character recognition process on the image data contained in the character region if the first information is attached.
A document processing method comprises adding document markers to predetermined locations of an electronically stored document. These are printed with the document. The document is scanned and the scanned document markers are used to process the scanned image. This processing comprises at least pixel threshold setting and determination of the locations of the scanned image which are to be processed to derive the pixels of a digital version of the document. This enables local deformations in the paper document to be corrected and enables correct thresholds for the printing and scanning operations to be applied. The electronically stored document can be processed to derive a set of document properties which can be used when constructing the digital version.
A method 1100 of creating a document comprising a modifiable shape is disclosed. The method analyzes an image to detect at least a graphical object. The method matches the detected graphical object with at least one of a plurality of predetermined modifiable closed-form non-textual template shapes e.g. 420 comprising control parameters for modifying the closed-form non-textual template shape in a non-affine manner. The number of control parameters of the predetermined modifiable closed-form non-textual template shape is less than the number of sections making up the modifiable closed-form non-textual template shape. The method creates a document comprising the at least one modifiable closed-form non-textual template shape.
A moving image creating apparatus includes a memory that stores a plurality of template files each of which holds a plurality of component templates each for accommodating an image. An input device that selects any one of the template files stored in the memory. A processing unit analyzes metadata about each of a plurality of images. The processing unit analyzes metadata about each of the component templates in the selected template file. Further the processing unit places the images into the component templates of the selected template file in accordance with the analyzed metadata about the images and the analyzed metadata about the component templates and places one of the images into one of the component templates of the selected template file in response to a determination that none of the metadata about each of the images matches the analyzed metadata about the one of the component templates.
An object is held in any one of a plurality of specific orientations to present an aspect corresponding to a specific orientation to an imaging module of an electronic device. An image of the aspect is captured. The current captured image is compared with images in a library of image-command associations to find a match. If a match is found the electronic device triggers a command execution of the matching image-command association. If no match is found a new image-command association is established and stored in the library of the image-command associations.
A system and method detects matches between portions of video content. A matching module receives an input video fingerprint representing an input video and a set of reference fingerprints representing reference videos in a reference database. The matching module compares the reference fingerprints and input fingerprints to generate a list of candidate segments from the reference video set. Each candidate segment comprises a time-localized portion of a reference video that potentially matches the input video. A classifier is applied to each of the candidate segments to classify the segment as a matching segment or a non-matching segment. A result is then outputted identifying a matching portion of a reference video from the reference video set based on the segments classified as matches.
In an image classification method dividing an input image into blocks; obtaining block features of each block of the image; performing an evaluation of each block based on the block features thereof; obtaining image features based on the evaluations of the blocks of the image; and classifying the image based on the image features into pre-defined categories.
Aspects of the invention pertain to identifying whether or not an image from a user s device is of a place. Before undertaking time and resource consuming analysis of an image using specialized image analysis modules pre-filtering classification is conducted based on image data and metadata associated with the image. The metadata may include geolocation information. One classification procedure analyzes the metadata to perform a high level determination as to whether the image is of a place. If the results indicate that it is of a place then a further classification procedure may be performed where the image information is analyzed with or without the metadata. This process may be done concurrently with a place match filtering procedure. The results of the further classification will either find a match with a given place or not. The output is a place match either with or without geolocation information.
Disclosed is an automatic video summarization device and method using a fuzzy OC-SVM one-class support vector machine algorithm. A user s subjective decision is reflected in order to generate an effective video summary and a method for generating flexible video summary information which satisfies the user s environment or requirements is provided. Important video segments are extracted from a given video and a sequence of key frames is extracted from the video segments and hence the user can catch the contents of the video quickly and access desired video scenes.
A pattern identification apparatus for identifying one of a plurality of classes defined in advance to which data of a pattern identification target belongs comprises a read unit adapted to read out from a storage unit in correspondence with each of the plurality of classes a projection rule to a hyperplane which approximates a manifold corresponding to the class in a feature space an input unit adapted to input identification target data; a calculation unit adapted to calculate for each class a projection result obtained by projecting the input identification target data to the hyperplane which approximates the manifold corresponding to each of the plurality of classes on the basis of the projection rule; and an identification unit adapted to identify on the basis of the projection result of each classes calculated by said calculation unit one of the plurality of classes to which the identification target data belongs.
Methods and systems are provided for storing organizing and accessing image-based documents. The method includes receiving an image-based document conducting an OCR conversion process to produce an equivalent document in text format identifying keywords of the equivalent document in text format linking the keywords with the image-based document and the corresponding equivalent document in text format and storing the image-based document the corresponding equivalent document in text format and the keywords in a relational database.
Systems and methods are described that facilitate dominant point detection for text in a scanned document. The dominant points are classified as &#x201c;major&#x201d; e.g. structural and &#x201c;minor&#x201d; e.g. serif . A set of rules or parameters for each character is determined off-line. During the text vectorization OCR is performed and the rules parameters associated with the recognized character are selected. Both major and minor dominant points are detected as a maximization process with the parameter set. For minor dominant points additional processes are optionally employed.
A first combination of feature and processing content of image data is stored in a storing unit in a first period and a second combination of feature and processing content of image data is stored in the storing unit in a second period that is later in terms of time. When a change in processing content is detected between the first period and the second period an updating unit updates the first combination to the second combination. An acquiring unit acquires a processing content for target image data based on a combination of feature and processing content stored in the storing unit. An output unit outputs the processing content acquired by the acquiring unit.
A system recognizes the outline of an object that includes at its edge a portion including a rollover or a chipped portion. An image processing unit finds an outline of an object having a flat face from an image captured perpendicular to the flat face. A dark-transition-boundary detecting unit detects on each of a plurality of recognition lines a possible boundary point of dark-transition where a bright-to-dark transition occurs from outside toward inside of the object. A bright-transition-boundary detecting unit detects a possible boundary point of bright-transition where a dark-to-bright transition occurs from outside toward inside of the object. An edge detecting unit detects an edge point on the basis of the possible dark-transition-boundary point and the possible bright-transition-boundary point. An outline-determining unit determines an outline of the object that minimizes the sum of deviations between the outline and the respective edge points detected on the recognition lines.
Disclosed is a method for determining the absence or presence of one or more instances of a predetermined pattern in an image and for determining the location of each found instance within a multidimensional space. A model represents the pattern to be found the model including a plurality of probes. Each probe represents a relative position at which a test is performed in an image at a given pose each such test contributing evidence that the pattern exists at the pose. The method further includes a comparison of the model with a run-time image at each of a plurality of poses. A match score is computed at each pose to provide a match score surface. Then the match score is compared with an accept threshold and used to provide the location any instances of the pattern in the image.
A pattern matching method which is capable of selecting a suitable measurement object pattern even on a sample containing a periodic structure and a computer program for making a computer execute the pattern matching. In a pattern matching method which executes matching between the design data-based first image of an object sample and a second image whether or not a periodic structure is included in a region to execute the matching is determined so as to select a pattern based on distance between an original point which is set in said image and the pattern configuring said periodic structure in the case where the periodic structure is included in said region and to select a pattern based on coincidence of the pattern in said image in the case where the periodic structure is not included in said region and a computer program product.
A computer-implemented method for moving information between computing devices includes capturing a digital image of a display of a first computing device using a camera of a second computing device transmitting to the first computing device data that corresponds to the digital image; analyzing the transmitted data on the first computing device to determine whether the digital image matches a current display of the first computing device and using the analysis to cause one of the first or second computing devices to invoke an application and match a state of an application that is executing on the other of the first or second computing devices.
Image feature selection and extraction e.g. for image classifier training is accomplished in an integrated manner such that higher-order features are merely developed from first-order features selected for image classification. That is first-order image features are selected for image classification from an image feature pool initially populated with pre-extracted first-order image features. The selected first-order classifying features are paired with previously selected first-order classifying features to generate higher-order features. The higher-order features are placed into the image feature pool as they are developed or &#x201c;on-the-fly&#x201d; e.g. for use in image classifier training .
A method system and machine-readable medium for classifying an image element as one of a plurality of categories including assigning the image element based on a ratio between an unoccluded perimeter of the image element and an occluded perimeter of the image element and coding the image element according to a coding scheme associated with the category to which the image element is classified. Exemplary applications include image compression where categories include image foreground and background layers.
There is provided a character string updated degree evaluation program that enables quantitative grasping of an amount of intellectual work through editing and updating of character strings. A text subjected to comparison is divided into common part character strings each having a length greater than or equal to a threshold value and non-common part character strings. A number of edited points from the original text and a context edit distance are calculated based on the rate of the common part character strings and the occurrence pattern thereof. A number of edited point is acquired from a number of elements contained in a common part character string set and a context edit distance is acquired from a change in an order of occurrence of the common part character strings. Calculation of a new creation percentage and analysis by an N-gram are performed on the non-common part character string. The new creation percentage is acquired from the total length of the elements contained in a non-common part character string set and a new creation novelty degree is acquired from a non-partial matching rate between a non-common part character string set and an element contained in the non-common part character string set. Calculations for the common part character string set and for the non-common part character string set are united thereby calculating a text updated degree.
The present invention is a method and apparatus for protection of products and packaging against counterfeiting using dedicated authentication protocol coupled with portable devices. It is based on the product identification information i.e. PIN generated by the product manufacturer stored in the product database and added to product or packaging in an open and/or a hidden form. The open part is directly available to the consumer before buying opening or consuming the product or package or damaging its integrity while the hidden part is only revealed after these operations. The hidden information can also be disappearing after a predefined interval of time or number of trials or usages. Both parts are communicated to the authentication server in a predefined order to verify the product or package authenticity. The presence absence or multiple requests for the same product PIN confirm or reject product authenticity or detect attempt at attacking the system or at using counterfeited products.
A method for assisting in the creation of a logical structure model which stores from an image in which character strings associated respectively with a plurality of logical elements constituting a logical structure are described the logical elements character strings associated with the logical elements and the logical structure wherein character strings in an input image and the logical structure among the character strings in the input image are extracted a logical element is selected among the plurality of logical elements according to the degrees of similarity between the extracted character strings and the character string associated respectively with the plurality of logical elements stored in the logical structure model a character string associated with the selected logical element and a character string in the input image associated with the logical element based on the logical structure among the extracted character strings in the input image are extracted.
A document image processing apparatus includes an specifying section an extracting section a recognizing section an interpreting section an arranging section and a generating section. The specifying section specifies a sentence region including a character row from a document image. The extracting section extracts at least one of character row images included in the specified sentence region. The recognizing section recognizes respective characters included in the extracted character row image. The interpreting section interprets an original sentence character row comprising the recognized characters and generates an interpreted sentence character row. The arranging section arranges the respective character row images in the sentence region by contracting the respective character row images. The arranging section arranges the generated respective interpreted sentence character rows in a vacant region except a region arranging the respective character row images from the sentence region.
The present invention provides a technique for retrieving pictures from a large database that is less complex and uses significantly less memory and computational resources than current techniques. This is accomplished by determining representative data vectors based on a tolerance distance that represents data vectors in a given vector space that defines the picture to extract features of the picture that facilitates in retrieving pictures.
A method for finding edge points of an object is disclosed. The method includes receiving an electronic image of an object selecting one or more edge points in the image of the object creating an image template for each edge point in the object image. The method further includes receiving a command to measure a second object of the same kind as the object and obtaining a measured object image reading the image templates for the same kind of object from the storage device and finding a matched sub-image to each image template from the measured object image according to an image matching algorithm obtaining a central point of each matched sub-image and displaying coordinates of the central point of the matched sub-image.
The invention relates to a method for noise suppression in medical images comprising steps of measuring the gradient field strength of an image pixel and selecting a suitable filter mask for noise suppression as a function of the gradient field strength with the value of the gradient field strength being compared with a predetermined threshold value. The method is repeated when an additional image pixel is selected. A decision is made per read-in image pixel as to which type of filter mask is used for filtering. A selection can be made between filter masks of different sizes or isotropic or anisotropic or directional filter masks. The decision is based on the measured gradient field strength of the respective pixel. The use of different filter masks allows the signal-to-noise ratio to be improved without distorting structures like edges for instance and without generating artificial structures in homogenous noise regions.
Physical page layout analysis for optical character recognition is performed. A physical page layout analysis method finds constituent parts of an image and gives an initial data-type label such as text or non-text. Within the text data connected components are identified and analyzed. Tab-stops are detected from groups of edge-aligned connected components. The detected tab-stops are used to deduce the column layout of the page by finding column partitions. The column layout is then applied to find the polygonal boundaries of and a reading order of regions containing flowing text headings and pull-outs.
A system and a method for automatic restoration of isotropic degradations of a digital image based on receiving a blurred image by an image capture assembly automatically finding proper step edge calculating the PSF from the step edge and restoring the blurred image by means of a processor and with the option to display the resorted image by means of an output assembly.
Provided is an image quality evaluation method for evaluating image qualities of a second image by using a difference from a first image. In the image quality evaluation method a representative pixel component value indicating a pixel component value that represents pixels in the image frame of one of the images and pixel position information indicating a pixel position where the representative pixel component value appears are extracted as a feature quantity. By using the representative pixel component value and the pixel position information which are the image feature quantity and based on a difference between a pixel component value at the pixel position indicated by the pixel position information in the image frame of the other image and the representative pixel component value a difference of the entire second image from the first image is estimated.
A detector detects a specified image in an input image. The detector includes an area determination unit for determining in the input image a detection target area in which the specified image potentially exists a setting unit for setting positions of a plurality of matching target ranges substantially in the detection target area each of the matching target ranges being a predetermined size so that the matching target ranges cover the detection target area and each matching target range overlaps a neighboring matching target range by a predetermined overlap width and a matching unit for detecting the specified image by matching a portion of the input image encompassed by each matching target range set by the setting unit and a template image for detecting the specified image.
A method and a device are for an automated comparison of at least two sets of measuring values. The measuring values of the two sets are assigned respectively to one class from a finite number of classes defined by indices so that a frequency distribution is defined respectively for each of the two sets which frequency distribution indicates for each class a frequency of the measuring values assigned to this class. A distance measure reflecting a similarity or dissimilarity between the two sets of measuring values between these frequency distributions is calculated as a function of a final value of a first auxiliary value termed here match by way of example. The first auxiliary value match is calculated by an algorithm using two sets of variables in that with a given maximum distance dmax&#x2267;1 for all integral distances d with 0&#x2266;d&#x2266;dmax beginning with d=0 and continuing to larger distances d respectively for all indices i and j at a distance from each other by the distance d. A current value of a further auxiliary value is defined as m=min qi ; vj ; m stands for the further auxiliary value qi ; for the variables of a first of the two sets of variables and vj ; for the variables of the second set of variables the variables of the two sets of variables being defined at the beginning of the algorithm as qi ;=qi vj ;=vj wherein qi stands for the frequencies from a first of the two frequency distributions and vj for the frequencies of the second frequency distribution. Respectively the variables qi ; and vj ; are defined again by subtracting the current value of the further auxiliary value m and the current value of the further auxiliary value m multiplied by a matrix element ai j is added to a current value of the first auxiliary value match defined originally as match=0 the matrix elements ai j forming a similarity matrix with ai i=1 for all indices i and 0&#x2266;ai j&#x2266;1 for all indices i and j at a distance of at most dmax with i&#x2260;j.
An object identification system iteratively learns both a template map used to transform a template describing an object in an image and a related similarity metric used in comparing one transformed object template to another. This automatic learning eliminates the need to manually devise a transformation and metric that are effective for a given image corpus. The template map and the similarity metric are learned together such that the incremental component to be added to the template map at a given iteration of the learning process is based at least in part on the components of the similarity metric and vice-versa.
Disclosed is a method for determining the absence or presence of one or more instances of a predetermined pattern in an image and for determining the location of each found instance within a multidimensional space. A model represents the pattern to be found the model including a plurality of probes. Each probe represents a relative position at which a test is performed in an image at a given pose each such test contributing evidence that the pattern exists at the pose. The method further includes a comparison of the model with a run-time image at each of a plurali of poses. A match score is computed at each pose to provide a match score surface. Then the match score is compared with an accept threshold and used to provide the location any instances of the pattern in the image.
An image comparison method compares a reference image with a test image. Each image includes objects and a background. The method generates a skeleton image of the reference image. The skeleton image of the reference image is compared with the test image so as to determine if the reference image have more objects or objects parts than the test image. Similarly a skeleton image of the test image is generated. The skeleton image of the test image is compared with the reference image so as to determine if the test image have more objects or objects parts than the reference image.
The present invention is related to a method for resolving contradicting output data from an Optical Character Recognition OCR system providing a conversion of pixelized documents into computer coded text as the output data wherein the OCR output data comprises at least a first and second character listed as being likely candidates for an exemplar of a same sampled character instance from the pixelized document by providing steps that identify locations of differences in graphical appearance between the candidate characters and then using the location information to identify a corresponding locations in the sampled character instance. Based on correlation technique this location information is used to select the correct candidate character as the identification of the sampled character instance.
Methods and apparatus for directional texture generation using flow-guided sample-based texture synthesis. A texture synthesis directional texture generation method may for example be used to design hair or hairstyles. The method may obtain one or more strokes one or more optional masks one or more optional user maps and directional texture samples. A target region and one or more samples may be divided into patches. For each patch in the target region a matching patch from the samples may be located according to one or more features to generate a similarity map. The patches in the target region may then be replaced with the patches from the samples according to the similarity map. To match sample patches to target region patches based on features such as color and brightness a procedural directional texture generation method may be used as a pre-processing step.
Described is a technology by which an image is classified e.g. grouped and/or labeled based on multi-label multi-instance data learning-based classification according to semantic labels and regions. An image is processed in an integrated framework into multi-label multi-instance data including region and image labels. The framework determines local association data based on each region of an image. Other multi-label multi-instance data is based on relationships between region labels of the image relationships between image labels of the image and relationships between the region and image labels. These data are combined to classify the image. Training is also described.
The present invention discloses an image processing apparatus for processing an image. The image processing apparatus includes a line-pattern detecting module and an image processing module. The line-pattern detecting module examines how a first plurality of pixels of a first pixel line change and how a second plurality of pixels of a second pixel line change so as to determine which pattern an area of the image corresponds to. The image processing module selectively performs at least one of a plurality of image processing operations according to the pattern the image area corresponds to. The first and the second pixel lines correspond to the image area.
When a small block area enters a first two-dimensional code during a scan and features of the image within the area of a position in the first two-dimensional code coincide with a two-dimensional code the block area is specified as containing a code and a recognition process is performed in the nearby areas. When the recognition of the two-dimensional code has been successful the area of the first two-dimensional code is further extracted. When the extraction of the area of the first two-dimensional code has been successful the scan using the small block area is further continued to search for a second two-dimensional code. With an already recognized entrance to the area of the first two-dimensional code the area is skipped to continue the search. The second two-dimensional code is detected at a high speed by repeating the operation.
Methods and systems for managing digital photos are disclosed. In one implementation a method for organizing digital photos includes receiving a set of digital photos analyzing the set of digital photos to create tags that identify content information in the set of digital photos tagging the set of digital photos in accordance with their corresponding content information categorizing the set of digital photos in accordance with their corresponding tags and displaying the digital photos and their corresponding tags with a display device.
Systems methods and media for transitioning detecting content change in a streaming image system are disclosed. One embodiment provides a method for detecting a content change between image frames in a streaming image system. Embodiments may include selecting a change detection algorithm from a plurality of change detection algorithms and comparing a first image frame of m image stream with a second image frame of the image stream using the selected change detection algorithm. Embodiments may also include in the event of detecting a content change between the first image frame and the second image frame generating an indication of the content change. Further embodiments may include selecting the change detection algorithm based on a user s selection or system capabilities. Other further embodiments may include transmitting the indication of the content change.
The present invention discloses an on-line identifying method of hand-written Arabic letter. The advantage of the present invention is that the multilayer coarse classification algorithm based on the local characteristic of Arabic letter fully utilize the various local characteristics of Arabic letter obtain the first candidate letter aggregation matching with the inputted hand-written Arabic letter according to the first level coarse classification formed by the stroke number of letter and then obtain the second candidate letter aggregation matching with inputted hand-written Arabic letter according to the other local characteristics and the first candidate letter aggregation. The application of the algorithm enables that the inputted hand-written Arabic letter only need to match with the standard letter stored in the predetermined letter library and the corresponding standard letters of the second candidate letter aggregation.
The present invention relates to for example an image pickup system having a structure capable of imaging a subject at a low power consumption and a low cost even when the subject may be dark. The image pickup system comprises an image pickup device a peak position detecting section a partial image acquiring section and a partial image operating section. The image pickup device outputs image data that represents the two-dimensional intensity distribution of light incident on a photodetecting section and outputs light intensity profile data that represents the one-dimensional intensity distribution of the incident light in each of first and second directions in the photodetecting section. The peak position detecting section detects a light intensity peak position in the two-dimensional intensity distribution of the light incident on the photodetecting section in the image pickup device based on the light intensity profile data outputted from the image pickup device. The partial image acquiring section acquires a partial image from an entire image that can be imaged by the image pickup device so that the light intensity peak position detected by the peak position detecting section is made a specific position for the partial image in the entire image. The partial image operating section integrates the acquired partial image.
This method includes: extracting a feature vector for an input character from a reading result of the input character; calculating distances between the feature vector for the input character and vectors including average vectors stored in a system dictionary storing for each character the average vector and distribution information and feature vectors stored in a user dictionary; extracting the top N character codes in an ascending order of the calculated distances; obtaining second distribution information for the character codes which are included the user dictionary and in the top N character codes; calculating for each of the top N character codes a second distance with the feature vector for the input character by using for the character codes which are included in the user dictionary and in the top N character codes the second distribution information; and identifying a character code whose second distance is shortest.
An information processing apparatus that compares a query image and a model image and provides support information for discriminating a subject of the model image from a subject of the query image is disclosed. The information processing apparatus includes: a feature point extracting unit extracting one or more feature points from the model image; a feature describing unit describing features of the one or more feature points extracted by the feature point extracting unit; and a discrimination capability value calculating unit generating correlation images among the features described by the feature describing unit the extracted model image and one or more other model images for the one or more feature points extracted by the feature point extracting unit and calculating a discrimination capability value indicating the degree of contribution to discriminating the subject of the model image on the basis of the correlation images.
A facial expression recognition apparatus includes an image input unit configured to sequentially input images a face detection unit configured to detect faces in images obtained by the image input unit and a start determination unit configured to determine whether to start facial expression determination based on facial image information detected by the face detection unit. When the start determination unit determines that facial expression determination should be started an acquisition unit acquires reference feature information based on the facial image information detected by the face detection unit and a facial expression determination unit extracts feature information from the facial image information detected by the face detection unit and determines facial expressions of the detected faces based on the extracted feature information and the reference feature information.
The method compares a first document 10 and a second document 20. The documents may be scanned in 110 112 or an electronic image formed in other ways 114 116. Each electronic image is then segmented into basic units 14 24 such as words lines or paragraphs. Differences between the matched basic units 14 24 are determined and a document 30 representing the differences is created 130 and output 132.
An image processing apparatus and method generate a vector expression by defining a direction and attribute of gradation of an image as a daub color of the vector expression for each divided contour line of a similar color region obtained from an input image based on pixel values of plural sampling points inside each of the divided contour lines.
Disclosed herein is a method for detecting thin lines in image data. The method is performed by a processor to process contone image data. The processing includes thresholding a window of pixels established in the contone domain to generate a binary window of image data and then determining characteristics associated with on pixels or runs of the binary data. The characteristics start and end locations length of on runs are then thresholded. The processing in the contone and binary domain are used to determine if a thin line exists in the window of image data. The disclosed method produces better quality output images and reduces the addition of false lines in an image.
Disclosed is a method for determining the absence or presence of one or more instances of a predetermined pattern in an image and for determining the location of each found instance within a multidimensional space. A model represents the pattern to be found the model including a plurality of probes. Each probe represents a relative position at which a test is performed in an image at a given pose each such test contributing evidence that the pattern exists at the pose. The method further includes a comparison of the model with a run-time image at each of a plurality of poses. A match score is computed at each pose to provide a match score surface. Then the match score is compared with an accept threshold and used to provide the location any instances of the pattern in the image.
A method is provided for detection of an airborne contaminant in a atmospheric environment. The method comprises capturing an air sample from the atmospheric environment; separating candidate particles of interest from particles of non interest in the air sample; generating an image of the candidate particles; identifying a contaminant from among the candidate particles by comparing the image of candidate particles with a plurality of stored reference images each of which reflects a respective identified contaminant; and notifying a remote third party in response to detecting a contaminant from among the candidate particles.
Methods are disclosed for finding images from a large corpus of images that at least partially match a query image. The present method makes use of feature detectors to bundle features into local groups or bundles. These bundled features are repeatable and much more discriminative than an individual SIFT feature. Equally importantly the bundled features provide a flexible representation that allows simple and robust geometric constraints to be efficiently enforced when querying the index.
The present invention discloses methods for document-to-template matching for data-leak prevention DLP the methods including the steps of: providing a document as a stream of characters; splitting the stream into a plurality of serialized data lines; calculating a hash value for each serialized data line; checking for each hash value in a hash map of a template set; determining a similarity match to a particular template based on a predefined threshold of template hash values of the template set being found in the stream; and based on the similarity match executing a DLP security policy for the document. Preferably the template set is extracted from documents manually prepared by a security administrator. Preferably each template in the template set is deduced automatically from a plurality of documents.
An object recognition system performs a number of rounds of dimensionality reduction and consistency learning on visual content items such as videos and still images resulting in a set of feature vectors that accurately predict the presence of a visual object represented by a given object name within an visual content item. The feature vectors are stored in association with the object name which they represent and with an indication of the number of rounds of dimensionality reduction and consistency learning that produced them. The feature vectors and the indication can be used for various purposes such as quickly determining a visual content item containing a visual representation of a given object name.
The technology described herein includes a system and/or a method for identifying an object. The technology includes determining an alpha parameter that is associated with a fusion function. The technology includes determining a beta parameter that is associated with a degree of expected independence of a received set of data and the received set of data including information associated with a classification of the object. The technology includes fusing the received set of data based on the alpha parameter and the beta parameter. The technology includes generating a probability of identification of the classification of the object based on the fused data.
A method virtualizes an image sensor. The method comprises selecting one of at least two portions of a filter to use as a function of a mode of operation. The method comprises capturing an image using the selected one of the at least two portions. The method comprises executing a functionality using data extracted from the image. The functionality corresponds to the mode of operation.
A method for matching an image-form textual string in an image to a regular expression is disclosed. The method includes constructing a representation of the regular expression and generating a candidate string of characters from the image-form textual string. The method further includes ascertaining whether there exists a match between the image-form textual string and the regular expression the match is deemed achieved if a probability value associated with the match is above a predetermined matching threshold.
Methods and apparatus for identifying primary media content in a post-production media content presentation are disclosed. An example computer-implemented method to detect primary media content included in a secondary media content presentation disclosed herein comprises determining a first image corresponding to the secondary media content presentation the first image comprising a plurality of image subregions each image subregion representative of an inter-frame variation associated with a corresponding subregion of the secondary media content presentation selecting a region of the first image comprising a plurality of connected image subregions of the first image together exhibiting a first type of inter-frame variation and when a shape of the selected region of the first image corresponds to a predefined shape processing a region of the first captured image corresponding to the selected region of the first synthetic image to identify the primary media content.
The invention teaches a method of positioning a first image having a first image format into a second image comprising multiple image blocks and having a second image format. A straight boundary of at least one image block in the second image is identified. The first image is positioned into the second image by aligning an edge of the first image with the identified straight boundary. Alternatively a block row or column of the first image can be aligned with the straight boundary but then in such a way that an edge of the first image parallel to the block row or column is aligned with a boundary of a row or column of image blocks in the second image. This image positioning reduces any bleeding artifacts and the number of bits required for representing the image during encoding.
In an image processing apparatus a binary image generating unit generates a binary image from a multi-value image a ruled line candidate extracting unit extracts ruled line candidate pixels constituting a ruled line from the binary image an edge detecting unit determines from the multi-value image target pixels that are positioned near the ruled line candidate pixels and detects edge information indicative of whether each target pixel constitutes an edge and a ruled line obtaining unit obtains a ruled line from the multi-value image based on the edge information detected by the edge detecting unit.
A template-matching apparatus includes a first calculating unit calculating a first characteristic amount from the image information of a template image and extracting unit extracting a partial image a second calculating unit calculating for image information of the partial image a second characteristic amount a third calculating unit calculating a residual amount from the image information of the template image and the partial image a first computing unit finding a first degree of similarity a second computing unit that finds a second degree of similarity based on the residual amount a third computing unit finding a third degree of similarity based on the first and second degree of similarity and a specifying unit specifying a matching position thereby specifying the matching position with good accuracy even if the input image is observed with some geometrical change.
The present invention provides a system and method for detecting deformable objects in images even in the presence of partial occlusion clutter and nonlinear illumination changes. A holistic approach for deformable object detection is disclosed that combines the advantages of a match metric that is based on the normalized gradient direction of the model points the decomposition of the model into parts and a search method that takes all search results for all parts at the same time into account. Despite the fact that the model is decomposed into sub-parts the relevant size of the model that is used for the search at the highest pyramid level is not reduced. Hence the present invention does not suffer the speed limitations of a reduced number of pyramid levels that prior art methods have.
A comparison apparatus 2 designates first registration information RT1 inherent to a first parameter obtained by applying generalized Hough transform processing to a registered image AIM based on the set first parameter as the registration information RT1 used for the comparison and designating second registration information RT1 obtained by applying generalized Hough transform processing to the registered image AIM based on a second parameter different from the first parameter as the registration information RT1 used for the comparison when receiving an instruction for change of the registration information RT1 after the designation whereby security can be improved.
In an image data output processing apparatus of the present invention an image matching section is capable of determining whether a similarity exists between each image of an N-up document and a reference document when input image data is indicative of the N-up document. An output process control section is capable of regulating an output process of each image in accordance with a result of determining whether the similarity exists between each image of the N-up document and the reference document. This allows detecting with high accuracy a document image under regulation on the output process and regulating the output process when the input image data is indicative of an N-up document and includes the document image under regulation on the output process.
A system a computer readable storage medium including instructions and method for generating genre models used to identify genres of a document. For each document image in a set of document images that are associated with one or more genres the document image is segmented into a plurality of tiles wherein the tiles in the plurality of tiles are sized so that document page features are identifiable and features of the document image and the plurality of tiles are computed. At least one genre classifier is trained to classify document images as being associated with one or more genres based on the features of the document images in the set of document images the features of the plurality of tiles of the set of documents images and the one or more genres associated with each document image in the set of documents images.
A control unit 41 included in an image classification apparatus of the present invention performs a step of clustering a plurality of training images for each of a plurality of combination patterns of a plurality of feature quantities that an image has and a step of selecting from among the plurality of combination patterns a classification-use combination pattern to be used in image classification based on a result of the clustering. The clustering is performed based on degrees of similarity between the training images that have been calculated with use of the feature quantities constituting the combination patterns.
An image processing method includes receiving an image including a writing detecting a position of the writing in the received image detecting a position of a character image in the received image performing character recognition on the detected character image comparing the position of the detected writing with the position of the detected character image to associate the writing with a result of the character recognition translating the result of the character recognition so as to be recognizable as a translation of the result of the character recognition associated with the writing generating an image of the translation result associated with the writing so as to be output in a format different from a format of an image of a translation result that is not associated with the writing and outputting the image of the translation result associated with the writing.
Disclosed is a method for determining the absence or presence of one or more instances of a predetermined pattern in an image and for determining the location of each found instance within a multidimensional space. A model represents the pattern to be found the model including a plurality of probes. Each probe represents a relative position at which a test is performed in an image at a given pose each such test contributing evidence that the pattern exists at the pose. The method further includes a comparison of the model with a run-time image at each of a plurality of poses. A match score is computed at each pose to provide a match score surface. Then the match score is compared with an accept threshold and used to provide the location any instances of the pattern in the image.
The present invention provides for the recovery of characters entered into at least one data entry zone of a data entry window. A method in accordance with an embodiment includes: storing a first image of the data entry window during data entry; subtracting a reference image from the first image to obtain a delta image wherein the reference image is an image of the data entry window without data entered; identifying at least one non empty zone of the delta image and the location of the at least one data entry zone on the data entry window from the location of the at least one non empty zone on the delta image; extracting at least one character by applying optical character recognition to the least one non empty zone; and inputting the at least one character into the location of the at least one data entry zone.
An image retrieval method and apparatus for extracting a desired frame as still image data from moving image data is provided in which when a character search string is input frames having the character search string are retrieved from moving image data including a plurality of frames and if retrieved frames having the character search string in an equivalent position are consecutive for a predetermined amount one of the consecutive frames is extracted as still image data.
There is provided an image analysis system which captures image data of an arbitrary pair of a first image RI and a second image LI among images obtained by color-photographing a single object from different positions into an analysis computer wherein the computer includes corresponding point extraction means for assigning a weighing factor to a pixel information value based on the contrast size of the pixel information value in each of a first local area ROI1 set around an arbitrary reference point in RI and second local areas ROI2s at which scanning is performed on LI calculating the similarity between ROI1 and ROI2s and extracting a corresponding point which corresponds to the reference point from a ROI2 having the highest similarity and depth information calculating means for calculating depth information of the object based on coordinates of the reference point and the corresponding point.
A method of automatically establishing the correct orientation of an image using facial information. This method is based on the exploitation of the inherent property of image recognition algorithms in general and face detection in particular where the recognition is based on criteria that is highly orientation sensitive. By applying a detection algorithm to images in various orientations or alternatively by rotating the classifiers and comparing the number of successful faces that are detected in each orientation one may conclude as to the most likely correct orientation. Such method can be implemented as an automated method or a semi automatic method to guide users in viewing capturing or printing of images.
Establishments are identified in geo-tagged images. According to one aspect text regions are located in a geo-tagged image and text strings in the text regions are recognized using Optical Character Recognition OCR techniques. Text phrases are extracted from information associated with establishments known to be near the geographic location specified in the geo-tag of the image. The text strings recognized in the image are compared with the phrases for the establishments for approximate matches and an establishment is selected as the establishment in the image based on the approximate matches. According to another aspect text strings recognized in a collection of geo-tagged images are compared with phrases for establishments in the geographic area identified by the geo-tags to generate scores for image-establishment pairs. Establishments in each of the large collection of images as well as representative images showing each establishment are identified using the scores.
A method for manipulating an image the method includes: capturing image information representative of an image that includes images of textual characters; recognizing the textual characters by applying Optical Character Recognition; identifying the layout of the image; and applying at least one de-identification process on textual characters of interest to provide de-identification process results.
A method and gem pattern matching technique to analyze a target gemstone by analyzing a pattern created by transmitting a light source such as a laser beam through the gemstone to create a visual optical pattern and comparing the pattern to a database of known gemstone patterns to determine the percentage likelihood that the target gemstone will match a gemstone in the database. The matching is based on the weight of the heaviest spot in the pattern and its location in the gemstone image and comparing it to the weight and location of the heaviest spots in each gemstone image in the database to determine a percentage matching.
The present invention includes a method of secure data entry that enables complex data entry work to be performed by unskilled workers that results in data entry with higher productivity higher quality and higher security than data entry performed by highly skilled workers. The invention identifies data fields on an electronic image of an identified input page sequences identified data field images and individually displays data field images for manual data entry. The invention also provides for extracting data from a data field image and displaying extracted data along with the corresponding data field image for approval or correction. Sequenced data field images are optionally reordered or randomized for display and manual entry.
In a method for acquiring data from a machine-readable document for assignment to fields of a database individual data are extracted substantially automatically from the document and entered into the corresponding database fields. If data cannot be extracted from the document with a desired degree of reliability for one or more particular database fields then the steps are executed of displaying the document onto the display screen displaying on the display screen the at least one or more database fields for which the data cannot be extracted with the desired degree of reliability and executing a proposal routine with which string sections in the vicinity of a pointer movable by a user on the display screen are selected marked and proposed for extraction.
Image processing by which both of high compressibility and high image quality are achieved and in which characters in character regions and graphics in graphic regions are vectorized. If a pixel of a character in a character region overlaps with a graphic in a graphic region graphic region vectorization is performed first whereas if a pixel of a character in the character region does not overlap with a graphic in the graphic region character region vectorization is performed first.
A recognition device includes storage unit that stores information of a cluster to which a model feature point belongs; extracting unit that extracts a feature amount of a query feature point; generating unit that determines a first set of the query feature point including a reference point and a dependent point and generates geometric information; clustering unit that clusters the query feature point; correcting unit that sets up the model feature point as a nearest candidate of the reference point sets up the model feature point as a nearest candidate of the dependent point determines whether or not the nearest candidate of the reference point is present and corrects the model feature point; and similarity degree calculating unit that calculates a similarity degree of the first set and a second set and determines the second set nearest to the first set.
An image signature to be used for matching is generated by the following generation method. First region features are extracted from respective sub-regions of a plurality of pairs of sub-regions in an image and for each of the pairs of sub-regions a difference value between the region features of two sub-regions forming a pair is quantized. When performing the quantization the difference value is quantized to a particular quantization value if an absolute value of the difference value is smaller than a predetermined value. Then a collection of elements which are quantization values calculated for the respective pairs of sub-regions is used as an image signature to be used for discriminating the image. An image signature matching device matches an image signature of a first image and an image signature of a second image generated by the above-described generation method in such a manner that a weight of an element having the particular quantization value is reduced.
A method for creating a page template corresponding to a form for use in a mark recognition system includes identifying at least one path of traversal across a form detecting edge transitions along each such path and creating page template using the detected edge transitions.
An authentication apparatus is provided. A forgery determination threshold is determined on the basis of two types of parameters a forgery similarity and a forgery difficulty. If a calculated value for an object under test is lower than or equal to the forgery determination threshold then it is determined that the object is a biologic object. Thus easiness in impersonation with a fake of a biologic object that is easy to forge may be reduced and a false rejection due to a determination in which a biologic object is erroneously determined as a fake may be reduced.
The method system and apparatus of source statistics based intra prediction type is disclosed. In one embodiment a method includes classifying a four-pixel square block in an edge class e.g. may include a DC edge class a vertical edge class a horizontal edge class a diagonal edge class and/or a planar edge class based on an edge classifier classifying an eight-pixel square block having the four-pixel square block and other four-pixel square blocks as a homogenous class if the four-pixel square block and the other four-pixel square blocks of the eight-pixel square block belong to the edge class assigning a direction to the edge class of the eight-pixel square block and determining an optimal intra-prediction type through the classification such that empirical testing of all possible ones of the edge class and the direction is avoided when the homogenous class is identified.
An information processing apparatus inputs image data including a first pixel group a second pixel group generated by interpolating the first pixel group and verification data of the first pixel group verifies whether the first pixel group has been altered using the first pixel group and the verification data verifies whether the second pixel group has been altered by determining whether the second pixel group and the first pixel group are in a predetermined relationship and determines whether the image data has been altered based on results of the verification as to whether the first pixel group has been altered and the verification as to whether the second pixel group has been altered.
The invention to be provided relates to focusing control for obtaining a detected image necessary for image authentication. Through the focusing control a lens is controlled to be located at an optimum position upon starting authentication. An image authenticating apparatus compares a detected image with a recorded image to carry out authentication using the detected image and the recorded image. The apparatus includes an image-capturing unit camera unit that obtains the detected image by capturing an image of a photographed subject a display unit image display unit that displays the detected image on a screen displaying a target image showing the outline of a portion to be detected and a controlling unit image processing unit that controls the lens of the image-capturing unit to locate the lens at a given focusing position relative to the photographed subject upon obtaining the detected image.
A method of target recognition performs a 3D comparison of target and reference data. Translation invariant signatures are derived from the two data sets and an estimate of the orientation of the target with respect to the reference is obtained. Rotational alignment and comparison can then be achieved. The 3D data sets can be represented on an axi-symmetric surface such as a sphere and rotational convolution over a discrete set of selected rotation angles can be performed. Optic flow can be used to derive the estimate of orientation or the target relative to the reference in terms of a displacement field.
A method of identifying an image classification for an input digital image comprising receiving an input digital image for a captured scene; receiving a range map which represents range information associated with the input digital image wherein the range information represents distances between the captured scene and a known reference location; identifying the image classification using both the range map and the input digital image; and storing the image classification in association with the input digital image in a processor-accessible memory system.
Techniques are disclosed for discovering object type clusters using pixel-level micro-features extracted from image data. A self-organizing map and adaptive resonance theory SOM-ART network is used to classify objects depicted in the image data based on the pixel-level micro-features. Importantly the discovery of the object type clusters is unsupervised i.e. performed independent of any training data that defines particular objects allowing a behavior-recognition system to forgo a training phase and for object classification to proceed without being constrained by specific object definitions. The SOM-ART network is adaptive and able to learn while discovering the object type clusters and classifying objects.
Techniques are disclosed for identifying anomaly object types during classification of foreground objects extracted from image data. A self-organizing map and adaptive resonance theory SOM-ART network is used to discover object type clusters and classify objects depicted in the image data based on pixel-level micro-features that are extracted from the image data. Importantly the discovery of the object type clusters is unsupervised i.e. performed independent of any training data that defines particular objects allowing a behavior-recognition system to forgo a training phase and for object classification to proceed without being constrained by specific object definitions. The SOM-ART network is adaptive and able to learn while discovering the object type clusters and classifying objects and identifying anomaly object types.
A sheet music processing method of processing by an image processing apparatus image data of sheet music input by an input device the method comprising setting by a user using a designation unit of the image processing apparatus a unit in which the image data of the sheet music is processed; dividing the image data of the sheet music into units corresponding to the unit; determining whether image data of a first one of the units is repeated in one or more others of the units; and processing the image data when the image data of the first one of the units is determined to be repeated in the one or more others of the units to append information using the image processing apparatus to the image data of the first one of the units and the image data of the one or more others of the units.
Methods for estimating joint geometric and radiometric deformations relating two observations of the same object provide methods for identifying and matching images as in face recognition and for characterizing and determining the relationship between a pair of observations as in target recognition .
A system having an approach for prioritizing targets for an order of capturing the targets photographically or otherwise. Prioritizing is based on cost of obtaining or capturing the target for viewing or photographing in high resolution. One acquisition mechanism is for obtaining a wide field of view of a scene of targets and another acquisition mechanism is for obtaining a narrow field of view of a target for capture. The cost for prioritizing is based on the time that the narrow field of view acquisition mechanism takes to pan and tilt to get a close-up image of a target divided by the width of the target. The targets may be faces of people.
A learning device includes: a feature point extracting unit for extracting a feature point from each of multiple generated images made up of a positive image including an identified object and a negative image excluding the identified object; a feature point feature amount extracting unit for extracting feature point feature amount representing the feature of the feature point from the generated image; a whole feature amount calculating unit for calculating the whole feature amount representing the feature of the whole generated image based on the feature point feature amount of a feature point existing on a feature point selection range determined based on the multiple generated images of the generated image range; and an identifier generating unit for generating an identifier based on the whole feature amount of the generated image and a correct answer label representing whether the generated image is the positive image or the negative image.
A character classification system is disclosed. The character classification system has an input device for receiving a handwritten input character and a processor. The processor is configured to for each character model each character model being associated with an output character and defining a model specific segmentation scheme for that output character and an associated segment model the model specific segmentation scheme defining a minimum length corresponding to a number of points in a stroke of the output character: i decompose the handwritten input character into one or more segments in accordance with the model specific segmentation scheme of the respective character model; and ii evaluate the one or more segments against the segment model of the respective character model to produce a score indicative of the conformity of the one or more segments with the segment model. The processor then selects the character model that produced the highest score and classifies the handwritten input character as the output character associated with the character model that produces the highest score.
Handwriting activity is recorded by use of electromyography EMG signals detected from muscles at several locations on the hand. The EMG signals are sensed and registered. The sensed signals are processed and stored after which the signals are analyzed to reconstruct handwriting activity into a digital format. Machine edible text is generated and displayed along with a graphical depiction of the handwriting.
An intermediate image is generated between a reference image and a corresponding image. To achieve this moving subject images are detected in respective ones of a first image and second image captured at a fixed interval. A moving subject image of an intermediate image is positioned at a position that is intermediate the moving subject images. The intermediate image is generated utilizing the reference image in a portion of the image other than occupied by the moving subject image. A correction is applied in such a manner that the second image will coincide with the first image with the exception of the portion of the second image occupied by the moving subject image.
Some embodiments provide a method that provides a display area for displaying an image. Some embodiments provide a tool that when activated generates a deformable tunnel based on a cursor movement through the display area. The tunnel is for differentiating a region of interest of the image from the rest of the image. The method provides a moveable tool for determining a width for the tunnel region. The moveable tool is a slider tool in some embodiments. In some embodiments the moveable tool is for determining the initial width at which the tunnel is generated. The moveable tool is further for modifying the width of the tunnel after the tunnel is generated in some embodiments.
A method for correcting coaxial light image edge location errors in a precision machine vision inspection system is disclosed. The method comprises comparing an edge position measurement of a workpiece edge feature using coaxial light and stage light. Edge position measurements using stage light have a lower uncertainty than that of coaxial light. Position correction factors may be determined from the difference between the two edge position measurements. The position correction factors may be stored for correcting subsequent edge position measurements that are based on images acquired using coaxial light. In some embodiments position correction factors may be determined based on comparing edge position measurements for a plurality of edges.
A method for determining feature point locations in an image performs a first search in a predetermined first search area to search for locations of plural feature points in the image corrects the locations of the plural feature points based on a geometric layout relationship among the plural feature points searched for sets a second search area based on the corrected location of each of the feature points and performs a second search in the second search area to search for the location of each of the feature points. Then the method determines reliability of the location of each feature point searched for by the second search and selects one of the corrected location and the location searched for by the second search as a location of the feature point.
A document processing apparatus includes: a character segmentation unit that segment a plurality of character images from a document image; a character image classifying unit that classifies the character images to categories corresponding to each of the character images; an average character image obtaining unit that obtains average character images for each of the categories of the character images classified by the character image classifying unit; a character recognizing unit that performs a character recognition to a character contained in each of the average character images; and an output unit that outputs character discriminating information as a character recognition result obtained by the character recognizing unit.
A method of classifying a character string formed from a known number of hand-written characters is disclosed. The method starts by determining character probabilities for each hand-written character in the character string. Each character probability represents a likelihood of the respective hand-written character being a respective one of a plurality of predetermined characters. Each predetermined character has a respective character type. Character templates having the known number of characters are next identified. Each character template has a respective predetermined probability and represents a respective combination of character types. Character sequence probabilities corresponding to each of the character templates having the known number of characters are next determined. The character sequence probabilities are a function of the predetermined probability of the respective character template and the character probabilities of the hand-written character in the character string. The character string is classified as the sequence of characters having the highest character sequence probability.
A processing device may recognize a number of input handwritten strokes which may represent a mathematical expression a chemical formula or other two-dimensional structure. Rewriting rules of a grammar may be applied to the strokes to produce a number of possible recognition results. Each of the possible recognition results has a respective score based on a sum of rewriting rules applied to the strokes to produce respective ones of the possible recognition results. Input may be provided to identify misrecognized strokes and a correct terminal production or symbol corresponding to the misrecognized strokes. Strokes may be misrecognized for many reasons including parsing errors over-grouping or under-grouping of matrices and improper placement of a recognized terminal production or symbol with respect to a root structure. Correction hints may be leveraged for correcting types of errors mentioned above.
A house change judging method is provided for judging a change of a house in a data acquisition region based on new and old data concerning two periods which have been aerially acquired including: extracting as a judgment target region a predetermined region in the new data by trimming with house polygon data corresponding to a predetermined region prepared in advance; computing after the extraction as evaluation values two kinds of new and old difference values between the two periods with respect to a gradation value of color image data and an altitude value of altitude data across the entire judgment target region; and judging after the computation based on the evaluation values whether a house change has occurred in the judgment target region by referring to a judging table including combinations of two kinds of preset evaluation criterion values.
An information processing apparatus detects from time-sequential information continuously supplied for a given period of time associated information regarding a time at which a piece of information satisfying a predetermined condition is supplied within the given period of time. A dividing section divides the time-sequential information into a plurality of temporally successive information units at predetermined time intervals. A feature value detecting section temporally successively detects feature values of the plurality of temporally successive information units. A change-information detecting section stores the temporally successively detected feature values for a predetermined period of time and detects a plurality of temporally successive pieces of feature-value-change information on the basis of the stored feature values and a currently detected feature value. The change-information detecting section outputs the plurality of temporally successive pieces of feature-value-change information in sequence to output time-sequential associated information as the associated information.
Described is a system for ordering images. The system receives a plurality of images. Image features are extracted from each image. A set of all possible image pairs are generated for all images. A similarity metric with weights is generated between the images in each image pair in the set with a net similarity metric thereafter generated by combining the similarity metrics. The images are then ordered according to the net similarity metrics to generate a computer-ordered set of images. The computer-ordered set of images is then displayed to the user which allows the user to re-order the images to generate a user-ordered set of images. The weights are then optimized to minimize the distance between the computer-ordered set of images and the user-ordered set of images. The similarity metrics are then re-weighted with the images thereafter being re-ordered according to the new metrics.
A codebook generating method comprises a dividing and transforming step dividing an original image into original blocks and transforming each of the original blocks into an original vector; a parameter setting step setting a distortion tolerance and a predetermined number of representative blocks; a single group setting step setting the original vectors as a group; a preliminary grouping step grouping all the original vectors in a group currently having largest distortion into two groups using a grouping algorithm wherein the preliminary grouping step is repeated until the number of groups is equal to the predetermined number of representative blocks; and a grouping step grouping all the original vectors based on a plurality of initial centroids to obtain final centroids and storing vectors corresponding to the final centroids in a codebook wherein the centroids of the groups are treated as the initial centroids.
Methods and apparatuses for detecting a plurality of pixels of interest within an image and identifying luminance values corresponding to a predetermined object. The apparatus for detecting includes a memory configured to store first and second images captured using light of first and second wavelengths respectively. The apparatus for detecting further includes at least one processor configured to detect a plurality of pixels of interest within the first captured image based on luminance values of the stored first and second captured images. The apparatus for identifying includes a memory configured to store a processed image and at least one processor configured to determine frequencies of luminance values of the plurality of pixels of interest in the processed image and to determine a range of luminance values corresponding to a predetermined object within the processed image based on the determined frequencies of the luminance values.
Determining correspondence between image regions includes identifying first and second regions of visual content including pixels in a computer system. The first region includes a first patch of pixels having a first mapping to a second patch of pixels in the second region. Iterative evaluations of the first and second regions are performed each including at least i a first evaluation phase selecting a best mapping for the first patch according to a distance metric the best mapping selected from among the first mapping and a second mapping obtained from mappings of nearby pixels and ii a second evaluation phase selecting one of the best mapping and a third mapping obtained by perturbing the second mapping. A result of the iterative evaluations is recorded in the computer system that indicates a third patch of pixels in the second region identified in the iterative evaluations.
A matching degree computing apparatus is provided for comparing an input image and an object template image and computing a matching degree between an input image and an object template image based on the compared result. The computing apparatus includes a transforming unit for transforming the input image so as to be matched to the template object region and a computing unit for computing a matching degree between the transformed input image and the template image. The transforming unit provides a shaping unit for shaping a non-background region to the form of the template object region in the object corresponding region of the input image and a processing unit for arranging the non-background region contacting with the template object corresponding region so that the non-background region has no substantial impact on the matching degree in the object non-corresponding region of the input image.
Methods and corresponding systems of generating one or more image anchor templates for discriminating between documents of a first class and documents of other classes are provided. The methods include generating one or more candidate image anchor templates; determining using a computer processor a quality score for each of the one or more candidate image anchor templates; ranking the one or more candidate image anchor templates according to the quality scores of the one or more candidate image anchor templates; and selecting one or more of the most highly ranked image anchor templates.
Methods and corresponding systems of generating one or more image anchor templates for extracting data from a data field of a first class of documents are provided. The methods include generating one or more candidate image anchor templates from at least one of one or more exemplars of the first class; determining a quality score for each of the one or more candidate image anchor templates using a computer processor and known locations of the data field within the one or more exemplars of the first class; ranking the one or more candidate image anchor templates according to quality score; and selecting one or more of the most highly ranked image anchor templates.
A content-based image processing method and system are provided for images identified as having snow content. Images having dark snow content are identified and processed with a first enhancement chain tailored to enhancing images which would be generally perceived as having dark snow while images having blue snow content are identified and processed with a second enhancement chain tailored to enhancing images which would be generally perceived as having blue snow.
Techniques are disclosed for determining anomalous trajectories of objects tracked over a sequence of video frames. In one embodiment a symbol trajectory may be derived from observing an object moving through a scene. The symbol trajectory represents semantic concepts extracted from the trajectory of the object. Whether the symbol trajectory is anomalous may be determined based on previously observed symbol trajectories. A user may be alerted upon determining that the symbol trajectory is anomalous.
A method medium and apparatus for correcting a projected image is provided. The method includes detecting a pattern image based on photographing information of consecutive image frames into which a reference pattern and an offset pattern corresponding to the reference pattern are alternately inserted and which are projected onto a projection surface accordingly and correcting projected image frame based on the detected pattern image.
In one embodiment there is disclosed a method capturing data from a document image. The method 300 comprises processing the document image to identify at least one repetitive structure and performing a capturing operation including creating a plurality of instances of the repetitive structure based on once-described structure properties of the repetitive structure in a document template and populating each instance with corresponding data from the document image. The method may also include creating a document template for capturing data from a document image.
Multi-frame persistence of videotext is exploited to mitigate challenges posed by varying characteristics of videotext across frame instances to improve OCR techniques. In some examples each frame of video is processed to form multiple binary images and one or more text hypotheses is formed from each binary image. In some examples one or more combined images are formed from multiple frames processed to form a binary image and a corresponding text hypothesis. The text hypotheses are combined to yield an overall text recognition output.
A method is provided that includes capturing an input handwritten character with parameter representation for each stroke and applying a polygonal approximation thereto; assuming each polygonal line segment approximated to be vector that reaches an end point from a start point and obtaining an angle between an axis that becomes a reference and each line segment as a polygonal line segment angle sequence; obtaining an exterior angle sequence of vertices of the line segments; making a sum of exterior angles of the same sign where the same sign of plus or minus in the exterior angle sequence continues to be a winding angle sequence; extracting a global feature according to each obtained sequence and a localized or quasi-localized feature in each curved portion divided corresponding to the winding angle sequence hierarchically and divisionally; and performing character recognition by comparing the extracted result with a template of an object character.
The method of identifying an effective pigment comprises: a first step of imaging a target effective pigment to obtain image data thereof; a second step of subjecting the obtained image data to background processing and extracting image data concerning a region containing one particle of the effective pigment as image data for processing; a third step of extracting image characteristic parameters from the image data for processing; and
An image display device that includes an extraction component a calculation component an image processing component and a display component is provided. The extraction component extracts from photographic images a photographic image in which a face has been photographed. The calculation component calculates a position of an eye in the photographic image extracted by the extraction component. The image processing component performs image processing on the photographic image such that the position of the eye calculated by the calculation component will be at a predetermined position. The display component displays the photographic image which has been processed by the image processing component.
A method for setting a lip region of a face included in an image including setting a first region and a second region in an image including a face identifying contrast information of the first region setting a threshold for binarization using the contrast information and binarizing the second region based on the threshold. A region in which a pixel having an identical binary value continuously distributed within a predetermined number of ranges in the binarized image is set as an eye candidate object. An eye region is then extracted from the eye candidate object based on geometric characteristic of an eye region in an image and the lip region is set with reference to the extracted eye region based on geometric information of the eye region and the lip region.
There is provided an image processing apparatus that specifies a position of a predetermined characteristic portion of a target face image.
A method for processing an image of a person the method including: i defining a first search area in response to a value of a metric parameter and to a location of an element of interest within the image; ii generating an edge detection data structure wherein some of the elements of the edge detection data structure are indicative of edges of the image which are located within an edge detection search area that is contained within the first search area; iii determining a contour path in the edge detection data structure in response to multiple edges of the edge detection data structure wherein the contour path includes a single data structure element from each column of the data structure; and iv retrieving a face portion of the image wherein the face portion is included within a mask that is responsive to the contour path.
An image processing device includes a region-of-interest detecting unit that detects a region of interest from each of sequence images acquired in chronological order; a region dividing unit that divides a plurality of images temporally neighboring to each other into regions based on region-of-interest detection results obtained from the plurality of images; an inter-image variation calculating unit that calculates an inter-image variation between the plurality of images based on a variation in each region obtained by the division by the region dividing unit; and a display-condition setting unit that sets a display condition for each image based on the inter-image variation.
A method for the selective presentation of a plurality of images from a set of digital images provided for upload to a computing apparatus the method comprising providing image data representing the set of digital images for upload processing said image data in order to determine for respective ones of the images in the set a measure for: i image quality ranking ii duplicate image detection and iii face detection; and on the basis of the determination generating data representing a slideshow for the plurality of images.
There is described an image reading terminal having an image sensor array including a plurality of pixels a first optical assembly for focusing imaging light rays onto a first set of pixels of an image sensor array and a second optical assembly for focusing imaging light rays onto a second set of pixels of the image sensor array. The first set of pixels and the second set of pixels of the image sensor array can have different exposure settings in a single exposure period for the image sensor array. In one embodiment the indicia reading terminal can be adapted to process image data corresponding to pixels of the image sensor array for attempting to decode a decodable indicia.
An image processing apparatus performs character recognition processing on a character image in a character area to obtain character code data and performs vectorization processing on the character image in the character area to obtain vector data. Based on the rule set for each of a plurality of color information definitions and the character color of the character image the image processing apparatus generates a plurality of color information definitions that define colors to be used in rendering the character code data and the vector data so that an electronic document is generated that contains the character code data the vector data and the plurality of color information definitions.
In an image processing apparatus for determining whether input image data is identical with image data of a reference image or not and performing a process according to the result of the determination input image data whose similarity to a reference image is not less than a predetermined first threshold value or encoded image data obtained by encoding the input image data is stored in an access limitation storage section to which only a specific user is accessible. This allows an administrator to easily check whether the result of the determination is appropriate or not without requiring a larger and more complex structure.
An image search method that is robust and fast with computational complexity of logarithmic order relative to the number of models . The image search method including: extracting a plurality of specific regions possessing such a property that a shape can be normalized regardless of an affine transformation thereof as affine-invariant regions from one or more learning images; calculating with respect to a reference affine-invariant region other neighboring affine-invariant regions as a set; deforming the neighboring affine-invariant regions by a transformation to normalize the shape of the reference affine-invariant region; and outputting the deformed shapes of the neighboring affine-invariant regions together with combination of the reference affine-invariant region and the neighboring affine-invariant regions.
The present invention relates to a method for identifying dimensions of shot subject implemented on an identification system including a photo shooting unit capable of adjusting focal lengths. The method includes steps of using the photo shooting unit to focus on plural positions respectively having different field depths on a shot subject and respectively capture a image thereof determining whether resolutions of the captured images are same and if so the shot subject is a two dimensional object otherwise the shot subject is a three dimensional object.
A device for detecting a shadow region in an image includes an imaging module generating a multi-channel image including brightness red green and blue channels a brightness correcting module correcting values of the brightness channel based on imaging parameters and outputting a corrected multi-channel image a scene classifying module determining to carry out a shadow detection on the corrected multi-channel image a shadow detecting module classifying pixels of the corrected multi-channel image into a shadow or non-shadow pixel and generating a shadow classification mark matrix having pixels having a shadow classification mark value corresponding to the classification a region segmentation module segmenting the multi-channel image into regions having pixels having similar color values and generating a region mark matrix having pixels having a region mark value and a post-processing module updating the shadow classification mark matrix based on the shadow classification mark matrix and region mark matrix.
A method for detecting edges includes calculating a gradient level value for each pixel of a digital image and assigning each pixel to one of a plurality of gradient bins based on the calculated gradient level value for each pixel the gradient bins being defined by threshold levels. One or more of the gradient bins are assigned as edge bins and one or more of the gradient bins are assigned as non-edge bins according to the number of pixels assigned to each gradient bin. Pixels in the one or more edge bins are identified as edge pixels and pixels in the one or more non-edge bins are identified as non-edge pixels in an edge map. The one or more gradient bins are assigned such that a minimum number of pixels are identified as edge pixels and no more than a maximum number of pixels are identified as edge pixels.
There are provided a device and method for detecting joint parts of a steel strip in an endless hot rolling process. The device for detecting joint parts of a steel strip in an endless hot rolling process includes an image signal collection block receiving image signals each having information on gray level pixels of a steel strip from a charge coupled device CCD camera; an edge line detection block receiving the image signals from the image signal collection block to detect an edge line of the steel strip; a profile calculation block receiving information on the detection of the edge line from the edge line detection block to calculate the sum of gray levels up to an edge line of the steel strip in a traverse direction of the steel strip when the edge line is detected by the edge line detection block; a joint part judgement block receiving information on the sum of the gray levels which shows a current profile value from the profile calculation block to judge the edge line as a joint part when a ratio of a mean value of the current profile and a mean value of the previous profile is less than a predetermined value; and an output block receiving information on the judgement of the edge line as the joint part from the joint part judgement block to output a joint part-detecting signal when the edge line is judged to be a joint part.
There is provided an image processing apparatus. The image processing apparatus includes: an obtaining unit configured to capture an image; a specifying unit configured to specify at least one pixel on an edge of the image; a tracking unit configured to track pixels that are similar to the at least one pixel among peripheral pixels around the at least one pixel; and an estimating unit configured to estimate as a region of interest a region other than a region consisting of the pixels tracked by the tracking unit.
A feature used in face detection can be applied to an image portion and can be scaled to fit differently sized image areas. If a feature is positioned with respect to an image area such that a vertex of the feature is aligned with a non-integer pixel location at least one dimension of the filter can be rounded. A dimension to be rounded further can correspond to a directional component of the feature. For instance contrast regions within the feature can be arranged horizontally such that the vertical dimension represents a directional component. A rounding rule associated with the feature can be used in rounding a dimension corresponding to a directional component such that a size ratio between the contrast regions is maintained. In some instances the rounding rule can specify a factor that is a positive integer determined based on the number of contrast regions in the feature.
Techniques for determining if two video signals match by extracting features from a first and second video signal and cross-correlating the features thereby providing a cross-correlation score at each of a number of time lags then determining a mean magnitude of a difference of average values at each of the lags and finally determining the similarity score based on both the cross-correlation scores and the mean magnitude difference scores and optionally then outputting an indication of a degree of match between the first and second video signals.
Change image detecting devices and methods are disclosed. In one example a determination unit partially compares a first image and a reference image and determines whether there is a change therebetween. If the determination unit determines no change between the first image and the reference image the change image detecting unit selects a second image which is temporally later than the first image and stored in a first storing unit as a new image to be processed and the determination unit partially compares the second image and the reference image at a different position than previously compared and determines whether there is a change between the second image and the reference image. If the determination unit determines change between the first image and the reference image a change image detecting unit detects the first image stored in the first storing unit as the change image and stores the first image in the second storing unit.
Disclosed is a method for determining the absence or presence of one or more instances of a predetermined pattern in an image and for determining the location of each found instance within a multidimensional space. A model represents the pattern to be found the model including a plurality of probes. Each probe represents a relative position at which a test is performed in an image at a given pose each such test contributing evidence that the pattern exists at the pose. The method further includes a comparison of the model with a run-time image at each of a plurality of poses. A match score is computed at each pose to provide a match score surface. Then the match score is compared with an accept threshold and used to provide the location any instances of the pattern in the image.
A 2D model fitting means 1201 estimates values of parameters optimum to generate a probe model image similar to a probe image and a gallery model image similar to a gallery image with an image variation model 1204. At that time among a plurality of parameters of the image variation model 1204 the value of a parameter of which sameness between the probe image and the gallery image is to be judged as a target parameter is set to be the same for both images. A model goodness-of-fit evaluation means 1202 computes a model goodness of fit for the probe model image and the gallery model image to the probe image and the gallery image under the estimated parameters. A collation means 1203 compares the model goodness of fit with a threshold value to judge the sameness between the probe image and the gallery image.
A method of determining a regular grid pattern from a surface coded pattern that comprises the regular grid pattern interleaved with a further data carrying pattern wherein the surface coded pattern is subject to perspective distortion the method comprising: extracting a set of straight line hypotheses from the coded surface pattern; clustering the straight line hypotheses by orientation; for each cluster extracting a set of line pencil hypotheses;
An area extraction method including obtaining a character lattice showing a connection relation between unit areas which are obtained by separating a character string pattern in an image into patterns each recognized as corresponding to a single character judging whether or not all combinations of each of the unit areas in the obtained character lattice and each of the unit areas in a regular lattice defining a regular connection relation between the unit areas are likely to be established generating a path coupling between nodes corresponding to the combination of the unit areas which is determined as likely to be established determining an optimum path from the generated paths based on a degree of coincidence with the regular lattice or the character lattice and extracting from an image the unit areas in the character lattice corresponding to the determined optimum path.
Embodiments include an article of manufacture apparatus device system computer-program product and method. In an embodiment an article of manufacture includes a display surface that includes a machine-distinguishable form identifier keyed to an electronic version of the form and at least two fields. Each field of the at least two fields respectively includes a unique machine-distinguishable field identifier keyed to a field of the electronic version of a form a content area that accepts a hand-formed entry and a unique user-understandable field identifier.
An image processing system according to the present invention includes: a management server in which related information set with respect to reference image data is stored; a similarity determination process section for determining whether or not there is a similarity between input image data and the reference image data; a related information obtaining process section for obtaining related information from a related information storage section if the similarity determination process section determines that there is a similarity between the input image data and the reference image data; and a control section for adding the related information obtained to the input image data. With the arrangement it becomes possible for the image processing system to add appropriate related information to inputted image data so as to realize an accurate search for the image data on the basis of the related information.
Aspects of the present invention are related to systems and methods for connected-component labeling.
An input image is divided into a plurality of regions and it is determined whether each of the divided regions is suitable for thinning processing. In accordance with a result of the determination an outlining processing is selected to generate outline data vector data for each of the regions. The generated outline data is output. For example a character region and a drawing region are discriminated from each other and outline data having a format suitable for a discriminated type of region is generated. In addition generation of outline data vector data which pass through a center line of the line drawing or generation of outline data vector data indicating a contour of a drawing is automatically selected. Furthermore in accordance with the size of a character function-approximation processing may be selected.
A method and apparatus for estimating the contour of a user object in a moving picture during video communications so that a personal background image is not provided during video communications. Information about center coordinates as well as a size of a face of the user object is extracted from a moving picture frame. Edges are extracted from the moving picture frame and a boundary of a head of the user object is estimated using a semicircle. The boundaries of left and right shoulders and left and right arms of the user object are estimated using second-order function graphs that overlap a largest portion of the edges. An entire contour of the user object is estimated according to the boundaries of the head the left and right shoulders and the left and right arms of the user object.
De-ringing operation for image processing. A selective image processing means is presented herein by which high frequency content is preserved while also eliminating ringing within digital images and this is achieved without introducing aliasing. Based on the analysis of neighboring pixels one or more of multiple filter modules and/or multiple image filtering/rocessing means is/are selectively applied to generate an output sample for a given pixel location. Two measures e.g. local activity LA and edge strength ES are calculated based on processing at least two different groups of pixels near a desired output sample. One of these groups of pixels may be a subset of another of the groups of pixels. By analyzing these two measures e.g. LA and ES selective processing of pixels near the desired output location ensures that high frequency content within the digital image is preserved with substantially reduced and/or eliminated ringing therein.
A method for determining edge features of an image comprising filtering at least a portion of the image to attenuate high frequency signals of the image to an extent greater than low frequency signals of the image. Performing a one-dimensional search in a two different horizontal directions relative to a particular pixel of the image to determine horizontal direction local maximums. Calculating a horizontal gradient based upon the horizontal direction local maximums. Performing a one-dimensional search in a two vertical horizontal directions relative to a particular pixel of the image to determine vertical direction local maximums. Calculating a vertical gradient based upon the vertical direction local maximums. Calculating a gradient for the particular pixel based upon the horizontal gradient and the vertical gradient.
A large number of stable local regions can be set with low calculation cost. In a face recognition apparatus which discriminates similar face images using feature amounts extracted from local regions included in an image to be discriminated a moving destination of a feature point extracted from the image to be discriminated and the size of an image to be clipped at the moving destination are calculated based on a table which defines information required to designate a moving destination of each feature point and information required to designate the size of an image to be clipped at the moving destination and an image with the calculated size is clipped at the calculated moving destination as the local region.
A method to find symmetries along curved paths in input scenes. The method may detect a curve in an input scene and one or more elements on that curve. The method may define and group points for the one or more element on the curve and define a centroid for each group. The method may then parameterize a transformation in transformation space between each centroid pair in the input scene. The method may then extract transformation paths by clustering points. The method may create phantom objects in case of mirroring along curved paths to help detect the curved paths.
An electronic document comparison system and method removes cachets and noise from a test electronic document. The system and method further compares each of second minimum blocks with a corresponding first minimum block in a standard electronic document line by line and obtains the second minimum blocks having different coordinates on each line. Furthermore the system and method simplifies the obtained second minimum blocks having different coordinates by filtering designated objects and marks the simplified second minimum blocks in the test electronic document.
Digital media categorization can include receiving information including a plurality of media objects and a metadata tag descriptive of at least a first media object; comparing the first media object with a second media object; and selectively associating the first media object s metadata tag with the second media object based on a result of the comparison. Each media object can include a digital image.
An information processing apparatus includes a first classification unit configured to set each of pixels forming a first image as a pixel of interest and classify the pixels of interest into one of a plurality of provided classes of a first type in accordance with a predetermined rule; a feature amount generation unit configured to generate a shifted waveform whose phase is shifted with respect to a waveform of the first image containing the pixels of interest and configured to generate a feature amount; a second classification unit configured to be provided with a plurality of classes of a second type in accordance with the feature amount for each of the plurality of classes of the first type and configured to classify the pixels of interest; and a prediction calculation unit configured to predictively calculate pixels forming a second image.
A plurality of images inputted in an image signal input portion are divided into a plurality of regions by an image dividing portion and a feature value in each of the plurality of regions is calculated by a feature value calculation portion and divided into a plurality of subsets by a subset generation portion. On the other hand a cluster classifying portion classifies a plurality of clusters generated in a feature space into any one of a plurality of classes on the basis of the feature value and occurrence frequency of the feature value. And a classification criterion calculation portion calculates a criterion of classification for classifying images included in one subset on the basis of a distribution state of the feature value in the feature space of each of the images included in the one subset.
A method and system for recognizing a character affected by a noise or an obstruction is disclosed. After receiving an image with characters a character being affected by a noise or an obstruction is determined. Then areas in the character where the noise or obstruction affected are precisely located. Templates representing every possible character in the image are updated by removing equivalent areas to the areas in the character being affected by the noise or obstruction. Then the character is classified in a template among the updated templates by finding the template having the highest number of matching pixels with the character.
A method converts an outline character to a stylized stroke character by first identifying regions of the outline character wherein each region is closed and disjoint. For each region candidate locations for stroke bodies and terminals of the stylized stroke character are determined. The stroke bodies are then initialized and organized into a hierarchical tree stricture and modified in an order of the hierarchical tree structure. End positions of the modified stroke bodies are then adjusted to match the outline character and lastly the terminals are selected for the adjusted stroke bodies.
A language-neutral method for searching online handwritten notes is provided. The different algorithms contained in this method enable querying online multilingual handwritten documents with substrings of words rather than just whole words. More particularly two approaches are presented &#x2014;one based on partial Fr&#xe9;chet distance calculations and the other based on a pair hidden Markov models. The partial Fr&#xe9;chet distance is adapted from the traditional Fr&#xe9;chet distance concept to match a subcurve or prefix of a query word. The pair hidden Markov model used in the present application is adapted from pair hidden Markov models used in bioinformatics as generative models of local and global alignment of biological sequences.
A method to detect answers and notes inputted a game apparatus including: receiving user input data and determining the received user input data to be an answer character based on a characteristic of the user input data; displaying on the display the answer character contemporaneously with the determination of the received user data is the answer character; making a game determination based on the answer character; displaying a result of the game determination; determining the received user input data to be a note character based on the characteristic of the user input data; displaying the note character contemporaneously with the determination that the user input data is the note character; settling the note character as an answer character based on a user input made after the note character is displayed and displaying the answer character determined from settling the note character.
An image processing apparatus includes a management unit configured to manage a template arranged to determine the placement of an image a clipping unit configured to clip a part of a first image and a placement unit configured to dispose a second image clipped from the first image by the clipping unit on the template wherein the clipping unit clips the second image from the first image so as to include a region which maintains the aspect ratio of a region of the template where an image is disposed and also includes the first image as much as possible.
An image search method that is robust and fast with computational complexity of logarithmic order relative to the number of models . The image search includes extracting a plurality of regions from one or more model images and normalizing the regions as standard regions; setting a specific region in each normalized standard region and classifying the plurality of standard regions under two or more subsets on the basis of a feature of the specific region; iteratively performing an operation of setting another specific region at a location different from that of the aforementioned specific region in each standard region classified in each subset and classifying the plurality of standard regions under still more subsets on the basis of a feature of the other specific region; and outputting the locations of the specific regions in the standard regions in the respective classifications and the features of the specific regions in the classifications.
A method for achieving segmentation of a picture according to one aspect of the present invention comprises: determining a first foreground of a picture based on a predetermined mask; applying Gaussian Mixture Models with weighted data GMM-WD to the first foreground to generate a second foreground; determining a first background of the picture based on the second foreground; applying the GMM-WD to the first background to generate a second background; and determining an unknown region based on the second background and the second foreground.
A method of representing and analysing images comprises producing a plurality of descriptors of an image at one or more scales and for one or more color channels said descriptors capturing color content and interrelation information within the regions and associating the descriptors in a plurality of ways based on their characteristics such as scale color channel feature semantics and region and comparing such representations of images to assess the similarity of images.
Analyzing an input image the input image being one of a digitized image stored in a memory or a scanned image from a scanner. Forming a feature image from the input image by dividing the input image into a plurality of blocks of pixels thus associating each block of pixels in the input image with a single pixel in the feature image and outputting the feature image for further analysis or storage in a memory. Example embodiments extract and analyze features from a document image to detect particular characteristics associated with the page area the distortion area and the book spine area. Extracted features can be further analyzed to detect document characteristics at the paragraph line word and character levels.
In accordance with one embodiment of the disclosure apparatus are provided including an image processor a unique image processing mechanism and a unique image processing activation mechanism. The image processor includes the unique image processing mechanism which processes a certain type of image. The unique image processing activation mechanism causes the unique image processing mechanism to process a given image.
Systems and methods are provided for detecting objects of an object class such as faces in an image sensor. In some embodiments the image sensor can include a detector with an image buffer. The image buffer can store image data in raster order. The detector can read the data out in Z order to perform object detection. The image data can then compute feature responses using the Z-ordered image data and determine whether any objects of the object class are present based on the feature responses. In some embodiments the detector can downscale the image data while the object detection is performed and use the downscaled image data to continue the detection process. In some embodiments the image data can perform detection even if the image is rotated.
First a binary image is generated by binarizing an image. Next a binary pixel ratio that is a ratio of a binary pixel quantity that is a quantity of dotted pixels included in a specific area of the binary image to a total quantity of pixels included in the specific area of the binary image is found. Then a thin-line image is generated by performing a line-thinning process on the specific area. After that a thin-line pixel ratio that is a ratio of the quantity of dotted pixels included in the generated thin-line image to the binary pixel quantity is found and the specific area is determined to be a map area or a photograph area based on the calculated binary pixel ratio and the calculated thin-line pixel ratio.
A method and apparatus is disclosed herein for performing pattern representation search and/or compression. In one embodiment the method comprises extracting one or more target patterns from a portion of an image; forming a pattern matrix based on the one or more target patterns; approximating the pattern matrix using a complexity-regularized representation derived from the pattern matrix; and sending a query to search a library of images for vectors in the query to detect using the a complexity-regularized representation any image in the library that contains image patches similar to the one or more target patterns.
An object comparison method comprises: generating a first ordered vector sequence representation of a first object; generating a second ordered vector sequence representation of a second object; representing the first object by a first ordered sequence of model parameters generated by modeling the first ordered vector sequence representation using a semi-continuous hidden Markov model employing a universal basis; representing the second object by a second ordered sequence of model parameters generated by modeling the second ordered vector sequence representation using a semi-continuous hidden Markov model employing the universal basis; and comparing the first and second ordered sequences of model parameters to generate a quantitative comparison measure.
A technology is disclosed for easily executing a compositional analysis to obtain a preferred composition. Image data is acquired the image data is analyzed and a plurality of composition lines expressing the feature of the image data on the composition are acquired. On the composition formed of the plurality of acquired composition lines the ratio of lengths of two sides selected from the plurality of sides in the region partitioned by the plurality of composition lines is detected to be a specified value for example the golden ratio .
Systems and methods for incorporating restricted access to feature vectors are described. A method is described for storing and accessing feature vectors relating to individuals in digital images. One or more individuals are identified within photos and feature vectors are generated for individuals in one or more photos. User profiles are downloaded from a database over a network. The feature vectors and downloaded user profiles are grouped. The face tagging system collects tags for the generated grouped feature vectors for generating enhanced user profiles for the individuals and the enhanced user profiles are stored in a storage resource.
In a first exemplary embodiment of the present invention an automated computerized method is provided for processing an image. According to a feature of the present invention the method comprises the steps of providing an image file depicting an image in a computer memory assembling a feature vector for the image file the feature vector containing information regarding a likelihood that a selected pair of regions of the image file are of a same intrinsic characteristic providing a classifier derived from a computer learning technique computing a classification score for the selected pair of regions of the image file as a function of the feature vector and the classifier and classifying the regions as being of the same intrinsic characteristic as a function of the classification score.
During shopping a shopper looks at herself in a mirror to evaluate clothing jewelry etc. because the mirror can provide a third-person view of the item. One thing a mirror cannot do is to show how two different items look at the same time because only one item can be tried on at a time. Because of this shoppers will often repeatedly try on items and must compare the look from memory. To enable self-comparison visually rather than from memory embodiments can detect matches between images from two separate recorded single camera video sequences corresponding to two different fittings . The matched images can then be played back to the user in close visual proximity for easy comparison shopping.
A document processing device includes: an extraction unit that extracts a first image of an element from a read image of a medium to which the element is affixed; an accepting unit that accepts first information for specifying processing to be performed to a document the first information being to be associated with the first image of the element; a determination unit that determines whether an image of an element identical to or similar to the first image of the element has been registered in a memory or not; and a registration unit that registers the first image of the element and the first information for specifying the processing in association with each other in the memory when the determination unit determines that the image of the element identical to or similar to the first image of the element has not been registered in the memory.
A method and system is described for determining the distance between first and second images using an enhanced P-Edit distance metric which accounts for differences in the rotation or pose of objects identified in the images.
A method for the classification of objects 16 and/or the recognition of their position and/or their orientation in space is set forth wherein measurement object data points of a measurement object surface are generated using a distance resolving receiver unit 18 and with the aid of model object data determined in advance hypotheses on the class the position and/or the orientation of a measurement object 16 are proposed and verified from the measurement object data points. A plurality of different hypothesis tests can be executed cascaded in such a way that only on verification of a hypothesis through a hypothesis test is a subsequent hypothesis test carried out within this cascade until either a hypothesis is falsified by the failure of a hypothesis test or a hypothesis is verified as a whole through a complete run through a cascade without falsification.
An image capture device captures a plurality of sequential images of a vehicle in motion. At substantially the same time a collocated rangefinder determines the distance between the vehicle and the image capture device. Each of the plurality of images may be segmented based on the rangefinder point of reference. The portion of each image representing the vehicle is extracted based on its motion with respect to a stationary background. Knowing the size of the vehicle with respect to the image and the distance that the vehicle is from the image capture device the image data is converted to real world dimensions. Using these real world dimensions a vehicle classification is determined.
The present disclosure relates to systems and methods for classifying videos based on video content. For a given video file including a plurality of frames a subset of frames is extracted for processing. Frames that are too dark blurry or otherwise poor classification candidates are discarded from the subset. Generally material classification scores that describe type of material content likely included in each frame are calculated for the remaining frames in the subset. The material classification scores are used to generate material arrangement vectors that represent the spatial arrangement of material content in each frame. The material arrangement vectors are subsequently classified to generate a scene classification score vector for each frame. The scene classification results are averaged or otherwise processed across all frames in the subset to associate the video file with one or more predefined scene categories related to overall types of scene content of the video file.
A method and system for detecting flames are provided. The flame detection method based on image processing techniques performs the following steps to detecting flames. It first finds one or more bright objects in the images that are captured from videos. A flickering state of a bright object is then determined. To verify the existence of a flame additionally subsequent images from the instant that a bright object first appears are utilized and the similar steps are applied to them. Finally a flame could be detected if the analyzed results are positive after the aforementioned steps have been performed.
Methods systems and apparatus including computer programs encoded on a computer storage medium for determining a location relative to an object and a type of a light source that illuminated the object when the image was captured are described. A method performed by a process executing on a computer system includes identifying an object of interest in a digital image. The method further includes projecting at least a portion of the digital image corresponding to the object of interest onto a three dimensional 3D model that includes a polygon-mesh corresponding to the object s shape. The method further includes determining one or more properties of a light source that illuminated the object in the digital image at an instant that the image was captured based at least in part on a characteristic of one or more polygons in the 3D model onto which the digital image portion was projected.
An apparatus and a method for character string recognition for correctly recognizing a character string placed on a medium even in a recognition process system in which a plurality of formats are handled. An image processing area is set on a medium. The image processing area is divided in a placement direction of character strings so as to make up a plurality of segments. An image data projection in a direction of character strings is calculated for each segment. The number of character string lines for each segment is calculated according to the image data projection. The number of character string lines is determined for the image processing area as a whole according to the number of character string lines for each segment and it is judged whether or not the character strings are predetermined character strings.
A method of organizing an image collection includes detecting faces in the image collection extracting features from the detected faces determining a set of unique faces by analyzing the extracted features wherein each face in the set of unique faces is believed to be from a different person than the other faces in the set; and displaying the unique faces to a user.
The a surface of an object is illuminated in sequence with a number of light beams each of which is nearly tangential to the surface. Images of the surface are recorded for each light beam and the images are analyzed to identify features such as depressions in the surface.
In general the subject matter described in this specification can be embodied in methods systems and program products. A plurality of electronic training images that are each classified as displaying substantially pictures is obtained. A plurality of local image features in each of the plurality of electronic training images is identified. A plurality of weak classifiers are recursively applied to the local image features. During each iteration a weak classifier that accurately classifies the local images features is selected. After each selection of a weak classifier features that were misclassified by the selected weak classifier are given greater weight than features that were classified correctly by the selected weak classifier. For each selected weak classifier a hillclimbing algorithm is performed to attempt to improve the weak classifier. A strong classifier that is a weighted combination of the selected weak classifiers on which hillclimbing algorithms have been performed is produced.
Disclosed is a method for determining the absence or presence of one or more instances of a predetermined pattern in an image and for determining the location of each found instance within a multidimensional space. A model represents the pattern to be found the model including a plurality of probes. Each probe represents a relative position at which a test is performed in an image at a given pose each such test contributing evidence that the pattern exists at the pose. The method further includes a comparison of the model with a run-time image at each of a plurality of poses. A match score is computed at each pose to provide a match score surface. Then the match score is compared with an accept threshold and used to provide the location any instances of the pattern in the image.
A wide range of digital devices either have or are provided with imaging devices which are capable of imaging externally provided information in the form of special codes that contain setup and/or configuration information. Processors within these devices which include cell phones cameras PDAs and personal computers to name just a few recognize the image and convert it to the desired configuration and/or setup information.
The present invention is related to a method of processing of output data from an Optical Character Recognition OCR system wherein the output data comprises images of double printed characters. The method identifies the respective members of a suspected double printed character image by first providing a set of single character template images from images of characters identified in the text being processed by the OCR system then combining the single character templates providing candidate models for the suspected double printed character image. Correlation between each respective candidate model and the suspected double printed character image provides an indication of which pair of modelled single template character images that most probable are the correct identification of the respective character images in the double printed character image.
A substrate having a coding pattern disposed on a surface thereof. The coding pattern comprises a plurality of contiguous tags each tag comprising x-coordinate data and y-coordinate data. A y-axis is nominally defined as north-south and an x-axis is nominally defined as east-west. A plurality of data elements are contained in each tag. The x-coordinate data is represented by a respective set of data elements and the y-coordinate data is represented by a respective set of data elements. The x-coordinate data has two replications within a respective tag a first replication in a western half of the tag and a second replication in an eastern half of the tag. The y-coordinate data has two replications within a respective tag a first replication in a northern half of the tag and a second replication in a southern half of the tag. Fragments of the coordinate data are arranged such that any tag-sized portion of the coding pattern is guaranteed to contain the x-coordinate data and the y-coordinate data for a tag irrespective of whether a whole tag is contained in the portion.
A method wherein images of different types of objects within a class are partitioned into region stacks. For each one of the stacks the method: a applies a template to extract fragments having a predetermined size and one of a plurality of different spatial orientations to generate extracted templates; b determines from the extracted templates a most frequent one thereof having only a first number of fragments with a common spatial orientations; c records the number of images having the determined most frequent extracted template; d repeats b and c with successively increasing number of fragments until the number of recoded images falls below a threshold; and e selects as a master extracted template the one of the most frequent templates having the largest recorded number of fragments. The master extracted templates for the stacks are combined into a map that is then compared with background images to remove extracted templates matching segment in the background.
Image data and image-capturing-condition information obtained by analyzing the image data are input from an external apparatus. Based on the input image-capturing-condition information a range of angles or sizes employed in a process of detecting a specific area from the image data is determined. The specific area is detected based on the determined range of angles or sizes.
Disclosed is a method and an apparatus for recognizing characters using an image. A camera is activated according to a character recognition request and a preview mode is set for displaying an image photographed through the camera in real time. An auto focus of the camera is controlled and an image having a predetermined level of clarity is obtained for character recognition from the images obtained in the preview mode. The image for character recognition is character-recognition-processed so as to extract recognition result data. A final recognition character row is drawn that excludes non-character data from the recognition result data. A first word is combined including at least one character of the final recognition character row and a predetermined maximum number of characters. A dictionary database that stores dictionary information on various languages using the first word is searched so as to provide the user with the corresponding word.
A physically demarcated body part is recognized and located using only a relatively small amount of computation but with a sufficient degree of recognition accuracy. For this purpose a procedure is proposed for detecting physically demarcated body parts face hand leg of a person s image 5 if a body part 2 as depicted in front of a background 3 . Borderlines 5d 5e in the image are only evaluated along line directions 5a ; 4a ; 4b ; 5c ; to determine by comparing with model 30 whether the body part image corresponds to a type of body part given by the model. In addition line directions 5d ; 5e ; inside a body part image and borderline directions 5a of a physically demarcated body part are used to locate and store its position.
When a reference image to which a document image is judged as being similar for the first time is not the first document sheet of the document type which contains this reference image error occurrence is concluded so that the page number indicated by a counter is set to be an error occurrence position. In case that the reference image to which the document image is similar is the last document sheet of the document type when the number of document images having been counted up by the time when this document image is judged as being similar to the reference image does not correspond with the number of reference images contained in the document type error occurrence is concluded so that the page number indicated by a counter is set to be an error occurrence position.
A method for locating an object in an image is provided for an object that exhibits in at least one direction foreground pixel runs and background pixel runs consistent with at least characteristic of the object. In one embodiment the method includes the acts of defining a plurality of regions in the image associating a metric with each of the regions finding pixel runs in the image and identifying at least one pixel run in one of the plurality of regions where the at least one pixel run is consistent with the at least one characteristic of the object. According to one embodiment the method includes the acts of adjusting the metric associated with the region where the at least one pixel run is identified and identifying from among the plurality of regions a region where the object is located based on a metric determined for a plurality of regions. In various embodiments the object includes a repetitive pattern such as those found in barcodes and character strings.
Search terms are derived automatically from images captured by a camera equipped cell phone PDA or other image capturing device submitted to a search engine to obtain information of interest and at least a portion of the resulting information is transmitted back locally to or nearby the device that captured the image.
An image processing apparatus of this invention includes a classification unit configured to classify anchor points that define the contour of an object into a plurality of groups based on features of the contour of the object and a saving unit configured to identifiably save the anchor points classified by the classification unit for respective groups.
Various technologies and techniques are disclosed that improve handwriting recognition operations. Handwritten input is received in training mode and run through several base recognizers to generate several alternate lists. The alternate lists are unioned together into a combined alternate list. If the correct result is in the combined list each correct/incorrect alternate pair is used to generate training patterns. The weights associated with the alternate pairs are stored. At runtime the combined alternate list is generated just as training time. The trained comparator-net can be used to compare any two alternates in the combined list. A template matching base recognizer is used with one or more neural network base recognizers to improve recognition operations. The system provides comparator-net and reorder-net processes trained on print and cursive data and ones that have been trained on cursive-only data. The respective comparator-net and reorder-net processes are used accordingly.
Data on a document is recognized using at least two machine recognition processes. Data from one machine recognition process is used as reference data; data formed using the other recognition process is used as verification data. If the verification data matches the reference data machine recognition may be verified. If the verification data does not exactly match the reference data an assessment is made of the likelihood that the verification data is sufficiently close to the reference data to suggest an error in the verification data. This may be done by applying a fitness function to the verification data to assess the likelihood that the verification data represents a mis-recognized version of the reference data. In one embodiment the verification data is OCR data and the reference data is MICR data.
The present invention provides a moving image analyzing apparatus method and system. The moving image analyzing apparatus comprises a moving image reading means for reading a moving image a region-of-interest extracting means for extracting a region-of-interest from each frame in the moving image an object feature extracting means for extracting an object feature in the region-of-interest or a region adjacent to the region-of-interest and a shot change detecting means for detecting a shot change on the basis of the color feature of image the object feature of the region-of-interest and the differences of the motion information among the images of each frame. By estimating the reliability of the motion information within an image the present invention can eliminate the shot change which is incorrectly detected according to the color distribution feature and the dimensional feature of the region-of-interest thereby improving the detection accuracy of shot change.
A video detection system and method compares a queried video segment to one or more stored video samples. Each of the queried video segments and stored video samples can be represented by respective digital image sets. A first and second comparison comprises comparing a set of low and high resolution temporal and spatial statistical moments in a COLOR9 space and eliminating file digital image sets that do not match the queried digital image set. A third comparison generates a set of matching files by comparing a set of wavelet transform coefficients in a COLOR9 space. RGB bit-wise registration and comparison of one or more subframes of specific frames in the queried digital image set to a corresponding set of matching file subframes determines queried subframe changes. In the event of a change in a queried subframe the changed subframe is added to the set of matching file subframes.
An image processing apparatus includes: a first area extraction unit that extracts as a first area an area assuming an intensity value equal to or greater than a first threshold value from an image; a second area extraction unit that extracts as a second area an area assuming an intensity value equal to or greater than a second threshold value smaller than the first threshold value from the image; a light source area designating unit that designates as a light source area an area in the image containing a light source based upon characteristic quantities indicating characteristics of the first area and the second area; and a control unit that controls the first area extraction unit the second area extraction unit and the light source area designating unit.
The invention relates to an image processing apparatus by means of which an image identification can take place in real time and which with only very little or even no a priori information is capable of carrying out a pertinent and reliable identification of objects. To this end the connection probabilities are determined between two contour points in each case taking into account the distance between the points by means of a computation mechanism. Further provided is at least one classifier which takes sets of calculated connection probabilities and selects from them subsets with at least three connection probabilities for possible links between at least three adjacent contour points one of which is a previously determined central contour point and for each subset sorts out that contour point which is adjacent to the central contour point and which has a possible link with the lowest connection probability to an adjacent contour point provided that the link does not connect two points that are adjacent to the central point and subsequently enters the contour points that have not been sorted out in a contour point list with connectors that identify the remaining links to the central point.
Method and system for low complexity assessment of quality of an image are presented. By performing multiresolution decomposition of images using for example a discrete wavelet transform and determining a metric based on a structural similarity index or a structural similarity map a structural similarity score characterizing similarity between images with a high degree of accuracy is produced. The processing time is much smaller in comparison to that required by other methods producing image quality metrics of comparable accuracy.
Image processing method that includes the steps of considering each image point as a node of an artificial neural network and of processing the image as function of values of the nodes and of connections of each image point undergoing processing with neighboring image points the image points of the processed image being obtained by iterative evolution steps of parameters defining the appearance as evolution steps of the value of nodes or by iterative evolution steps of values of the set of connections or by a combination of the evolutions wherein the processing occurs by evolution iterative steps that are functions of connections of neighboring image points with the image point under examination each of the neighboring image points being further considered as neighboring one or more or all adjacent image points the functions providing immediate feedback contributions for determining appearance values of all other image points.
Images may be sorted and categorized by defining a frustum for each image and overlaying the frustums in two three or four dimensions to create a density map and identify points of interest. Images that contain a point of interest may be grouped sorted and categorized to determine representative images of the point. By including many images from different sources common points of interest may be defined. Points of interest may be defined in two or three Euclidian dimensions or may include a dimension of time.
Disclosed is a method for determining the absence or presence of one or more instances of a predetermined pattern in an image and for determining the location of each found instance within a multidimensional space. A model represents the pattern to be found the model including a plurality of probes. Each probe represents a relative position at which a test is performed in an image at a given pose each such test contributing evidence that the pattern exists at the pose. The method further includes a comparison of the model with a run-time image at each of a plurality of poses. A match score is computed at each pose to provide a match score surface. Then the match score is compared with an accept threshold and used to provide the location any instances of the pattern in the image.
An occlusion detection system and method include a decomposer configured to decompose an image into a set of hierarchical parts. A hierarchy of classifiers is employed to detect features in the image and the hierarchical parts. A logical operation is configured to logically combine a classification result from at least two of the classifiers to detect an occlusion state of the image.
A first multi-dimensional digital image of a scan region is generated. The scan region is included in a materials-detection apparatus and is configured to receive and move containers through the materials-detection apparatus. A pre-defined background range of values is accessed the background range of values representing a range of values associated with non-target materials and the background range of values being distinct from values associated with the target materials. A value of a voxel included in the multi-dimensional digital image is compared to the background range of values to determine whether the value of the voxel is within the background range of values. If the value of the voxel is within the background range of values the voxel is identified as a voxel representing a low-density material. A second multi-dimensional digital image that disregards the identified voxel is generated to compress the first multi-dimensional digital image.
An image processing apparatus includes: a correlation value computing section that computes a correlation value between pixels in a noted image and its preceding and following reference images; a break determining section that determines a break in identical images based on the correlation value between pixels; a successive occurrence counting section that cumulatively counts successive occurrences of identical images as a successive occurrence count if the noted image is not determined as corresponding to a break; a pattern determining section that determines whether or not the successive occurrence count and a set count match if the noted image is determined as corresponding to a break; a matching counting section that counts up a matching count if it is determined that the successive occurrence count and the set count match; and a pull-down pattern detecting section that detects a predetermined pull-down pattern if the matching count exceeds a predetermined count.
A combined image and text document is described. In embodiment s a scanned image of a document can be generated utilizing a scanning application and text representations of text that is included in the document can be generated utilizing a character recognition application. Position data of the text representations can be correlated with locations of corresponding text in the scanned image of the document. The scanned image can then be rendered for display overlaid with the text representations as a transparent overlay where the scanned image and the text representations are independently user-selectable for display. A user-selectable input can be received to display the text representations without the scanned image the scanned image without the text representations or to display the text representations adjacent the scanned image.
Machine vision is used to identify a discontinuity in the boundary of an object in an image. An image of one or more objects is captured. One or more skeletons of the one or more objects are calculated. One or more boundaries of the one or more objects are calculated. A plurality of radial lines is extended from a spine point of a skeleton to the one or more boundaries. Each radial line intersects a boundary at a radial endpoint producing a plurality of radial endpoints. For each radial endpoint an expected radial endpoint is calculated based on two or more neighboring radial endpoints. If the difference between the radial endpoint and its expected radial endpoint exceeds a threshold a radial line including the radial endpoint is identified as a discontinuity in a boundary of an object.
Search terms are derived automatically from images captured by a camera equipped cell phone PDA or other image capturing device submitted to a search engine to obtain information of interest and at least a portion of the resulting information is transmitted back locally to or nearby the device that captured the image.
A novel and useful method of using Incremental Connected Components to segment and isolate individual characters in a gray-scale or color image. For each pixel intensity of pixels in the image a plurality of pixel groups are created comprising contiguous pixels of intensity equal to or less than the current pixel intensity. The pixel groups are then input to a character classifier which returns an identified character and a confidence value. Non-overlapping pixel groups i.e. segmentation of identified characters having the highest confidence values are then selected.
Generating typefaces from various images is disclosed in which any image whether from a still photograph or a video frame is analyzed to find various patterns existing in the image. These patterns may be evident from the image itself or may be discovered by applying various transforms to the image. The patterns obtained from the image are then compared against existing characters in existing typefaces in trying to find correlations between individual patterns and individual characters of the existing typefaces. When correlations are found the character image representing the pattern that resembles the existing typeface character is analyzed for various typeface properties such as weight width angle and the like. Using these determined typeface properties and the visual elements of the character image an entire set of characters making up a new typeface is generated.
Systems and methods are provided for recognizing a single stroke gesture. An input trajectory representing the single stroke gesture is received. The input trajectory is normalized to produce a normalized trajectory having a standard set of dimensions. The normalized trajectory is reduced to a standard number of substantially evenly spaced points. Respective covariance adjusted distances are determined for each class as the covariance adjusted position between a set of points representing each single stroke character classes and the substantially evenly spaced points representing the normalized trajectory.
An image processing apparatus has an extraction unit configured to extract a thin line with a width of equal to or less than a predetermined value from rendering data and an end point processing unit configured to displace with respect to a portion that satisfies a predetermined condition in the thin line at least one of end points of the portion within a predetermined range.
An apparatus and method for detecting &#x201c;Object Portraits&#x201d; photographs or images with a stand-out object of interest or a set of stand-out objects of interest is described. A set of tools has been developed for object of interest detection including &#x201c;Sunset-like&#x201d; scene detection pseudo-color saturation-based detection and object of interest isolation block intensity based detection and object of interest isolation. By effectively integrating these tools together the &#x201c;Object Portrait&#x201d; images and &#x201c;Non-Object Portrait&#x201d; images are successfully identified. Meaningful object of interest areas are thereby successfully isolated in a low complexity manner without human intervention.
Some embodiments provide a method that provides a display area for displaying an image that includes several of edges. The method provides a border drawing tool that in response to cursor movement across the image displays a search window about the cursor. The search window specifies a region to be searched to identify edges for use in defining a border for the image. In some embodiments the size of the search window varies based on the speed of the cursor. The search window is a square box in some embodiments and a circle in other embodiments. The search window is centered at the cursor in some embodiments. In some embodiments the display area is also for displaying the defined border over the image.
A method of extracting line segments from a subject image includes calculating a gradient image and a direction image of respective edge pixels in a canny edge image obtained from the subject image calculating a primary line passing arbitrary two pixels selected among the edge pixels selecting candidate line segment pixels through performing an incremental pixel extension from a midpoint of the two pixels forming the primary line and extracting the line segments by checking whether the candidate line segment pixels are connected to each another.
An image processing device includes a detecting unit configured to detect an external light reflection region from an input image and a determining unit configured to determine the glossiness of said external light reflection region and determines whether or not the reflection of the external reflection region is specular reflection and extracts a gloss region based on the determination result.
A model generator computes a first image perimeter color difference value for each of a plurality of first pixels included in a first image that is captured using a first focal length and selects one of the first image perimeter color difference values that exceeds a perimeter color difference threshold. Next the model generator computes a second image perimeter color difference value for each of a plurality of second pixels included in a second image that is captured using a second focal length and selects one of the second image perimeter color difference values that exceeds the perimeter color difference threshold. The model generator then determines that an edge is located at the first focal length by detecting that the selected first image perimeter color difference value is greater than the selected second image perimeter color difference value and generates an image accordingly.
Systems and methods for detecting a border region in an image. A blank border in a video picture is determined by summing luminance or other pixel measures in a direction parallel to the border and looking for the maximum gradient of those summed measures in a direction perpendicular to the border. Sensitivity can be enhanced by increasing relative to other pixels the gain of pixels around the present pixel value of the border. The location of the maximum gradient may be weighted by other measures before a decision on border location is taken.
A method is provided for creating a panorama. The method includes photographing a plurality of images having same backgrounds and different forms of a subject determining a size and a position of a reference region for creating a panorama using the images extracting a target region within the reference region from each of the images detecting same portions in adjacent target regions and creating a panorama by combining the adjacent target regions on the basis of the same portions.
An image-data processing apparatus. The image-data processing apparatus includes: an imaging section capturing an image of a subject and generating image data; a feature-extraction processing section extracting a visual feature from the generated image data; a feature-comparison processing section comparing a visual feature having been extracted from recorded image data in a recording medium and related to the recorded image data with the visual feature extracted by the feature-extraction processing section; and a control section reading image data having the visual feature extracted by the feature-extraction processing section from the recording medium on the basis of the comparison result.
An image processing system includes: an image reception unit that receives an image including an additional entry portion; an additional entry portion extracting unit that extracts the additional entry portion from the image received by the image reception unit; a concealment area specifying unit that specifies an area to be concealed in the image based on the additional entry portion extracted by the additional entry portion extracting unit; a concealment reason specifying unit that specifies a concealment reason based on one of operation information related to an operation for the image and a feature of the additional entry portion extracted by the additional entry portion extracting unit; an image concealment unit that conceals the area specified by the concealment area specifying unit in the image; and an image addition unit that adds concealment reason information related to the concealment reason specified by the conceal reason specifying unit to the image.
An information retrieval apparatus includes an obtaining unit configured to obtain dynamic ranges or re-quantization codes of a target object to be retrieved and dynamic ranges or re-quantization codes of each of comparison objects to be compared with the target object the dynamic ranges or re-quantization codes of the target object and the dynamic ranges or re-quantization codes of the comparison objects being obtained as a result of adaptive dynamic range coding; a distance computation unit configured to compute distances between the target object and the comparison objects using the obtained dynamic ranges or re-quantization codes of the target object and the obtained dynamic ranges or re-quantization codes of the comparison objects; and a comparison unit configured to compare the distances between the target object and the comparison objects to select one of the comparison objects having a minimum distance.
Conventionally there is the problem that a source program that is to be converted cannot be properly analyzed and the conversion ratio cannot be improved. The present invention provides a program pattern analyzing apparatus comprising: a pattern information storage portion 201 in which at least one piece of first command pattern information of a first source program can be stored; a first source program accepting portion 202 that accepts the first source program; a comparing portion 203 that fetches at least one piece of conversion unit information from the first source program and compares each piece of the fetched conversion unit information with the first command pattern information stored in the pattern information storage portion 201; and a pattern accumulating portion 204 that accumulates comparison command pattern information that is information indicating a command pattern corresponding to the conversion unit information judged by the comparing portion 203 to match none of the first command pattern information as the first command pattern information in the pattern information storage portion 201.
A method of updating parameters for pixels associated with a background estimation portion of a video frame is disclosed. The method comprises receiving a group of pixels of an incoming data stream associated with the video frame each pixel of the group of pixels being characterized by a plurality of parameters; comparing for each pixel of the group of pixels the plurality of parameters for a pixel with the plurality of parameters for adjacent pixels; determining for each pixel of the group of pixels whether the parameters are similar to the parameters of an adjacent pixel; identifying a region of the group of pixels having similar parameters; and updating parameters for all pixels associated with the region with a single set of parameters.
To provide an update region detection device capable of accurately detecting an update region from plot data on a computer screen. In an update region detection unit 125 a pixel comparison unit 601 compares a difference between values of pixels at the same position in each of a reference frame and a current frame with a first threshold and a second threshold the second threshold being a value greater than the first threshold. An update region extraction unit 602 extracts an update region a group including a pixel where a difference greater than the second threshold has been detected from among a group of pixels where a difference greater than the first threshold has been detected.
Disclosed are a system and a method for a computerized automatic placement of objects in media files in post-production. Embodiments of the present invention enable the automatic placement of objects which appear in a media file such as a digital video file. According to one embodiment of the present invention the disclosed system and method allow the replacement of a specific pattern which appears in a given video file with a new image in a fully transparent manner. According to embodiments of the present invention the makers of the media file place a designated pattern in the media file such as a sticker on an object. Embodiments of the present invention enable the replacing of a new image on the designated pattern on the sticker with a new image.
Frontal face images are classified into four categories such as Asian Caucasian African and others. A new representation of face appearance named BITF Block Intensity and Texture Feature is employed as the discrimination feature. An ensemble of three component classifiers each trained with a different number of BITF features as inputs is designed to achieve a reliable classification. Further reliability is obtained by taking into consideration other secondary features to boost the classification performance.
Described herein is a framework for constructing a hierarchical classifier for facilitating classification of digitized data. In one implementation a divergence measure of a node of the hierarchical classifier is determined. Data at the node is divided into at least two child nodes based on a splitting criterion to form at least a portion of the hierarchical classifier. The splitting criterion is selected based on the divergence measure. If the divergence measure is less than a predetermined threshold value the splitting criterion comprises a divergence-based splitting criterion which maximizes subsequent divergence after a split. Otherwise the splitting criterion comprises an information-based splitting criterion which seeks to minimize subsequent misclassification error after the split.
Disclosed is a method for determining the absence or presence of one or more instances of a predetermined pattern in an image and for determining the location of each found instance within a multidimensional space. A model represents the pattern to be found the model including a plurality of probes. Each probe represents a relative position at which a test is performed in an image at a given pose each such test contributing evidence that the pattern exists at the pose. The method further includes a comparison of the model with a run-time image at each of a plurality of poses. A match score is computed at each pose to provide a match score surface. Then the match score is compared with an accept threshold and used to provide the location any instances of the pattern in the image.
A wordspotting system and method are disclosed for processing candidate word images extracted from handwritten documents. In response to a user inputting a selected query string such as a word to be searched in one or more of the handwritten documents the system automatically generates at least one computer-generated image based on the query string in a selected font or fonts. A model is trained on the computer-generated image s and is thereafter used in the scoring the candidate handwritten word images. The candidate or candidates with the highest scores and/or documents containing them can be presented to the user tagged or otherwise processed differently from other candidate word images/documents.
A method and system for increasing the certainty of a silhouette matching process where the process is being used for attitude determination of an object of interest for example an aircraft. The method involves using one or more mask images that include structure or features that may or may not always be associated with the object of interest and overlaying the mask image s onto a library image of the aircraft. Each pixel of the library image is compared against corresponding pixels of the mask image s to determine which pixels represent ambiguous areas of the library image. Those pixels are eliminated from consideration in determining a Fit score where the Fit score represents a percentage value indicative of a certainty of the matching process in identifying the attitude of the aircraft. The method and system is applicable to a wide ranging variety of object detection applications.
In some embodiments image spam is identified by comparing color histograms of suspected spam images with color histograms of reference known images. The histogram comparison includes comparing a first color content in a query image with a range of similar color contents in the reference image. For example a pixel count for a given color in the query image may be compared to pixel counts for a range of similar colors in the reference image. A histogram distance between two images may be determined according to a computed pixel count difference between the given query histogram color and a selected color in the range of similar reference histogram colors.
An apparatus for processing image information regarding image data pieces each having retrievable information including shooting time and a shooting interval includes a grouping unit configured to group the image data pieces which are arranged in order of the shooting time by sequentially carrying out grouping steps that each divide or merge the image data pieces into groups according to the shooting intervals an evaluation unit configured to calculate a score for each of the grouping steps according to one or a plurality of predetermined evaluation items and a determination unit configured to determine a specific one of the grouping steps according to the calculated scores.
Provided is an apparatus and method for recognizing characters. The apparatus includes a display unit to display an image in which a region of interest or an error region is indicated and a character recognition result a region-of-interest setting unit to set the region of interest in the image displayed on the display unit a recognition unit to perform character recognition on the region of interest or the error region and provide the character recognition result to the display unit and an error correction unit to set the error region in the image displayed on the display region perform image copying on the set error region according to a user input and provide a handwriting input using the image copying to the recognition unit.
In one aspect a computer-implemented method of providing a symbol includes using a computer to receive a request to provide the symbol retrieve an image based on the request modify the image based on the request convert the image to form the symbol and provide the symbol. In another aspect an article includes a machine-readable medium that stores executable instructions to provide a symbol. The instructions cause a machine to receive a request to provide the symbol retrieve an image based on the request modify the image based on the request convert the image to the symbol and provide the symbol. In a further aspect an apparatus to provide a symbol includes circuitry to receive a request to provide the symbol retrieve an image based on the request modify the image based on the request convert the image to the symbol and provide the symbol.
A word spotting system includes a semi-continuous hidden Markov model configured to model a handwritten word of interest. A writing segments extractor is configured to extract writing segments generally comprising images of handwritten character strings from a received document image. A word model adaptation processor is configured to adjust a shared pool of Gaussians of the semi-continuous hidden Markov model respective to the extracted writing segments. A modeler is configured to model extracted writing segments using the semi-continuous hidden Markov model with the adjusted shared pool of Gaussians to identify whether each modeled writing segment matches the handwritten word of interest.
Disclosed is a method of searching a digital image of a document for a predetermined keyword. The method identifies a word in the digital image the word comprising one or more shapes. A test matrix comprising a difference vector for each character of the word is generated and a template matrix comprising a difference vector for each shape of the keyword is also generated wherein a difference vector represents the differences between the visual features of a respective shape and the visual features of a collection of reference shapes. A measure of similarity between the word and the keyword is generated by comparing the test matrix and the template matrix.
Aspects of the present invention relate to methods and systems for determining image characteristics in a digital image.
An automatic photographing method with face recognition is applied in a camera having a detecting lens and a photographing lens for a user to photograph a target. First detect a face of the user through the detecting lens and obtain a plurality of face images of the detected face. Then capture an image variance of the obtained face images and photograph the target through a photographing lens when the captured image variance exceeds a photographing starting value. Therefore during the whole photographing process photographing can be achieved through determining variations of the face images of the user without pressing the shutter key of the camera thereby completely preventing handshakes resulted from the pressing action and thus improving the photographing quality.
A depth image of a scene may be received observed or captured by a device. A human target in the depth image may then be scanned for one or more body parts such as shoulders hips knees or the like. A tilt angle may then be calculated based on the body parts. For example a first portion of pixels associated with an upper body part such as the shoulders and a second portion of pixels associated with a lower body part such as a midpoint between the hips and knees may be selected. The tilt angle may then be calculated using the first and second portions of pixels.
An image processing apparatus include: a storage unit storing an image of a processing target; a tangent calculating unit extracting contours as a bent lines represented by sets of contour points from an image read from the storage unit and computing tangents to the extracted contour; a projecting unit projecting computed tangents to axes in directions orthogonal to the corresponding tangents and computing coordinates of intersections where the tangents intersect the axes; and a rectangle calculating unit selecting intersections with maximum values and minimum values of coordinates among intersections computed by the projecting unit for each direction of the axis and computing a rectangle formed by a pair of parallel tangents passing through two intersections with maximum values and minimum values selected for a first axis and another pair of tangents passing through two intersections with maximum values and minimum values selected for a second axis orthogonal to the first axis.
A computer readable medium storing a program causing a computer to execute a process for image processing the process includes: inputting first image data as a reference and second image data to be compared with the first image data; selecting a plurality of first sequences from different positions of the first image data each of the plurality of first sequences includes first unit-image elements; determining whether or not a second sequence including second unit-image elements having identity in an alignment of shapes with respect to the plurality of first sequences exists in the second image data; and detecting from the second sequence determined not to exist in the second image data a unit-image element not having the identity in the alignment of shapes with respect to the first image data among the second image data.
A method for object recognition using shape and color features of the object to be recognized. An adaptive architecture is used to recognize and adapt the shape and color features for moving objects to enable object recognition.
A method for determining significant events in a digital image collection including using a processor for generating image counts time-series from the image collection; computing a model of the image counts time-series; and using the image counts time-series and the model to determine significant events.
Provided are methods for determining optimal features for classifying patterns or objects. Also provided are methods for image analysis. Further provided are methods for image searching.
The different illustrative embodiments provide a method for identifying landmarks in an image. An image of a worksite is received. The image is analyzed to determine a suggested identity of a worksite feature in the image. The suggested identity of the worksite feature is sent over a communications unit. A confirmation of the suggested identity of the worksite feature is received to form a confirmed identity. The confirmed identity and a number of attributes associated with the confirmed identity is stored in a database.
In an image conversion method a value which reflects the mutual relationship between the classes of pixel patterns each formed from a pixel classified as one of a plurality of classes and peripheral pixels is set as a converted value corresponding to each of the plurality of classes a pixel of interest is sequentially selected from the input image and a pixel pattern formed from the selected pixel of interest and a predetermined number of pixels around it is classified as one of the plurality of classes in accordance with a neighboring pattern obtained based on the relationship between the value of the pixel of interest and the values of peripheral pixels located at predetermined relative positions with respect to the pixel of interest. The value of the pixel of interest is converted into a converted value set for a class to which the pixel of interest has been classified.
